{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import sleep\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def f_score(cm, index = 2, beta = 1):\n",
    "    tp = cm[index][index]\n",
    "    fp = cm[:, index].sum() - cm[index][index]\n",
    "    relevant = cm[index, :].sum()\n",
    "    precision = tp/(tp + fp)\n",
    "    recall = tp / (relevant)\n",
    "    \n",
    "    return (1 + beta ** 2) * (precision * recall)/(beta * beta * precision + recall)\n",
    "\n",
    "    \n",
    "    \n",
    "path = '/Users/Alex/Desktop/2.FutureTech/OSFM/uniform_sample/results/9-13-and-8-28-with-confidence.csv'\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "manual_column_name = 'alex'\n",
    "\n",
    "if (manual_column_name not in set(df.columns)):\n",
    "    df[manual_column_name] = [None for _ in range(len(df))]\n",
    "\n",
    "options = {str(idx): el for idx, el in enumerate(['context', 'uses', 'extends'])} | {'*': '*'}\n",
    "print(options)\n",
    "\n",
    "df = df[df['strippedModelKey'] != 'ase']\n",
    "labeling_on = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df[manual_column_name].isna()\n",
    "print(f\"{mask.sum()}/{len(mask)} left.\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['classification_mod'] = [c if correct_attribution >= .3 else 'context' for c, correct_attribution in zip(df['classification'], df['gpt4o_prompt1_10'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "mask = df[manual_column_name].isna()\n",
    "while mask.sum() > 0 and labeling_on:\n",
    "    idx = random.choice(df[mask].index)\n",
    "    \n",
    "    print(f\"{mask.sum()}/{len(mask)} left.\", flush = True)\n",
    "    print(options, flush = True)\n",
    "    print(f\"Model Key:{df.at[idx,'modelKey']}\", flush = True)\n",
    "    print(df.at[idx, 'multisentence'], flush = True)\n",
    "    \n",
    "    sleep(1)\n",
    "\n",
    "    response = input()\n",
    "    \n",
    "    if (response == 'exit'):\n",
    "        #df.to_csv(path) commenting out to avoid oopsies\n",
    "        clear_output()\n",
    "        break\n",
    "    \n",
    "    df.loc[idx, manual_column_name] = options.get(response)\n",
    "    mask = df[manual_column_name].isna()\n",
    "    clear_output()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_table = lambda s: s.find('\\\\begin{tab') == -1\n",
    "\n",
    "confidence_threshold = 5\n",
    "subset_mask = (df['alex'].notna() & df['multisentence'].apply(not_table)\n",
    "               #& (df['alex_confidence'] > confidence_threshold)\n",
    "               #& (df['alex_confidence'] <= confidence_threshold)\\\n",
    "               )\n",
    "\n",
    "df_not_null = df[subset_mask]\n",
    "\n",
    "true, pred = df_not_null['alex'], df_not_null['classification_mod']\n",
    "\n",
    "print(Counter(true), Counter(pred))\n",
    "\n",
    "cm = confusion_matrix(true, pred)\n",
    "\n",
    "use_weights = False\n",
    "if use_weights:\n",
    "    weights = np.array([0.855154, 0.016340, 0.128506]).reshape(1, 3)\n",
    "    cm  = cm * weights \n",
    "    cm = cm * (1000 / cm.sum())\n",
    "    cm = np.round(cm).astype(int)\n",
    "    assert(np.abs(cm.sum() - 1000) < 5), cm.sum()\n",
    "    \n",
    "print(cm.sum())\n",
    "\n",
    "y_label, x_label = 'alex'\n",
    "\n",
    "\n",
    "#labels = ['context', 'extends', 'uses']\n",
    "labels = ['context', 'not_context']\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels, cbar = False, annot_kws={\"size\": 20})\n",
    "plt.xlabel(x_label)\n",
    "plt.ylabel(y_label)\n",
    "\n",
    "\n",
    "#print(f\"Uses F1: {f_score(cm, index = 2, beta = 1)}\")\n",
    "#print(f\"Extends F1: {f_score(cm, index = 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
