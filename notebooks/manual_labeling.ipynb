{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import sleep\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def f_score(cm, index = 2, beta = 1):\n",
    "    tp = cm[index][index]\n",
    "    fp = cm[:, index].sum() - cm[index][index]\n",
    "    relevant = cm[index, :].sum()\n",
    "    precision = tp/(tp + fp)\n",
    "    recall = tp / (relevant)\n",
    "    \n",
    "    return (1 + beta ** 2) * (precision * recall)/(beta * beta * precision + recall)\n",
    "\n",
    "    \n",
    "    \n",
    "path = '/Users/Alex/Desktop/2.FutureTech/OSFM/uniform_sample/results/post_classification_random_sample_8-28 copy.csv'\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "manual_column_name = 'alex'\n",
    "pred_col = 'learned_classification'\n",
    "\n",
    "if (manual_column_name not in set(df.columns)):\n",
    "    df[manual_column_name] = [None for _ in range(len(df))]\n",
    "\n",
    "options = {str(idx): el for idx, el in enumerate(['context', 'uses', 'extends'])} | {'*': '*'}\n",
    "print(options)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df[manual_column_name].isna()\n",
    "print(f\"{mask.sum()}/{len(mask)} left.\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "mask = df[manual_column_name].isna()\n",
    "while mask.sum() > 0:\n",
    "    idx = random.choice(df[mask].index)\n",
    "    \n",
    "    print(f\"{mask.sum()}/{len(mask)} left.\", flush = True)\n",
    "    print(options, flush = True)\n",
    "    print(f\"Model Key:{df.at[idx,'modelKey']}\", flush = True)\n",
    "    print(df.at[idx, 'multisentence'], flush = True)\n",
    "    \n",
    "    sleep(1)\n",
    "\n",
    "    response = input()\n",
    "    \n",
    "    if (response == 'exit'):\n",
    "        #df.to_csv(path) commenting out to avoid oopsies\n",
    "        clear_output()\n",
    "        break\n",
    "    \n",
    "    df.loc[idx, manual_column_name] = options.get(response)\n",
    "    mask = df[manual_column_name].isna()\n",
    "    clear_output()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_table = lambda s: s.find('\\\\begin{tabular}') == -1\n",
    "\n",
    "confidence_threshold = 5\n",
    "subset_mask = (df['alex'].notna() & df['multisentence'].apply(not_table)\n",
    "               & (df['alex_confidence'] > confidence_threshold)\n",
    "               #& (df['alex_confidence'] <= confidence_threshold)\n",
    "               )\n",
    "\n",
    "df_not_null = df[subset_mask]\n",
    "\n",
    "true, pred = df_not_null['alex'], df_not_null[pred_col]\n",
    "\n",
    "print(set(true), set(pred))\n",
    "\n",
    "cm = confusion_matrix(true, pred)\n",
    "\n",
    "use_weights = False\n",
    "weights = np.array([0.92822272, 0.00804214, 0.06373514]).reshape(1, 3) * (10000 / cm.sum())\n",
    "cm = np.round(cm * weights).astype(int) if use_weights else cm\n",
    "\n",
    "y_label, x_label = 'alex', pred_col\n",
    "\n",
    "\n",
    "labels = ['context', 'extends', 'uses']\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(x_label)\n",
    "plt.ylabel(y_label)\n",
    "\n",
    "print(f\"Uses F1: {f_score(cm, index = 2, beta = 1)}\")\n",
    "print(f\"Extends F1: {f_score(cm, index = 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = df_not_null[(df_not_null[pred_col] == 'extends') & (df['alex'] == 'context')]\n",
    "for sentence in fp['multisentence']:\n",
    "    print(sentence, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp['multisentence'].apply(lambda s: s.find('\\\\begin{table}') > 0).sum()/len(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, sentence in enumerate(df_not_null[df_not_null['alex'] == 'extends']['multisentence']):\n",
    "    print(idx, sentence, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
