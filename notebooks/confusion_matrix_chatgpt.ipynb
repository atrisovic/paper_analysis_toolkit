{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "CONNECTION_ON = False\n",
    "MODEL = 'gpt-4o' #'gpt-3.5-turbo',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "def prompt(input):\n",
    "    if not CONNECTION_ON:\n",
    "        raise Exception\n",
    "    \n",
    "    api_key = None\n",
    "    api_url = 'https://api.openai.com/v1/chat/completions'\n",
    "\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': f'Bearer {api_key}',\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        'model': MODEL,\n",
    "        'messages': [\n",
    "            {'role': 'user', 'content': input},\n",
    "        ],\n",
    "        'max_tokens': 2000,\n",
    "        'temperature': 0.5,\n",
    "    }\n",
    "\n",
    "    response = requests.post(api_url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        response_data = response.json()\n",
    "        return response_data['choices'][0]['message']['content']\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return response.json()\n",
    "\n",
    "def stripJSON(text: Optional[str], added_bracket = False, debug = False) -> Optional[dict]:\n",
    "    if (text is None):\n",
    "        return None\n",
    "    \n",
    "    #text = text.replace('\\(', '(').replace('\\)', ')') #Mistral likes to add escape sequences, for some unknown reason\n",
    "    text = text.replace(\"```\", \"\").replace('json', '')\n",
    "    \n",
    "    if (debug):\n",
    "        print(text)\n",
    "        try:\n",
    "            json.loads(text)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    # a very manual way of finding our JSON string within the output\n",
    "    \n",
    "    all_open_brackets = [i for i, ltr in enumerate(text) if ltr == '{']\n",
    "    obj = None\n",
    "    for start in all_open_brackets:\n",
    "        balance_counter = 1\n",
    "        for offset, chr in enumerate(text[start + 1:], start = 1):\n",
    "            balance_counter += (1 if chr == '{' else -1 if chr == '}' else 0)\n",
    "            if (balance_counter == 0):\n",
    "                try:\n",
    "                    obj = json.loads(text[start: start + offset + 1])\n",
    "                except:\n",
    "                    pass\n",
    "                break\n",
    "        if (obj is not None):\n",
    "            break\n",
    "        \n",
    "    # sometimes we miss the first or last bracket (dumb LLM), so we add it manually.\n",
    "    if not added_bracket:\n",
    "        return (stripJSON('{' + text, added_bracket = True) or stripJSON(text + '}', added_bracket = True))\n",
    "        \n",
    "    return obj\n",
    "\n",
    "\n",
    "def update_labels(path, \n",
    "                  column = 'alex2',\n",
    "                  ground_truth_path = '/home/gridsan/afogelson/osfm/scripts/urop_samples/uniform_sample/uniform_urop_sample_alex_labeled.csv',\n",
    "                  save = False):\n",
    "    ground_df = pd.read_csv(ground_truth_path)\n",
    "    to_update_df = pd.read_csv(path)\n",
    "    \n",
    "    updated = 0\n",
    "    for idx in to_update_df.index:\n",
    "        mask = ground_df['multisentence'] == to_update_df['multisentence'].loc[idx]\n",
    "        assert(mask.sum() == 1)\n",
    "        \n",
    "        if to_update_df[column].loc[idx] != ground_df[column].loc[idx]:\n",
    "            updated += 1\n",
    "            to_update_df[column].loc[idx] = ground_df[column].loc[idx]\n",
    "    \n",
    "    print(f\"Updated {updated} labels in {path}.\")\n",
    "    \n",
    "    if (save):\n",
    "        print(f\"Saving to original path. \")\n",
    "        to_update_df.to_csv(path, index = False)\n",
    "    return to_update_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following sentences are from an academic paper (the CITING paper) which references a pretrained machine learning model through citation (the CITED paper). The models are called foundation models, and they might be a language model, a vision model, or any other kind of large neural network. The CITED paper is highlighed using HTML tags as such: <cite> cited reference </cite>. All other citations can be ignored, as we only care about the cited reference with these tags.\n",
      "\n",
      "We'd like to discern how the CITING paper makes use of the foundation model, as described within the sentences. Below are ten statements, which will be evaluated as either true or false. Only use the sentences provided to answer the questions about this particular paper's use of the foundation model, not other references. \n",
      "1. The CITING sentences explicitly mention results from the CITED paper to support background claims.\n",
      "2. The CITING sentences explicitly mention a techniques of the CITED paper in order to provide relevant context.\n",
      "3. The CITING sentences mention performance results of the CITED paper to contextualize the CITED model's capabilities.\n",
      "4. The CITING sentences mention deploying the CITED foundation model's encoder or decoder as part of their methodology.\n",
      "5. The CITING sentences uses the CITED foundation model to create embeddings as part of their methodology.\n",
      "6. The CITING sentences explicitly describe their methodology including fine-tuning or adjusting the parameter weights of the CITED foundation model.\n",
      "7. The CITING sentences describe adopting the CITED foundation model's architecture as part of their model design.\n",
      "8. The CITING sentences describe training a model using the CITED paper's dataset.\n",
      "9. The CITING sentences mention using the CITED foundation model for feature extraction as part of their methodology.\n",
      "10. The CITING sentences mention using the CITED foundation model as a classifier or detector as part of their methodology.\n",
      "11. The CITING sentences describes deploying the CITED foundation model to generate data in the form of text/image/audio/video for later training of their model.Please respond with the following information per question:\n",
      "    (a) an explanation of the relevant information\n",
      "    (b) explain how you know the usage (or lacktherof) of the <cite> CITED </cited> foundation model is by the CITING sentences rather than some other reference.\n",
      "    (c) The final True or False answer to the question.\n",
      "Use this JSON format: {{\"explanation_1\": \"Information relevant to the first question...\", \"confirmation_1\": \"True | False\", \"answer_1\": \"True | False\", \"explanation_2\": \"Information relevant to the second question...\" , \"confirmation_2\": \"True | False\", \"answer_2\": \"True | False\", ... }}, classifying based on the following:\n",
      "\n",
      "{input}\n"
     ]
    }
   ],
   "source": [
    "questions = {\n",
    "1: \"The CITING sentences explicitly mention results from the CITED paper to support background claims.\",\n",
    "2: \"The CITING sentences explicitly mention a techniques of the CITED paper in order to provide relevant context.\",\n",
    "3: \"The CITING sentences mention performance results of the CITED paper to contextualize the CITED model's capabilities.\",\n",
    "4: \"The CITING sentences mention deploying the CITED foundation model's encoder or decoder as part of their methodology.\",\n",
    "5: \"The CITING sentences uses the CITED foundation model to create embeddings as part of their methodology.\",\n",
    "6: \"The CITING sentences explicitly describe their methodology including fine-tuning or adjusting the parameter weights of the CITED foundation model.\",\n",
    "7: \"The CITING sentences describe adopting the CITED foundation model's architecture as part of their model design.\",\n",
    "8: \"The CITING sentences describe training a model using the CITED paper's dataset.\",\n",
    "9: \"The CITING sentences mention using the CITED foundation model for feature extraction as part of their methodology.\",\n",
    "10: \"The CITING sentences mention using the CITED foundation model as a classifier or detector as part of their methodology.\",\n",
    "11: \"The CITING sentences describes deploying the CITED foundation model to generate data in the form of text/image/audio/video for later training of their model.\"}\n",
    "\n",
    "questions_as_string = '\\n'.join([f\"{key}. {value}\" for key, value in questions.items()])\n",
    "\n",
    "MULTIPROMPT = (\"\"\"The following sentences are from an academic paper (the CITING paper) which references a pretrained machine learning model through citation (the CITED paper). The models are called foundation models, and they might be a language model, a vision model, or any other kind of large neural network. The CITED paper is highlighed using HTML tags as such: <cite> cited reference </cite>. All other citations can be ignored, as we only care about the cited reference with these tags.\n",
    "\n",
    "We'd like to discern how the CITING paper makes use of the foundation model, as described within the sentences. Below are ten statements, which will be evaluated as either true or false. Only use the sentences provided to answer the questions about this particular paper's use of the foundation model, not other references. \\n\"\"\" + questions_as_string + \n",
    "\n",
    "\n",
    "\"\"\"Please respond with the following information per question:\n",
    "    (a) an explanation of the relevant information\n",
    "    (b) if applicable, explain how you know this usage of the <cite> CITED </cited> foundation model is by the CITING paper rather than a different reference in the sentences (or say \"didn't use\").\n",
    "    (c) The final True or False answer to the question.\n",
    "Use this JSON format: {{\"explanation_1\": \"Information relevant to the first question...\", \"confirmation_1\": \"True | False\", \"answer_1\": \"True | False\", \"explanation_2\": \"Information relevant to the second question...\" , \"confirmation_2\": \"True | False\", \"answer_2\": \"True | False\", ... }}, classifying based on the following:\\n\\n{input}\"\"\" )\n",
    "\n",
    "\n",
    "SINGLEPROMPT = (\"\"\"The following sentences are from an academic paper (the CITING paper) which references a pretrained machine learning model through citation (the CITED paper). The models are called foundation models, and they might be a language model, a vision model, or any other kind of large neural network. The CITED paper is highlighed using HTML tags as such: <cite> cited reference </cite>. All other citations can be ignored, as we only care about the cited reference with these tags.\n",
    "\n",
    "We'd like to discern how the CITING paper makes use of the foundation model, as described within the sentences. Below are ten statements, which will be evaluated as either true or false.\n",
    "\n",
    "{question}\n",
    "\n",
    "Please response in this JSON format: {{\"explanation\": \"True | False\"}}, classifying based on the following:\\n\\n{input}\"\"\" )\n",
    "\n",
    "\n",
    "sentences = 'these models take transformers (vaswani et al, 2017) as the backbone, and predict the next token based on previous tokens.1 prior to the widespread adoption of transformers, autoregressive language models were built on the backbones of n-grams (bickel et al, 2005; pauls and klein, 2011) and recurrent neural networks (mikolov et al, 2010), and have been applied to various nlg tasks such as summarization (nallapati et al, 2017) and dialogue generation (chen et al, 2017). footnote 1: another variant of language models predicts masked tokens in a corrupted sequence (devlin et al, 2019; <cite>liu et al, 2019</cite>; lan et al, 2019, _inter alia_). transformer-based llms have demonstrated exceptional performance across tasks, and have therefore shifted nlp from a paradigm centered on task-specific solutions to general-purpose pretraining (devlin et al, 2019; radford et al, 2019).'\n",
    "\n",
    "print(MULTIPROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "urop_path = '/home/gridsan/afogelson/osfm/scripts/urop_samples/uniform_sample/uniform_urop_sample_alex_labeled'\n",
    "df = pd.read_csv(urop_path + '.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated 0 labels in /home/gridsan/afogelson/osfm/scripts/urop_samples/uniform_sample/uniform_urop_sample_alex_labeled_gpt4o_response_2024-06-21 09:38:45.344243.csv.\n",
      "Saving to original path. \n"
     ]
    }
   ],
   "source": [
    "other_path = '/home/gridsan/afogelson/osfm/scripts/urop_samples/uniform_sample/uniform_urop_sample_alex_labeled_gpt4o_response_2024-06-21 09:38:45.344243.csv'\n",
    "\n",
    "df = update_labels(other_path, save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 201/201 [37:49<00:00, 11.29s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for sentence in tqdm(df['multisentence']):\n",
    "    #each_question = {}\n",
    "    #for key, question in questions.items():\n",
    "    #    each_question[str(key)] = stripJSON(prompt(SINGLEPROMPT.format(input = sentence, question = question))).get('explanation')\n",
    "    results.append(prompt(MULTIPROMPT.format(input = sentence)))\n",
    "df['mcllm_gpt_booleans'] = results\n",
    "new_path = urop_path + f\"_{MODEL}_response_{datetime.now()}.csv\"\n",
    "df.to_csv(new_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{None, 'background', 'uses'}\n",
      "we report the setting with the best performance for each baseline. our implementation of per-token cql is identical to ilql with the only exception being that for per-token cql the loss function is defined as:\n",
      "\n",
      "\\[l_{q,v}(\\theta)=\\mathbf{e}_{\\tau\\sim d}\\left[\\sum_{i=0}^{t}(r(h_{i},a_{i})+ \\gamma\\max_{a_{t+1}\\in\\mathcal{a}}q_{\\hat{\\theta}}(h_{i+1},a_{t+1})-q_{\\theta }(h_{i},a_{i}))^{2}\\right]\\]\n",
      "\n",
      "our implementation of \\(\\psi\\)-learning is adapted from jaques et al (jaques et al, 2020, 2017) for use on transformer language models (vaswani et al, 2017; <cite>radford et al, 2019</cite>) instead of rnns (gers et al, 2000). the architecture is identical to that of ilql, the main difference is in the loss function:\n",
      "\n",
      "\\[l_{q,v}(\\theta)=\\mathbf{e}_{\\tau\\sim d}\\left[\\sum_{i=0}^{t}l_{\\delta}(\\frac{ r(h_{i},a_{i})}{c}+\\log(\\pi_{\\beta}(h_{i},a_{i}))+\\gamma\\log(\\sum_{a_{t+1} \\in\\mathcal{a}}\\exp q_{\\hat{\\theta}}(h_{i+1},a_{t+1}))-q_{\\theta}(h_{i},a_{i }))\\right]\\]\n",
      "\n",
      "where \\(\\pi_{\\beta}\\) is our bc baseline model: a transformer language model trained with supervised learning.\n",
      "None\n",
      "```json\n",
      "{\n",
      "    \"explanation_1\": \"The sentences do not explicitly mention results from the CITED paper to support background claims.\",\n",
      "    \"confirmation_1\": \"True\",\n",
      "    \"answer_1\": \"False\",\n",
      "    \n",
      "    \"explanation_2\": \"The sentences mention that the implementation of \\(\\psi\\)-learning is adapted from the CITED paper for use on transformer language models.\",\n",
      "    \"confirmation_2\": \"True\",\n",
      "    \"answer_2\": \"True\",\n",
      "    \n",
      "    \"explanation_3\": \"The sentences do not mention performance results of the CITED paper to contextualize the CITED model's capabilities.\",\n",
      "    \"confirmation_3\": \"True\",\n",
      "    \"answer_3\": \"False\",\n",
      "    \n",
      "    \"explanation_4\": \"The sentences do not mention deploying the CITED foundation model's encoder or decoder as part of their methodology.\",\n",
      "    \"confirmation_4\": \"True\",\n",
      "    \"answer_4\": \"False\",\n",
      "    \n",
      "    \"explanation_5\": \"The sentences do not mention using the CITED foundation model to create embeddings as part of their methodology.\",\n",
      "    \"confirmation_5\": \"True\",\n",
      "    \"answer_5\": \"False\",\n",
      "    \n",
      "    \"explanation_6\": \"The sentences do not explicitly describe fine-tuning or adjusting the parameter weights of the CITED foundation model.\",\n",
      "    \"confirmation_6\": \"True\",\n",
      "    \"answer_6\": \"False\",\n",
      "    \n",
      "    \"explanation_7\": \"The sentences describe adopting the CITED foundation model's architecture (transformer language models) as part of their model design.\",\n",
      "    \"confirmation_7\": \"True\",\n",
      "    \"answer_7\": \"True\",\n",
      "    \n",
      "    \"explanation_8\": \"The sentences do not describe training a model using the CITED paper's dataset.\",\n",
      "    \"confirmation_8\": \"True\",\n",
      "    \"answer_8\": \"False\",\n",
      "    \n",
      "    \"explanation_9\": \"The sentences do not mention using the CITED foundation model for feature extraction as part of their methodology.\",\n",
      "    \"confirmation_9\": \"True\",\n",
      "    \"answer_9\": \"False\",\n",
      "    \n",
      "    \"explanation_10\": \"The sentences do not mention using the CITED foundation model as a classifier as part of their methodology.\",\n",
      "    \"confirmation_10\": \"True\",\n",
      "    \"answer_10\": \"False\",\n",
      "    \n",
      "    \"explanation_11\": \"The sentences do not describe deploying the CITED foundation model to generate data in the form of text/image/audio/video for later training of their model.\",\n",
      "    \"confirmation_11\": \"True\",\n",
      "    \"answer_11\": \"False\"\n",
      "}\n",
      "```\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_truth(r):\n",
    "    if isinstance(r, str):\n",
    "        r = stripJSON(r)\n",
    "        \n",
    "    if r is None:\n",
    "        return None\n",
    "    \n",
    "\n",
    "    for key, item in r.items():\n",
    "        if key == 'error':\n",
    "            return None\n",
    "        r[key] = {'true': True, 'false': False, None: False}.get(item if not isinstance(item, str) else item.lower())\n",
    "    \n",
    "    uses = np.array([r.get(f\"answer_{i}\") for i in range(4, 7)] + [r.get(f\"answer_{i}\") for i in range(9, 12)] ).astype(bool).sum()\n",
    "    background = np.array([r.get(f\"answer_{i}\") for i in range(1, 4)]).astype(bool).sum()\n",
    "    not_uses = np.array([r.get(f\"answer_{i}\") for i in range(7, 9)]).astype(bool).sum()\n",
    "\n",
    "    \n",
    "    if background >= 2: # or not_uses > 0:\n",
    "        return 'background'\n",
    "\n",
    "    if uses > 0:\n",
    "        return 'uses'\n",
    "    \n",
    "    if background:\n",
    "        return 'background'\n",
    "\n",
    "    return 'background'\n",
    "\n",
    "df['mcllm_binary'] = df['mcllm_gpt_booleans'].apply(get_truth)\n",
    "\n",
    "print(set(df['mcllm_binary']))\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if (row['mcllm_binary'] is None):\n",
    "        print(row['multisentence'])\n",
    "        print(row['mcllm_binary'])\n",
    "        print(row['mcllm_gpt_booleans'])\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mcllm_binary'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df[\\'mcllm_binary_stripped\\'] = df[\\'mcllm_binary\\'].apply(lambda s: tuple(v.lstrip(\"(\\'\").rstrip(\"\\')\") for v in s.split(\",\"))[0])\\ndf[\\'mcllm_binary_stripped\\']\\ndf = df[df[\\'mcllm_binary_stripped\\'] != \\'unclear\\']\\nx_label = \\'mcllm_binary_stripped\\''"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_label, x_label = 'alex2', 'mcllm_binary'\n",
    "df = df[~df[y_label].isna() & ~df[x_label].isna()]\n",
    "\n",
    "\n",
    "\n",
    "#df['urop'] = df['urop'].apply(str.lower)\n",
    "#df = df[df['urop'] != 'select']\n",
    "\n",
    "\"\"\"df['mcllm_binary_stripped'] = df['mcllm_binary'].apply(lambda s: tuple(v.lstrip(\"('\").rstrip(\"')\") for v in s.split(\",\"))[0])\n",
    "df['mcllm_binary_stripped']\n",
    "df = df[df['mcllm_binary_stripped'] != 'unclear']\n",
    "x_label = 'mcllm_binary_stripped'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "seed = 1\n",
    "train_size = 150\n",
    "true = np.random.RandomState(seed=seed).permutation(df[y_label])[:train_size]\n",
    "pred = np.random.RandomState(seed=seed).permutation(df[x_label])[:train_size]\n",
    "\n",
    "\n",
    "mapping = lambda s: {'background': 'context',\n",
    "                     'future_work': 'context',\n",
    "                    'differences': 'context',\n",
    "                     'future work': 'context',\n",
    "                     'motivation': 'context',\n",
    "                     'similarities': 'context',\n",
    "                     'extends': 'uses',\n",
    "                     '*': 'context'\n",
    "                     }.get(s) or s\n",
    "true, pred = list(map(mapping, true)), list(map(mapping, pred))\n",
    "\n",
    "cm = confusion_matrix(true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uses', 'context'} {'uses', 'context'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(50.722222222222214, 0.5, 'alex2')"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#assert(len(set(true)) == 3), set(true)\n",
    "#assert(len(set(pred)) == 3), set(pred)\n",
    "#labels = ['context', 'extends', 'uses']\n",
    "print(set(true), set(pred))\n",
    "\n",
    "labels = ['context', 'uses']\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(x_label)\n",
    "plt.ylabel(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18181818 0.2       ]\n",
      "[0.08163265 0.38461538]\n"
     ]
    }
   ],
   "source": [
    "false_positives = (cm - cm * np.identity(len(labels))).sum(axis = 0)/cm.sum(axis = 0)\n",
    "false_negatives = (cm - cm * np.identity(len(labels))).sum(axis = 1)/cm.sum(axis = 1)\n",
    "\n",
    "print(false_positives)\n",
    "print(false_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "def get_examples(y_value, x_value):\n",
    "    mask = (df[y_label].apply(mapping) == y_value) & (df[x_label].apply(mapping) == x_value) \n",
    "    return df[mask]\n",
    "\n",
    "def format_as_questions(s):\n",
    "    L = list(questions.items())\n",
    "    L.reverse()\n",
    "    for key, value in L:\n",
    "        s = s.replace(f\"answer_{key}\", value)\n",
    "    return s\n",
    "\n",
    "idx = -1\n",
    "samples = get_examples(y_value='uses', x_value = 'context')\n",
    "print(len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 93\n",
      "Drawing from 26 samples\n",
      "529_chinchilla\n",
      "to prevent participants from intentionally or unintentionally selecting examples in a way that overfit to the quirks of a specific model series, we also ran evaluations on several private model series, to check that inverse scaling was also present on held-out models. private models were provided by anthropic (models trained in bai et al, 2022)2 and deepmind (gopher: rae et al, 2021, and chinchilla: <cite>hoffmann et al, 2022</cite>). for deepmind models, we report performance at each model size.\n",
      "```json\n",
      "{\n",
      "    \"explanation_1\": \"The sentence mentions results from the CITED paper by stating the performance of the DeepMind models (Gopher and Chinchilla) in the context of inverse scaling.\",\n",
      "    \"confirmation_1\": \"True\",\n",
      "    \"answer_1\": \"True\",\n",
      "    \n",
      "    \"explanation_2\": \"The sentence does not explicitly mention any techniques from the CITED paper. It only mentions the performance results of the models.\",\n",
      "    \"confirmation_2\": \"True\",\n",
      "    \"answer_2\": \"False\",\n",
      "    \n",
      "    \"explanation_3\": \"The sentence explicitly mentions the performance results of the CITED paper's models (Gopher and Chinchilla) to contextualize their capabilities.\",\n",
      "    \"confirmation_3\": \"True\",\n",
      "    \"answer_3\": \"True\",\n",
      "    \n",
      "    \"explanation_4\": \"The sentence does not mention deploying the encoder or decoder of the CITED foundation model.\",\n",
      "    \"confirmation_4\": \"True\",\n",
      "    \"answer_4\": \"False\",\n",
      "    \n",
      "    \"explanation_5\": \"The sentence does not mention using the CITED foundation model to create embeddings.\",\n",
      "    \"confirmation_5\": \"True\",\n",
      "    \"answer_5\": \"False\",\n",
      "    \n",
      "    \"explanation_6\": \"The sentence does not describe any methodology involving fine-tuning or adjusting the parameter weights of the CITED foundation model.\",\n",
      "    \"confirmation_6\": \"True\",\n",
      "    \"answer_6\": \"False\",\n",
      "    \n",
      "    \"explanation_7\": \"The sentence does not describe adopting the CITED foundation model's architecture as part of their model design.\",\n",
      "    \"confirmation_7\": \"True\",\n",
      "    \"answer_7\": \"False\",\n",
      "    \n",
      "    \"explanation_8\": \"The sentence does not describe training a model using the CITED paper's dataset.\",\n",
      "    \"confirmation_8\": \"True\",\n",
      "    \"answer_8\": \"False\",\n",
      "    \n",
      "    \"explanation_9\": \"The sentence does not mention using the CITED foundation model for feature extraction.\",\n",
      "    \"confirmation_9\": \"True\",\n",
      "    \"answer_9\": \"False\",\n",
      "    \n",
      "    \"explanation_10\": \"The sentence does not mention using the CITED foundation model as a classifier.\",\n",
      "    \"confirmation_10\": \"True\",\n",
      "    \"answer_10\": \"False\",\n",
      "    \n",
      "    \"explanation_11\": \"The sentence does not describe deploying the CITED foundation model to generate data in any form.\",\n",
      "    \"confirmation_11\": \"True\",\n",
      "    \"answer_11\": \"False\"\n",
      "}\n",
      "```\n",
      "uses\n",
      "background\n"
     ]
    }
   ],
   "source": [
    "idx += 1\n",
    "index = samples.index[idx]\n",
    "print(idx, index)\n",
    "print(f\"Drawing from {len(samples)} samples\")\n",
    "print(samples['modelKey'].iloc[idx])\n",
    "\n",
    "print(samples['multisentence'].iloc[idx])\n",
    "print(samples['mcllm_gpt_booleans'].iloc[idx])\n",
    "print(samples[y_label].iloc[idx])\n",
    "print(samples[x_label].iloc[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the tweets were annotated manually into abusive, offensive, hate, vulgar, and violence. different machine learning methods were used such as svm with character n-gram and word n-gram, arabert [35], multilingual bert <cite>[36]</cite>, xlm-roberta [37] and qarib [38]. the results show that monolingual models such as arabert outperformed the multilingual models for detecting offensive and hate speech language with 92% accuracy and 80% f1-score.\n"
     ]
    }
   ],
   "source": [
    "og_path = '/home/gridsan/afogelson/osfm/scripts/urop_samples/uniform_sample/uniform_urop_sample_alex_labeled.csv'\n",
    "df_temp = pd.read_csv(og_path)\n",
    "assert(df_temp['multisentence'].loc[index] == df['multisentence'].loc[index])\n",
    "print(df_temp['multisentence'].loc[index])\n",
    "reclass = input()\n",
    "\n",
    "if (len(reclass) > 0):\n",
    "    df_temp['alex2'].loc[index] = reclass\n",
    "    df_temp.to_csv(og_path, index = False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'uses'"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mcllm_binary'].loc[189]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated 0 labels in /home/gridsan/afogelson/osfm/scripts/urop_samples/uniform_sample/uniform_urop_sample_alex_labeled_gpt4o_response_2024-06-18 13:20:23.603635.csv.\n",
      "Saving to original path.\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
