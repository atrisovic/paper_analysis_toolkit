{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import regex as re\n",
    "from collections import Counter\n",
    "from utils import prompt, update_labels, master_path, get_answer_vector, stripJSON\n",
    "import json\n",
    "\n",
    "CONNECTION_ON = True\n",
    "MODEL = 'ollama'    # 'gpt-4o' 'ollama' 'gpt-3.5-turbo' \n",
    "right_now = datetime.now().replace(microsecond=0, second=0)\n",
    "label_col = 'json_response'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Prompt and Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following sentences are from an academic paper (the CITING paper) which references a pretrained machine learning model through citation (the CITED paper). The models are called foundation models, and they might be a language model, a vision model, or any other kind of large neural network. The CITED paper is highlighed using HTML tags as such: <cite> cited reference </cite>. All other foundation models can be ignored, as we only care about the model cited with these tags. If it's helpful, the model identifier of the CITED model is key. \n",
      "\n",
      "We'd like to discern how the CITING paper makes use of the foundation model, as described within the sentences. The following statement is to be evaluated as either true or false.\n",
      "Question!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "We want to be judicious and avoid guessing. The authors must explicitly mention the behavior in question specifically in relation to the CITED model with model identifier key. Use only this JSON format in your response: {\"answer\": \"True | False\"}, based on the following:\n",
      "\n",
      "\"SENTENCE HERE\"\n"
     ]
    }
   ],
   "source": [
    "question_list = [\n",
    "    \"The CITING sentences mention results from the CITED paper to support background claims.\",\n",
    "    \"The CITING sentences mention a technique of the CITED paper in order to provide relevant background context.\",\n",
    "    \"The CITING sentences mention performance results of the CITED paper to contextualize the CITED model's capabilities.\",\n",
    "    \"The CITING authors describe other researchers using the CITED foundation models.\",\n",
    "    \"The CITING authors use the CITED foundation models to note a similarity or difference to an existing method.\",\n",
    "    \"It's ambiguous as to whether or not the CITING authors actually use the CITED foundation model based on the wording.\",\n",
    "    \"The CITING authors deploy the CITED foundation model's encoder or decoder as part of their methodology.\",\n",
    "    \"The CITING authors use the CITED foundation model to create embeddings as part of their methodology.\",\n",
    "    \"The CITING authors use the CITED foundation model for feature extraction as part of their methodology.\",\n",
    "    \"The CITING authors use the CITED foundation model as a classifier or detector as part of their methodology.\",\n",
    "    \"The CITING authors deploy the CITED foundation model to generate data in the form of text/image/audio/video for later training of their model.\",\n",
    "    \"The CITING authors perform their own evaluation on the CITED foundation model.\",\n",
    "    \"The CITING authors perform an ablation study on the CITED foundation model.\",\n",
    "    \"The CITING authors clearly deploy the CITED foundation model at some point throughout their methodology.\",\n",
    "    \"It's unclear whether or not the CITING authors perform any training on the CITED foundation model.\",\n",
    "    \"The CITING authors deploy fine-tuning or adjusting the parameter weights of the CITED foundation model.\",\n",
    "    \"The CITING authors pre-train or train-from-scratch the CITED model as part of their methodology.\",\n",
    "    \"The CITING authors mention fine-tuning the CITED foundation model as a possibility, but do not mention fine-tuning themselves.\",\n",
    "    \"The CITING authors train a model using the CITED paper's dataset.\",\n",
    "    \"The CITING authors adopt the CITED foundation model's architecture as part of their model design.\",\n",
    "    \"The CITING authors use the CITED foundation model to perform transfer learning.\",\n",
    "    \"The CITING authors use the CITED foundation model as a benchmark for comparison.\",\n",
    "    \"The CITING authors report improvements achieved by using the CITED foundation model over other models.\",\n",
    "    \"The CITING authors integrate the CITED foundation model with other models or algorithms.\",\n",
    "    \"The CITING authors use the CITED foundation model to validate a hypothesis or experimental setup.\",\n",
    "    \"The CITING authors conduct a qualitative analysis involving the CITED foundation model.\",\n",
    "    \"The CITING authors conduct a quantitative analysis involving the CITED foundation model.\",\n",
    "    \"The CITING authors highlight limitations or challenges of using the CITED foundation model.\",\n",
    "    \"The CITING authors discuss future work or potential extensions involving the CITED foundation model.\",\n",
    "    \"The CITING authors leverage the CITED foundation model for a specific application domain (e.g., healthcare, finance, NLP).\",\n",
    "    \"The CITING authors mention modifications or adaptations made to the CITED foundation model.\",\n",
    "    \"The CITING authors deploy the CITED foundation model in a real-world scenario or experiment.\",\n",
    "    \"The CITING authors use the CITED foundation model to perform anomaly detection.\",\n",
    "    \"The CITING authors use the CITED foundation model to perform sentiment analysis.\",\n",
    "    \"The CITING authors use the CITED foundation model for unsupervised learning tasks.\",\n",
    "    \"The CITING authors use the CITED foundation model for supervised learning tasks.\",\n",
    "    \"The CITING authors use the CITED foundation model for reinforcement learning tasks.\",\n",
    "    \"The CITING authors use the CITED foundation model to process multi-modal data.\",\n",
    "    \"The CITING authors use the CITED foundation model to enhance interpretability or explainability of their results.\",\n",
    "    \"The CITING authors employ the CITED foundation model to optimize hyperparameters in their experiments.\",\n",
    "    \"The CITING authors fine-tune the CITED foundation model on a domain-specific dataset.\",\n",
    "    \"The CITING authors mention using a smaller learning rate specifically for fine-tuning the CITED foundation model.\",\n",
    "    \"The CITING authors use the CITED foundation model's pre-trained weights as initialization for their own model.\",\n",
    "    \"The CITING authors employ transfer learning techniques involving the CITED foundation model.\",\n",
    "    \"The CITING authors use the CITED foundation model to pre-train a model before fine-tuning on a specific task.\",\n",
    "    \"The CITING authors report using a specific dataset for fine-tuning the CITED foundation model.\",\n",
    "    \"The CITING authors mention the number of epochs or iterations used for fine-tuning the CITED foundation model.\",\n",
    "    \"The CITING authors discuss the computational resources needed for fine-tuning the CITED foundation model.\",\n",
    "    \"The CITING authors mention specific hyperparameters adjusted during the fine-tuning of the CITED foundation model.\",\n",
    "    \"The CITING authors compare results between pre-trained and fine-tuned versions of the CITED foundation model.\",\n",
    "    \"The CITING authors mention the use of regularization techniques during the fine-tuning of the CITED foundation model.\",\n",
    "    \"The CITING authors evaluate the CITED foundation model's performance before and after fine-tuning.\",\n",
    "    \"The CITING authors describe modifying the architecture of the CITED foundation model prior to fine-tuning.\",\n",
    "    \"The CITING authors report the impact of fine-tuning on the CITED foundation model's generalization ability.\",\n",
    "    \"The CITING authors use the CITED foundation model in a semi-supervised learning framework involving fine-tuning.\",\n",
    "    \"The CITING authors discuss challenges faced during the fine-tuning of the CITED foundation model.\",\n",
    "    \"The CITING authors use data augmentation techniques in conjunction with fine-tuning the CITED foundation model.\",\n",
    "    \"The CITING authors mention training the CITED foundation model on a multi-task learning setup.\",\n",
    "    \"The CITING authors use the CITED foundation model to initialize another model which is then fine-tuned.\",\n",
    "    \"The CITING authors highlight improvements in task performance due to fine-tuning the CITED foundation model.\"\n",
    "][:20]\n",
    "questions = {i+1: question for i, question in enumerate(question_list + question_list)}\n",
    "\n",
    "\n",
    "#section_lengths = [5,8,4,2]\n",
    "#assert(sum(section_lengths) == len(questions))\n",
    "\n",
    "questions_as_string = '\\n'.join([f\"{key}. {value}\" for key, value in questions.items()])\n",
    "\n",
    "GENERIC_PROMPT = (\"\"\"The following sentences are from an academic paper (the CITING paper) which references a pretrained machine learning model through citation (the CITED paper). The models are called foundation models, and they might be a language model, a vision model, or any other kind of large neural network. The CITED paper is highlighed using HTML tags as such: <cite> cited reference </cite>. All other foundation models can be ignored, as we only care about the model cited with these tags. If it's helpful, the model identifier of the CITED model is {{modelKey}}. \n",
    "\n",
    "We'd like to discern how the CITING paper makes use of the foundation model, as described within the sentences. {question_statement}\n",
    "\n",
    "\\n\n",
    "We want to be judicious and avoid guessing. The authors must explicitly mention the behavior in question specifically in relation to the CITED model with model identifier {{modelKey}}. Use only this JSON format in your response: {json_format}, based on the following:\\n\\n\\\"{{input}}\\\"\"\"\" )\n",
    "\n",
    "MULTIPROMPT = GENERIC_PROMPT.format(question_statement = \"Below are a set of statements which will be evaluated as either true or false.\\n\" + questions_as_string +\n",
    "                                    \"\"\"\\nPlease respond with the following information per question: \\n(a) Provide a direct quote from the sentences which includes the <cite> cited model </cited> and helps answer the question. \\n(b) Explain clearly how the sentence answers the question. \\n(c) The final answer to the question (True or False, of null if unsure)\"\"\",\n",
    "                                    json_format = '''{{\"quote_1\": \"Quotation from the sentences with the cited model\", \n",
    "                                                        \"explanation_1\": \"Information relevant to the first question...\", \n",
    "                                                        \"answer_1\": \"True | False\", \n",
    "                                                        \"quote_2\": \"Quotation from the sentences with the cited model\", \n",
    "                                                        \"explanation_2\": \"Information relevant to the second question...\" , \n",
    "                                                        \"answer_2\": \"True | False\", ... }}''')\n",
    "SINGLEPROMPT = GENERIC_PROMPT.format(question_statement = \"The following statement is to be evaluated as either true or false.\\n{question}\\n\",\n",
    "                                     json_format = '{{\"answer\": \"True | False\"}}')\n",
    "\n",
    "print(SINGLEPROMPT.format(input = \"SENTENCE HERE\", modelKey = \"key\", question = \"Question!\"))\n",
    "#print(MULTIPROMPT.format(input = \"SENTENCE HERE\", modelKey = \"key\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_all(multisentence, modelKey):\n",
    "    return prompt(\n",
    "            MULTIPROMPT.format(input = multisentence, modelKey = modelKey),\n",
    "            model = MODEL,  \n",
    "            connection_on = CONNECTION_ON,                \n",
    "            temperature = 1)\n",
    "    \n",
    "def prompt_singles(multisentence, modelKey):\n",
    "    results = {}\n",
    "    for idx, question in questions.items():\n",
    "        string_answer = prompt(\n",
    "            SINGLEPROMPT.format(input = multisentence, modelKey = modelKey, question = question),\n",
    "            model = MODEL,  \n",
    "            connection_on = CONNECTION_ON,                \n",
    "            temperature = 1\n",
    "        )\n",
    "        as_json = stripJSON(string_answer)\n",
    "\n",
    "        if (as_json is None):\n",
    "            print(\"Got NULL result\")\n",
    "        results[f\"answer_{idx}\"] = False if as_json is None else as_json['answer']\n",
    "    \n",
    "    return json.dumps(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load existing or default dataframe, query LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "519\n"
     ]
    }
   ],
   "source": [
    "if CONNECTION_ON:\n",
    "    df = pd.read_csv(master_path + '.csv')\n",
    "else:\n",
    "    other_path = '~/Desktop/2. FutureTech/uniform_sample/results/uniform_base_sample_gpt-4o_prompt_2024-07-17 11:55:00.csv'\n",
    "    df = update_labels(other_path, save = True)\n",
    "\n",
    "df['modelKeyStriped'] = df['modelKey'].apply(lambda s: re.sub(r'^\\d+_', '', s))\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'background': 265,\n",
       "         'uses': 111,\n",
       "         'similarities': 77,\n",
       "         'extends': 38,\n",
       "         'differences': 13,\n",
       "         'motivation': 10,\n",
       "         '*': 4,\n",
       "         'future work': 1})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df['alex2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 256/519 [2:10:35<2:00:58, 27.60s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got NULL result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 309/519 [2:32:57<1:28:22, 25.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got NULL result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 519/519 [4:05:10<00:00, 28.34s/it]  \n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.expanduser((master_path + f\"_{MODEL}_prompt_{right_now}.txt\").replace('uniform_sample/raw/', 'uniform_sample/prompts/'))\n",
    "new_path = os.path.expanduser((master_path + f\"_{MODEL}_prompt_{right_now}.csv\").replace('uniform_sample/raw/', 'uniform_sample/results/'))\n",
    "\n",
    "with open(file_path, 'w') as f:\n",
    "    f.write(MULTIPROMPT)\n",
    "\n",
    "if (label_col) not in set(df.columns):\n",
    "    print(\"Resetting results\")\n",
    "    df[label_col] = [None for i in range(len(df))]\n",
    "\n",
    "for idx in tqdm(df.index):\n",
    "    if df[label_col].loc[idx] is not None:\n",
    "        continue\n",
    "\n",
    "    df[label_col].at[idx] = prompt_singles(df['multisentence'], df['modelKeyStriped'].loc[idx])\n",
    "\n",
    "\n",
    "if (CONNECTION_ON):\n",
    "    df.to_csv(new_path, index = False)\n",
    "    CONNECTION_ON = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>sentence</th>\n",
       "      <th>mcllm</th>\n",
       "      <th>modelKey</th>\n",
       "      <th>paperId</th>\n",
       "      <th>modelId_x</th>\n",
       "      <th>mc</th>\n",
       "      <th>modelId_y</th>\n",
       "      <th>mc_reduced</th>\n",
       "      <th>urop_sentence</th>\n",
       "      <th>...</th>\n",
       "      <th>classification_order</th>\n",
       "      <th>labels</th>\n",
       "      <th>modelTitle</th>\n",
       "      <th>modelId</th>\n",
       "      <th>modelYear</th>\n",
       "      <th>paperYear</th>\n",
       "      <th>pot_extends</th>\n",
       "      <th>prob_extends</th>\n",
       "      <th>modelKeyStriped</th>\n",
       "      <th>json_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>in recent years, many large-scale pre-trained ...</td>\n",
       "      <td>background</td>\n",
       "      <td>417_gpt-3_175b_(davinci)</td>\n",
       "      <td>d8d578d4ece329f17b025946587b1751721b9144</td>\n",
       "      <td>6b85b63579a916f705a8e10a49bd8d849d91b1fc</td>\n",
       "      <td>background</td>\n",
       "      <td>6b85b63579a916f705a8e10a49bd8d849d91b1fc</td>\n",
       "      <td>context</td>\n",
       "      <td>in recent years, many large-scale pre-trained ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gpt-3_175b_(davinci)</td>\n",
       "      <td>{\"answer_1\": \"False\", \"answer_2\": \"False\", \"an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>one of the known problems with contrastive tra...</td>\n",
       "      <td>background</td>\n",
       "      <td>1013_wave2vec_2.0_large</td>\n",
       "      <td>7f0c7c324675179f0e32c160d99c7066c7ab30ae</td>\n",
       "      <td>49a049dc85e2380dde80501a984878341dd8efdf</td>\n",
       "      <td>background</td>\n",
       "      <td>49a049dc85e2380dde80501a984878341dd8efdf</td>\n",
       "      <td>context</td>\n",
       "      <td>one of the known problems with contrastive tra...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wave2vec_2.0_large</td>\n",
       "      <td>{\"answer_1\": \"False\", \"answer_2\": \"False\", \"an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>further work in compound scaling yielded model...</td>\n",
       "      <td>background</td>\n",
       "      <td>377_efficientnet-l2</td>\n",
       "      <td>970cb7b5b25da0f1f8b000add10960680fe8cd2e</td>\n",
       "      <td>4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9</td>\n",
       "      <td>background</td>\n",
       "      <td>4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9</td>\n",
       "      <td>context</td>\n",
       "      <td>further work in compound scaling yielded model...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>efficientnet-l2</td>\n",
       "      <td>{\"answer_1\": \"False\", \"answer_2\": \"False\", \"an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>due to the high computing cost, conducting a t...</td>\n",
       "      <td>background</td>\n",
       "      <td>417_gpt-3_175b_(davinci)</td>\n",
       "      <td>b6ec1e8f18185b4b3d46201359a440404575460c</td>\n",
       "      <td>6b85b63579a916f705a8e10a49bd8d849d91b1fc</td>\n",
       "      <td>background</td>\n",
       "      <td>6b85b63579a916f705a8e10a49bd8d849d91b1fc</td>\n",
       "      <td>context</td>\n",
       "      <td>due to the high computing cost, conducting a t...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gpt-3_175b_(davinci)</td>\n",
       "      <td>{\"answer_1\": \"False\", \"answer_2\": \"False\", \"an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>##  1 introduction\\n\\n\\nthe multilingual bert ...</td>\n",
       "      <td>background</td>\n",
       "      <td>1064_bert-large</td>\n",
       "      <td>1234fcc1577a32b829d2886fdf68375b9d4525e9</td>\n",
       "      <td>df2b0e26d0599ce3e70df8a9da02e51594e0e992</td>\n",
       "      <td>background</td>\n",
       "      <td>df2b0e26d0599ce3e70df8a9da02e51594e0e992</td>\n",
       "      <td>context</td>\n",
       "      <td>##  1 introduction\\n\\nthe multilingual bert mo...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bert-large</td>\n",
       "      <td>{\"answer_1\": \"False\", \"answer_2\": \"True\", \"ans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1114_mask_r-cnn</td>\n",
       "      <td>3c6321c030b656f6735c0b0239a18b7f8d30f438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mask_r-cnn</td>\n",
       "      <td>{\"answer_1\": \"False\", \"answer_2\": \"False\", \"an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1114_mask_r-cnn</td>\n",
       "      <td>8960d8b422ed5c6cb895e07bd0b0a6377ca6be57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mask_r-cnn</td>\n",
       "      <td>{\"answer_1\": \"False\", \"answer_2\": \"False\", \"an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>516</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1158_yolox-x</td>\n",
       "      <td>13f1b60bbb44e0e33e3fab8e9c39077e2d918287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yolox-x</td>\n",
       "      <td>{\"answer_1\": \"False\", \"answer_2\": \"False\", \"an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1160_batchnorm</td>\n",
       "      <td>320f5f838b754df3b4d56562b2beee0b7e67a515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>batchnorm</td>\n",
       "      <td>{\"answer_1\": \"False\", \"answer_2\": \"False\", \"an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1164_impala</td>\n",
       "      <td>5fe4712d9abbb60f070028b89355966c1e2bc91a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>impala</td>\n",
       "      <td>{\"answer_1\": \"False\", \"answer_2\": \"True\", \"ans...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>519 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0.1                                           sentence  \\\n",
       "0               0  in recent years, many large-scale pre-trained ...   \n",
       "1               1  one of the known problems with contrastive tra...   \n",
       "2               2  further work in compound scaling yielded model...   \n",
       "3               3  due to the high computing cost, conducting a t...   \n",
       "4               4  ##  1 introduction\\n\\n\\nthe multilingual bert ...   \n",
       "..            ...                                                ...   \n",
       "514           514                                                NaN   \n",
       "515           515                                                NaN   \n",
       "516           516                                                NaN   \n",
       "517           517                                                NaN   \n",
       "518           518                                                NaN   \n",
       "\n",
       "          mcllm                  modelKey  \\\n",
       "0    background  417_gpt-3_175b_(davinci)   \n",
       "1    background   1013_wave2vec_2.0_large   \n",
       "2    background       377_efficientnet-l2   \n",
       "3    background  417_gpt-3_175b_(davinci)   \n",
       "4    background           1064_bert-large   \n",
       "..          ...                       ...   \n",
       "514         NaN           1114_mask_r-cnn   \n",
       "515         NaN           1114_mask_r-cnn   \n",
       "516         NaN              1158_yolox-x   \n",
       "517         NaN            1160_batchnorm   \n",
       "518         NaN               1164_impala   \n",
       "\n",
       "                                      paperId  \\\n",
       "0    d8d578d4ece329f17b025946587b1751721b9144   \n",
       "1    7f0c7c324675179f0e32c160d99c7066c7ab30ae   \n",
       "2    970cb7b5b25da0f1f8b000add10960680fe8cd2e   \n",
       "3    b6ec1e8f18185b4b3d46201359a440404575460c   \n",
       "4    1234fcc1577a32b829d2886fdf68375b9d4525e9   \n",
       "..                                        ...   \n",
       "514  3c6321c030b656f6735c0b0239a18b7f8d30f438   \n",
       "515  8960d8b422ed5c6cb895e07bd0b0a6377ca6be57   \n",
       "516  13f1b60bbb44e0e33e3fab8e9c39077e2d918287   \n",
       "517  320f5f838b754df3b4d56562b2beee0b7e67a515   \n",
       "518  5fe4712d9abbb60f070028b89355966c1e2bc91a   \n",
       "\n",
       "                                    modelId_x          mc  \\\n",
       "0    6b85b63579a916f705a8e10a49bd8d849d91b1fc  background   \n",
       "1    49a049dc85e2380dde80501a984878341dd8efdf  background   \n",
       "2    4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9  background   \n",
       "3    6b85b63579a916f705a8e10a49bd8d849d91b1fc  background   \n",
       "4    df2b0e26d0599ce3e70df8a9da02e51594e0e992  background   \n",
       "..                                        ...         ...   \n",
       "514                                       NaN         NaN   \n",
       "515                                       NaN         NaN   \n",
       "516                                       NaN         NaN   \n",
       "517                                       NaN         NaN   \n",
       "518                                       NaN         NaN   \n",
       "\n",
       "                                    modelId_y mc_reduced  \\\n",
       "0    6b85b63579a916f705a8e10a49bd8d849d91b1fc    context   \n",
       "1    49a049dc85e2380dde80501a984878341dd8efdf    context   \n",
       "2    4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9    context   \n",
       "3    6b85b63579a916f705a8e10a49bd8d849d91b1fc    context   \n",
       "4    df2b0e26d0599ce3e70df8a9da02e51594e0e992    context   \n",
       "..                                        ...        ...   \n",
       "514                                       NaN        NaN   \n",
       "515                                       NaN        NaN   \n",
       "516                                       NaN        NaN   \n",
       "517                                       NaN        NaN   \n",
       "518                                       NaN        NaN   \n",
       "\n",
       "                                         urop_sentence  ...  \\\n",
       "0    in recent years, many large-scale pre-trained ...  ...   \n",
       "1    one of the known problems with contrastive tra...  ...   \n",
       "2    further work in compound scaling yielded model...  ...   \n",
       "3    due to the high computing cost, conducting a t...  ...   \n",
       "4    ##  1 introduction\\n\\nthe multilingual bert mo...  ...   \n",
       "..                                                 ...  ...   \n",
       "514                                                NaN  ...   \n",
       "515                                                NaN  ...   \n",
       "516                                                NaN  ...   \n",
       "517                                                NaN  ...   \n",
       "518                                                NaN  ...   \n",
       "\n",
       "    classification_order labels modelTitle modelId modelYear paperYear  \\\n",
       "0                    NaN    NaN        NaN     NaN       NaN       NaN   \n",
       "1                    NaN    NaN        NaN     NaN       NaN       NaN   \n",
       "2                    NaN    NaN        NaN     NaN       NaN       NaN   \n",
       "3                    NaN    NaN        NaN     NaN       NaN       NaN   \n",
       "4                    NaN    NaN        NaN     NaN       NaN       NaN   \n",
       "..                   ...    ...        ...     ...       ...       ...   \n",
       "514                  NaN    NaN        NaN     NaN       NaN       NaN   \n",
       "515                  NaN    NaN        NaN     NaN       NaN       NaN   \n",
       "516                  NaN    NaN        NaN     NaN       NaN       NaN   \n",
       "517                  NaN    NaN        NaN     NaN       NaN       NaN   \n",
       "518                  NaN    NaN        NaN     NaN       NaN       NaN   \n",
       "\n",
       "    pot_extends prob_extends       modelKeyStriped  \\\n",
       "0           NaN          NaN  gpt-3_175b_(davinci)   \n",
       "1           NaN          NaN    wave2vec_2.0_large   \n",
       "2           NaN          NaN       efficientnet-l2   \n",
       "3           NaN          NaN  gpt-3_175b_(davinci)   \n",
       "4           NaN          NaN            bert-large   \n",
       "..          ...          ...                   ...   \n",
       "514         NaN          NaN            mask_r-cnn   \n",
       "515         NaN          NaN            mask_r-cnn   \n",
       "516         NaN          NaN               yolox-x   \n",
       "517         NaN          NaN             batchnorm   \n",
       "518         NaN          NaN                impala   \n",
       "\n",
       "                                         json_response  \n",
       "0    {\"answer_1\": \"False\", \"answer_2\": \"False\", \"an...  \n",
       "1    {\"answer_1\": \"False\", \"answer_2\": \"False\", \"an...  \n",
       "2    {\"answer_1\": \"False\", \"answer_2\": \"False\", \"an...  \n",
       "3    {\"answer_1\": \"False\", \"answer_2\": \"False\", \"an...  \n",
       "4    {\"answer_1\": \"False\", \"answer_2\": \"True\", \"ans...  \n",
       "..                                                 ...  \n",
       "514  {\"answer_1\": \"False\", \"answer_2\": \"False\", \"an...  \n",
       "515  {\"answer_1\": \"False\", \"answer_2\": \"False\", \"an...  \n",
       "516  {\"answer_1\": \"False\", \"answer_2\": \"False\", \"an...  \n",
       "517  {\"answer_1\": \"False\", \"answer_2\": \"False\", \"an...  \n",
       "518  {\"answer_1\": \"False\", \"answer_2\": \"True\", \"ans...  \n",
       "\n",
       "[519 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (CONNECTION_ON):\n",
    "    print(f\"Saving to {new_path}\")\n",
    "    df.to_csv(new_path, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
