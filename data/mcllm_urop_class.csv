,model.name,model.title,citation.openAccessPdf,manual,Secondary use of the <model.name> (if applicable),Citation Sentence,Does the paper introduce a new model?,"If yes, what is the name of the model? (not named is fine)",Does the paper use AI model?,"If yes, which model it is using?",Notes,MCLLM,MC
1,MobileNet,MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications,https://www.frontiersin.org/articles/10.3389/fpls.2023.1308528/pdf?isPublishedV2=False,Uses,,Depthwise separable convolutions boosted computational efficiency in MobileNetV1 Howard et al. (2017). MobileNetV2 added a resource-efficient block with inverted residuals and linear bottlenecks to improve efficiency Howard et al. (2018).,No,,Yes,,Good example how models detect plant disease in agricultural applications.,background,background
3,Robot Parkour,Robot Parkour Learning,https://arxiv.org/pdf/2310.04828,Background,,"Recent advancements in reinforcement learning (RL) and optimal control have empowered quadrupedal robots to per- form a series of dynamic tasks, such as navigating diverse terrains in the wild [1], [2], [3], achieving high-speed run- ning [4], [5], engaging in parkour [6], executing jumps [7], and standing up on hind legs [8], [9].",Yes,,Yes,,,background,background
4,ReLU (NORB),Rectified Linear Units Improve Restricted Boltzmann Machines,https://arxiv.org/pdf/2308.16316,Background,,"However, DM-GAN’s computational complexity and memory management pose challenges, and it relies on labeled data [154], [155].",Yes,,Yes,,,motivation,motivation
5,ERNIE 3.0,ERNIE 3.0: Large-scale Knowledge Enhanced Pre-training for Language Understanding and Generation,https://arxiv.org/pdf/2211.05994,Background,,Incorporating knowledge into PLMs can empower their memorization and reasoning [10].,No,,No,,,background,background
6,,,,Background,,ERNIE [62] proposes a multi-stage knowledge masking strategy of both entity level and phase level.,,,,,,background,background
7,ContextNet,ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context,https://arxiv.org/pdf/2210.15781,Extends,,"TitaNet-LID-BxRxC consists of an encoder which is a 1D depth-wise channel separable convolutional model with a ContextNet-like [20, 23] architecture and a decoder.",Yes,,Yes,,,background,background
8,,,,Background,,"Among several proposed methods [15, 18, 19, 20], ContextNet, proposed by [20], builds upon previous work [21] and incorporates a Squeeze-and-Excitation (SE) layer [22] to compress a sequence of local feature vectors into a single global context vector.",,,,,,background,background
9,,,,Background,,"In the ASR domain, [20] demonstrated that incorporating global context improved accuracy.",,,,,,background,background
16,Pluribus,Superhuman AI for multiplayer poker,https://ojs.aaai.org/index.php/AAAI/article/download/20431/20190,Background,,"Among these, the most successful examples include the CFR algorithm (Zinkevich et al. 2007) and its modern variants (Tammelin 2014; Moravcík et al. 2017; ˇ
Brown and Sandholm 2017b,a, 2019a,b; Davis, Waugh, and Bowling 2019; Farina, Kroer, and Sandholm 2021b; Morrill et al. 2021), and methods based on accelerated firstorder methods such as EGT (Nesterov 2005; Hoda et al. 2010; Kroer, Farina, and Sandholm 2018; Farina, Kroer, and Sandholm 2021a) and Mirror Prox (Nemirovski 2004; Kroer
2019; Farina, Kroer, and Sandholm 2021a), which are able to scale to large two-player extensive-form games and compute approximate Nash equilibria for moderate approximation gaps.",Yes,,Yes,,,background,background
17,,,,Background,,"Hundreds of papers have been published on it, the AAAI Annual Computer Poker Competition was organized, and superhuman AI performance has been achieved (Bowling et al. 2015; Brown and Sandholm 2017b, 2019b).",,,,,,background,background
21,ESM2-15B,Evolutionary-scale prediction of atomic level protein structure with a language model,https://www.biorxiv.org/content/biorxiv/early/2023/12/01/2023.11.30.569352.full.pdf,Uses,,"To achieve this, we first used ESM-2 8M (version 2 with 8 million 215 parameters) to generate the vectors for a set of genes",Yes,,Yes,,,uses,uses
23,LUKE,LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention,https://aclanthology.org/2021.eval4nlp-1.5.pdf,Background,,"We examined several papers with state of the art NER results on the CoNLL 2003 dataset considering guidelines 1, 2, and 3. Of these papers Liu et al. (2019) follow 1, 2, and 3. Yamada et al. (2020) explicitly follows guidelines 2 and 3. Luoma and Pyysalo (2020) met guideline 1.",No,,Yes,,,uses,uses
24,ALIGN,Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision,https://aclanthology.org/2023.emnlp-main.301.pdf,Background,,"Underlying several popular multimodal models like CLIP (Radford et al., 2021), DALL-E 2 (Ramesh et al., 2022) and ALIGN (Jia et al., 2021) is a pooled text encoder, i.e., a text representation model that outputs a single vector for a given input caption",No,,Yes,,,background,background
25,XLM,Cross-lingual Language Model Pretraining,https://aclanthology.org/2021.emnlp-main.685.pdf,Motivation,,"As different tasks have different dataset sizes, we follow Conneau and Lample (2019) to employ a balanced sampling strategy",Yes,CodeT5,Yes,CodeT5,An example to show how the paper uses a similar sampling method as the one used for the AI model,uses,uses
26,LSTM,Long Short-Term Memory,https://www.biorxiv.org/content/biorxiv/early/2024/01/25/2024.01.24.577123.full.pdf,Background,,"However, the journey is not without its challenges. Despite all recent successes, optimization remains a key concern for deep learning, and while innovations such as LSTMs (39), ResNet’s skipped-connections (40), reward shaping (41) and sensorimotor priors (42, 43) have made strides in addressing these challenges, the true potential of RL lies in its adaptability",Yes,SDS,Yes,SDS,Good example of using a previous AI model to develop a new model that finds motor control policies in complex object manipulation tasks.,motivation,motivation
27,,,,Motivation,,"We used the powerful onpolicy RL algorithm PPO (16) from the Stable Baselines 3 library (46) with a recurrent architecture that has LSTM layers (39) in both the actor and critic, which allowed us to deal with the partially observable environment (Fig.1).",,,,,,uses,uses
28,S4,Efficiently Modeling Long Sequences with Structured State Spaces,https://arxiv.org/pdf/2306.16524,Background,,"Earlier examples of SSM layers in deep learning model includes Structured State Space(S4) 31, its variants 32,33 and Gated State Space (GSS)34",Yes,Hyena,Yes,Hyena,,background,background
29,NLLB,No Language Left Behind: Scaling Human-Centered Machine Translation,https://aclanthology.org/2023.wmt-1.24.pdf,Background,,"However, it is worth noting that GPT4-5shot displayed subpar performance when applied to legal data, while NLLB_Greedy demonstrated comparatively lower performance in the context of environmental data.",No,,Yes,,Evaluation on different machine translation systems,differences,differences
30,Relational Memory Core,Relational recurrent neural networks,https://link.springer.com/content/pdf/10.1007/s10489-022-03550-z.pdf,Background,,"A variety of RL-related methods have been proposed to make RL feasible in large-scale applications. One approach is to augment the neural network with a “memory” to enhance sample efficiency in complicated environments [127, 128].",No,,No,,,background,background
31,Base LM + kNN LM + Continuous Cache,Generalization through Memorization: Nearest Neighbor Language Models,https://arxiv.org/pdf/2309.14928,Motivation,,"Inspired by the adapter idea in supervised methods [11, 20, 32, 52, 52], NtUA introduces weighted key-value cache which formulates the CLIP-extracted visual features as keys, the predicted pseudo-labels of target samples as values, and the corresponding pseudo-label confidence as weights of the key-value pairs as illustrated in Fig. 1.",Yes,NtUA,Yes,NtUA,,extends,uses
32,VGG19,Very Deep Convolutional Networks for Large-Scale Image Recognition,https://www.mdpi.com/1424-8220/24/1/89/pdf?version=1703323668,Differences,,"Unlike other common networks such as ResNet and VGGNet that encode images into low-resolution representations through a sequential arrangement of convolutional layers [41–43], HRNet adopts a parallel processing framework.",Yes,,,,,background,background
33,S-Norm,Simple and Effective Multi-Paragraph Reading Comprehension,https://www.aclweb.org/anthology/D19-5815.pdf,Background,,"Such findings indicate that there are certain shortcuts in solving reading comprehension tasks that allow a model to find the answer by superficial clues such as lexical overlap and entity types (Clark and Gardner, 2018; Sugawara et al., 2018)",No,,No,,,background,background
34,ProBERTa,Transforming the Language of Life: Transformer Neural Networks for Protein Prediction Tasks,https://www.biorxiv.org/content/biorxiv/early/2023/02/09/2023.02.03.526917.full.pdf,Background,,"There is growing interest in developing protein language models (pLMs) at the scale of evolution due to the abundance of 1D amino acid sequences, such as the series of ESM (Rives et al., 2019; Lin et al., 2022), TAPE (Rao et al., 2019), ProtTrans (Elnaggar et al., 2021), PRoBERTa (Nambiar et al., 2020), PMLM (He et al., 2021), ProteinLM (Xiao et al., 2021), PLUS (Min et al., 2021), Adversarial MLM (McDermott et al., 2021), ProteinBERT (Brandes et al., 2022), CARP (Yang et al., 2022a) in masked language modeling (MLM) fashion, ProtGPT2 (Ferruz et al., 2022) in causal language modeling fashion, and several others (Melnyk et al., 2022a; Madani et al., 2021; Unsal et al., 2022; Nourani et al., 2021; Lu et al., 2020; Sturmfels et al., 2020; Strodthoff et al., 2020).",Yes,LM-DESIGN,Yes,LM-DESIGN,,background,background
35,Heuristic problem solving for AI,Steps toward Artificial Intelligence,https://aclanthology.org/2022.trustnlp-1.1.pdf,Background,,"Attribution analysis, or credit assignment, concerns how individual components of a system contribute to its overall performance (Minsky, 1961).",Yes,,Yes,,,background,background
36,Switch,Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity,https://arxiv.org/pdf/2102.04906,Background,,"On NLP tasks, sparely gated MoE [16] and switch Transformer [81] embeds hard MoE in a long shortterm memory (LSTM) [82] network and a Transformer [6], respectively. y. Instead of making choice with binary gates as in [80], only the branches corresponding to the top-K elements of the real-valued gates are activated in [16], [78], [81].",No,,No,,,background,background
37,SemVec,Linguistic Regularities in Continuous Space Word Representations,http://arxiv.org/pdf/2210.02771,Uses,,"We test this approach for k = 1 and k = 3, using embeddings from GloVe (Pennington et al., 2014) and Skip-gram8 (Mikolov et al., 2013), and using the embeddings predicted by our BERT-base encoder pre-trained on MSCG+PREFIX+GKB.",Yes,,Yes,SemVec,use embeddings from the AI model to test new approach,uses,uses
38,Sandwich Transformer,Improving Transformer Models by Reordering their Sublayers,https://www.mdpi.com/2076-3417/12/9/4502/pdf?version=1651215512,Background,,"In [16], the sub-layers of the encoder and decoder in the Transformer, such as the self-attention and feed forward layers, were reordered to reduce the model’s perplexity and increase the model’s robustness. In this study, we also aim to improve the efficiency of the refined model and shorten the training time.",Yes,X-Transformer,Yes,X-Transformer,,differences,differences
39,,,,Similarities,,"Finally, we chose s-sf-sf as our proposed model because it has fewer model parameters, while the BLEU score is almost the same. A similar notion was also proposed in [16]. If the self-attention mechanism appears earlier in the model and stacks more than the number of feed forward layers, the perplexity of the language model can be much lower.",,,,,use a similiar idea in the AI model to improve a current model,similarities,similarities
40,Transformer (Adaptive Input Embeddings),Adaptive Input Representations for Neural Language Modeling,https://www.aclweb.org/anthology/D19-1539.pdf,Uses,,"We adapt the transformer implementation available in the fairseq toolkit to our two tower architecture (Ott et al., 2019). For hyper-parameter and optimization choices we mostly follow Baevski and Auli (2018).",Yes,,Yes,Transformer (Adaptive Input Embeddings),,uses,uses
41,MT-DNN,Multi-Task Deep Neural Networks for Natural Language Understanding,https://arxiv.org/pdf/2308.08234,Background,,"One such approach, MT-DNN (Liu et al., 2019b), batches all the GLUE tasks (Wang et al., 2018) together and updates the model accordingly.",Yes,CMTL,Yes,CMTL,,background,background
42,,,,Background,,"Two learning types were mainly discussed. First, joint learning was used in an MTL setting where all the tasks are equally important (Kendall et al., 2018; Liu et al., 2019b).",,,,,,background,background
43,Culturome,Quantitative Analysis of Culture Using Millions of Digitized Books,https://serval.unil.ch/resource/serval:BIB_9947DF4A7067.P001/REF.pdf,Background,,"But the larger and the more ‘complete’ a corpus is, the greater the danger to succumb to an ‘implicit essentialism’22 and to mistake the model for the original: it seems to contain ‘everything’, so it must be ‘true’ (something that can often be observed in the field of cultoromics,23 when arguments are being made on the basis of the Google Books Ngram Corpus).",No,,No,,,background,background
44,Regularized SVD for Collaborative Filtering,Improving regularized singular value decomposition for collaborative filtering,https://eprints.sztaki.hu/9319/1/Palovics_400_3311628_ny.pdf,Background,,"Alpenglow1 is a free and open source C++ based framework with easy-to-use Python API especially suited for conjoint batch and online learning. We experiment in Aplenglow with • non-personalized temporal popularity and item-to-item recommender models, • time-aware variants of nearest neighbor [9], • SGD based batch and online matrix factorization [10], • asymmetric matrix factorization [8].",No,,No,,,uses,uses
45,GSM,Gated Self-Matching Networks for Reading Comprehension and Question Answering,https://link.springer.com/content/pdf/10.1007/s44267-023-00010-1.pdf,Uses,,"The predicted relatedness R(xi, xj) is the average value of two related attention scores rij and rji: where WrQ and WrM are two learnable matrices for query and memory according to the query-memory attention mechanism [41].",Yes,,Yes,GSM,,background,background
46,MnasNet-A3,MnasNet: Platform-Aware Neural Architecture Search for Mobile,https://arxiv.org/pdf/2212.06524,Uses,,"Concretely, a lightweight MnasNet [24] is applied for image feature Ft,color extraction.",Yes,SST,Yes,MnasNet-A3,,uses,uses
47,Statistical Shape Constellations,Unsupervised Learning of Models for Recognition,https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0203897&type=printable,Background,,"In computer vision field, traditional methods [19–21] and deep learning based methods [22–28] are applied to solve the object detection problems",Yes,Enhanced Region Proposal Network (ERPN),Yes,Region Proposal Network (RPN),,background,background
48,PolyCoder,A systematic evaluation of large language models of code,http://arxiv.org/pdf/2305.19213,Background,,"Recently, large language models of code (Code-LLMs) are receiving increasing attention (Chen et al., 2021; Xu et al., 2022).",No,,Yes,"DAVINCI002, CODEX","compared to textonly LLMs, Code-LLMs with code prompts are significantly better in causal reasoning",background,background
49,EDSR,Enhanced Deep Residual Networks for Single Image Super-Resolution,https://arxiv.org/pdf/2211.06770,Background,,"The problem of image restoration and enhancement has been addressed in several papers, though many were dealing only with particular aspects such as super-resolution [4, 8, 21,24,29,32,35,44,45,52], denoising [1,2,11,15,43,53,54], color and tone mapping [36, 38, 49, 50], luminance, gamma and contrast adjustment [5, 10, 51].",Yes,MicroISP,Yes,MicroISP,,background,background
51,TransE,Translating Embeddings for Modeling Multi-relational Data,https://arxiv.org/pdf/2310.08917,Background,,"This technique involves transforming entities and relations into low-dimensional vectors and using a scoring function (Bordes et al., 2013; Wang et al., 2017) to assess the plausibility of a triplet (consisting of a head entity, a relation, and a tail entity).",Yes,RelEns-DSC,Yes,TransE,,background,background
52,,,,Background,,"Well-known scoring functions, such as TransE (Bordes et al., 2013), ComplEx (Trouillon et al., 2017), ConvE (Dettmers et al., 2018), and CompGCN (Vashishth et al., 2020), have demonstrated remarkable success in learning from KGs.",,,,,,background,background
53,,,,Motivation,,"Following (Bordes et al., 2013; Trouillon et al., 2017; Sun et al., 2019; Vashishth et al., 2020), we adopt mean reciprocal ranking (MRR) as the evaluation metric. Larger MRR indicates better performance",,,,,,uses,uses
54,,,,Uses,,"We select some representative embedding models as our base models Fi , including: (i) translational distance models TransE (Bordes et al., 2013), RotatE (Sun et al., 2019), HousE (Li et al., 2022); (ii) bilinear model ComplEx (Trouillon et al., 2017); (iii) neural network model ConvE (Dettmers et al., 2018); and (iv) GNN based model CompGCN (Vashishth et al., 2020)",,,,,,uses,uses
55,ResNeXt-50,Aggregated Residual Transformations for Deep Neural Networks,http://arxiv.org/pdf/2306.05401,Uses,,"Mean accuracy of different backbone architectures on CCC-Medium. Accuracy reported is an average across 9 runs. Backbones used: [3, 10, 23, 43, 51], †: AugMix [14], ‡: DeepAugment [11].",Yes,RDumb,Yes,ResNeXt-50,,uses,uses
56,ViT-G (model soup),Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time,http://arxiv.org/pdf/2301.10092,Background,Uses,The publication ”Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time” [1] proposes to average the weights of the different models to maximize the use of all the training without wasting learning time.,Yes,Pruned Soup,Yes,"Model Soups, ResNet, ViT, EfficientNet",first test the Model Souping (the AI model) and then introduce a new model based on the original AI model ,background,background
57,SmooCT,Self-play Monte-Carlo tree search in computer poker,https://ojs.aaai.org/index.php/AAAI/article/download/25661/25433,Background,,"Others used Monte Carlo simulation-based approaches (Schweizer et al. 2009; Broeck, Driessens, and Ramon 2009) including Monte Carlo Tree Search (Heinrich and Silver 2014), which is a very popular and successful technique in games in general (Swiechowski et al. 2023).","Yes, fine tuned",DEVN,Yes,Counterfactual Values (CFVs),,background,background
58,DeepNet,"DeepNet: Scaling Transformers to 1, 000 Layers",https://arxiv.org/pdf/2310.03724,Uses,Differences,"We compare our results to massively multilingual supervised models, M2M100 [20] and Deepnet [21].",Yes,,Yes,"M2M100, Deepnet, T-Modules","The source paper compares their model with the target paper, not sure if i catogrize it into the correct 'use' labels?",uses,uses
59,RBM Image Classifier,Learning Multiple Layers of Features from Tiny Images,https://ieeexplore.ieee.org/ielx7/6570653/7076742/10233848.pdf,Uses,,"The framework was tested using the ResNet18 model [24] on the CIFAR-10 dataset [25], which consists of 50000 training images and 10000 test images classified into 10 classes.",Yes,F-2T2R,Yes,F-2T2R,,uses,uses
60,Megatron-Turing NLG 530B,"Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model",http://arxiv.org/pdf/2302.10360,Uses,Motivation,"We used a variety of real models that have been introduced by other works, and then designed our family of hypothetical future models FUTURE-* in a similar fashion, keeping a reasonable sequence length, increasing the embedding dimension drastically, and following the trend of recent large models like PaLM (Chowdhery et al., 2022) and MT-NLG (Smith et al., 2022) of increasing the ratio d/h, which results in favorable energy calculations due to the lower fraction of memory operations in attention.",No,,Yes,"PaLM, MT-NLG (target paper)",,uses,uses
62,Universal approximation via Feedforward Networks,Multilayer feedforward networks are universal approximators,https://www.biorxiv.org/content/biorxiv/early/2023/06/23/2023.05.05.539427.full.pdf,Background,,"Neural networks are machine learning models [17, 18] capable of approximating any function [19]",Yes,Dawnn,Yes,Dawnn,,background,background
63,Denoising Diffusion Probabilistic Models (LSUN Bedroom),Denoising Diffusion Probabilistic Models,https://www.mdpi.com/1424-8220/24/3/829/pdf?version=1706284599,Background,,"Representatively, denoising diffusion probabilistic models (DDPMs) [12] have rendered image generation plausible by gradually denoising sampled data from a Gaussian distribution.",Yes,HDPose,Yes,DDPM (target paper),,background,background
64,,,,Uses,,"Following DDPM [12], this process can be expressed as: xt := √ α¯tx0 + p 1 − α¯tϵ (3) where αt := 1 − βt , α¯t := Πt s=1 αs and ϵ ∼ N (0, I) Gaussian noise ϵ. We can optimize L by randomly sampling t during training, thereby exploiting these properties.",,,,,,uses,uses
65,ReLU (NORB),Rectified Linear Units Improve Restricted Boltzmann Machines,http://arxiv.org/pdf/2306.12929,Uses,,The configuration “MLP” parameterizes each Gi with a feed-forward net with one hidden layer of size nhid and a ReLU non-linearity [47].,Yes,fine tuned,Yes,,,uses,uses
66,ProBERTa,Transforming the Language of Life: Transformer Neural Networks for Protein Prediction Tasks,https://www.biorxiv.org/content/biorxiv/early/2024/02/08/2024.02.06.579188.full.pdf,Background,,"Recently, deep learning has been an accelerating force for protein engineers, and large attention based models are at the forefront.[16–18]",Yes,NOMELT,Yes,NOMELT,,background,background
69,ProtT5-XXL,ProtTrans: Towards Cracking the Language of Life’s Code Through Self-Supervised Learning,https://www.biorxiv.org/content/biorxiv/early/2021/07/20/2020.11.27.401232.full.pdf,Background,Future Work,"Standard transformer models have already been used to embed unaligned protein sequences (52–54), but the most efficient transformer models released in the last year are now capable of handling sequence lengths even in the millions, and so this suggests that a single deep transformer model with a compressed self-attention mechanism could, in principle, embed a whole MSA in one go by essentially treating it as a single sequence.",Yes,,Yes,,,background,background
70,BASIC-L + Lion,Symbolic Discovery of Optimization Algorithms,https://ieeexplore.ieee.org/ielx7/92/4359553/10313117.pdf,Background,,"Although both target the classification of images, best-inclass classifiers differ by multiple orders of magnitude in terms of model parameters, i.e., 1.5M [51] for MNIST and 2440M [52] for ImageNet.",Yes,,Yes,,,background,background
71,ShuffleNet v2,ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design,https://www.nature.com/articles/s41598-023-42577-1.pdf,Differences,,"Although EfcientNet-B0 consumes more computational resources than these models, it did improve identifcation accuracy when comparing with other lightweight CNN such as SqueezeNet and ShufeNetV2.",Yes,EfcientNet-CA,Yes,EfcientNet-B0,An interesting paper presents a deep learning-based model designed for the rapid and precise identifcation of common horseshoe bats,differences,differences
72,ShuffleNet v1,ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices,https://www.mdpi.com/2079-9292/12/22/4617/pdf?version=1699696562,Background,,"MobileNet [20], ShuffleNet [26], and EffNet [27] are examples of common artificially built lightweight models.",Yes,Arc_EffNet,Yes,Arc_EffNet,,background,background
73,Agent57,Agent57: Outperforming the Atari Human Benchmark,https://arxiv.org/pdf/2107.02195,Background,,"Reinforcement learning (RL) algorithms have reached tremendous success in the field of embodied intelligence, including human-level control in Atari games [1], [2] and in firstperson games [3], [4], and super-human control in competitive games [5], [6].",Yes,,Yes,,,background,background
74,Fast R-CNN,Fast R-CNN,https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0297059&type=printable,Background,,"Common two-stage detectors include R-CNN [12], Fast R-CNN [13] and Faster R-CNN [14].",Yes,PO-YOLOv5,Yes,PO-YOLOv5,,background,background
75,GShard (dense),GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding,https://arxiv.org/pdf/2309.13850,Background,,"These benefits have been empirically demonstrated in several deep learning applications, including natural language processing (Lepikhin et al., 2021; Du et al., 2022; Fedus et al., 2022b; Zhou et al., 2023; Pham et al., 2024), speech recognition (Peng et al., 1996; Gulati et al., 2020; You et al., 2022), computer vision (Dosovitskiy et al., 2021; Riquelme et al., 2021; Liang et al., 2022; Bao et al., 2022), multi-task learning (Hazimeh et al., 2021; Gupta et al., 2022) and other applications (Rives et al., 2021; Chow et al., 2023; Li et al., 2023; Han et al., 2024).",Yes,,Yes,,,background,background
76,Symmetric Residual Encoder-Decoder Net,Image Restoration Using Very Deep Convolutional Encoder-Decoder Networks with Symmetric Skip Connections,https://arxiv.org/pdf/2303.14934,Background,,"Image denoising aims to restore clean images from noisy observations [5, 11, 14], and it has achieved noticeable improvement with the advances in deep networks",Yes,not named,Yes,"blind-neighborhood network (BNN), locally aware network (LAN)",Discusses a method of denoising images by using BNN for supervision in flat regions of noisy images and LAN for supervision in textured regions of noisy images. ,background,background
77,,,,Background,,"Other learning based methods, such as RED30 [33], MemNet [40], and MWCNN [31], are also developed with advanced architectures",,,,,,background,background
81,SEER,Self-supervised Pretraining of Visual Features in the Wild,https://www.pure.ed.ac.uk/ws/files/241297605/Paper_Generative_Models_with_Negative_Retraining.pdf,Background,,Few-shot learning uses prior knowledge to augment the learned classes [12]–[15].,Yes,REtraining with Few-shots Generative Adversarial Network (REFGAN),No,,,background,background
82,,,,Extends,,"REFGAN is adaptive and takes into account OoC as they are introduced. We adapt the prior to detect OoC by moving away from a priori known OoC using two poles, one positive and one negative, in line with Contrastive Learning [15].",,,,,,similarities,similarities
83,,,,Background,,"It intersects with other methods such as [28], [15].",,,,,,similarities,similarities
84,,,,Extends,,Our REFGAN methodology can perform multi-class classification and recognize the class of OoC using Nearest Neighbors with f-divergences [15].,,,,,,uses,uses
85,,,,Future Work,,"In the future, we will evaluate REFGAN using a large number of classes using (9) to avoid softmax [39] and compare it to [15] and meta-learning methods that address the few-shot learning setting [25], [40], [41].",,,,,,uses,uses
86,AmoebaNet-A (F=448),Regularized Evolution for Image Classifier Architecture Search,https://ojs.aaai.org/index.php/AAAI/article/download/25118/24890,Background,,"Similarly, for AmobaNet(Real et al. 2019), to search for clean accuracy leveraging Evolutionary Algorithms, 8 days would be required on 10 GPUs",Yes,Wsr-NAS,Yes,WsrNet,,background,background
87,PaLM (540B),PaLM: Scaling Language Modeling with Pathways,https://arxiv.org/pdf/2310.03026,Background,,"The remarkable achievements of LLMs are undeniably captivating, demonstrating LLM’s human-like reasoning skills and generalization of human commonsense (Bian et al., 2023; Nay, 2022; Chowdhery et al., 2022; Ouyang et al., 2022; Chung et al., 2022)",Yes,LanguageMPC,No,,About automated driving LLM that combinds RL and MPC,background,background
88,GLM-130B,GLM-130B: An Open Bilingual Pre-trained Model,https://arxiv.org/pdf/2308.07107,Background,,"To our knowledge, it is the first model to directly fine-tune LLMs, including ChatGLM [68, 114], ChatGLM2.0 [68, 114], Baichuan [115], and Qwen [116], specifically for the query rewriting task",No,,No,,,background,background
89,VQGAN + CLIP,Taming Transformers for High-Resolution Image Synthesis,https://arxiv.org/pdf/2211.00680,Uses,,"In this Section we present the results of experiments carried out on images generated by several state-of-the-art generative models including GANs, transformers, and DMs: ProGAN [20], StyleGAN2 [22], StyleGAN3 [11], BigGAN [21], EG3D [30], Taming Transformer [23], DALL·E Mini [24], DALL·E 2 [3], GLIDE [5], Latent Diffusion [25], Stable Diffusion [4] and ADM (Ablated Diffusion Model) [26].",No,,Yes,"ProGAN, StyleGAN2, StyleGAN3, BigGAN, EG3D, Taming Transformer, DALL·E Mini, DALL·E 2, GLIDE, Latent Diffusion, Stable Diffusion and ADM (Ablated Diffusion Model)",Cool application on using AI to generate synthetic images,uses,uses
91,PaLI,PaLI: A Jointly-Scaled Multilingual Language-Image Model,http://arxiv.org/pdf/2303.07226,Background,,"However, state-of-the-art vision language models like Flamingo-80B [1], BEIT-3-1.9B[66], and PaLI-17B [6] can be computationally expensive and difficult to train, which has motivated researchers to explore ways of improving their efficiency and effectiveness.",Yes,VL-MoE,No,,,motivation,motivation
92,Cognitron,Cognitron: A self-organizing multilayered neural network,https://academic.oup.com/mnras/article-pdf/507/3/4425/40365089/stab2142.pdf,Background,,"The concept of machine learning in computational science started from Fukushima (1975, 1980) and Fukushima, Miyake & Ito (1983).",Yes,"No name just says ""our CNN classifier""",Yes,CNN,,background,background
93,Deeply-recursive ConvNet,Deeply-Recursive Convolutional Network for Image Super-Resolution,https://www.mdpi.com/2072-4292/14/2/257/pdf?version=1641475856,Background,,"In particular, the deep learning-based SRR methods, either using residual networks [37–39], recursive networks[40,41], attention-based networks [42,43], and/or using generative adversarial networks (GANs) [44–46], have become more and more popular over the last decade, not only in the field of picture/photo enhancement, but also in the field of Earth observation for improving the quality and resolution of satellite imagery [34–36].",No,,Yes,MARSGAN SRR,,background,background
94,Base LM + kNN LM + Continuous Cache,Generalization through Memorization: Nearest Neighbor Language Models,http://arxiv.org/pdf/2210.09340,Background,,"k-Nearest Neighbors (kNN)-based approaches have been successfully used in the literature for an array of tasks such as language modeling (Khandelwal et al., 2020), question answering (Kassner and Schütze, 2020), dialogue generation (Fan et al., 2021), etc.",Yes,"No name: "" a framework for transferring knowledge to a low-resource HS corpus by incorporating neighborhood information with Optimal Transport""",Yes,LaBSE,,background,background
95,SemExp,Object Goal Navigation using Goal-Oriented Semantic Exploration,https://arxiv.org/pdf/2307.15320,Background,,"Data-driven policy learning allows to acquire reactive robotic skills and has recently shown impressive results both in simulation and in the real world for tasks such as dexterous manipulation [1], [2], [3], [4], robotic arm manipulation [5], [6], [7], quadruped locomotion [8], [9], [10], [11] and navigation [12], [13], [14], [15].",Yes,,Yes,"DA, DM",,background,background
96,Conv-DBN,Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations,https://www.nature.com/articles/s41598-020-69201-w.pdf,Background,,"A DBN, consists of probabilistic models composed of multiple layers of random variables51.",No,,Yes,ResNet-50,,background,background
97,WGAN-GP,Improved Training of Wasserstein GANs,https://arxiv.org/pdf/2308.13295,Uses,,"In practice, the Wasserstein GAN with Gradient Penalty (WGAN-GP) [28] is used.",Yes,,Yes,"OL-GAN, FNN",,uses,uses
98,DeepNash,Mastering the game of Stratego with model-free multiagent reinforcement learning,https://arxiv.org/pdf/2307.13922,Background,,"Such examples include strong performance in competitive games (Brown & Sandholm, 2019; Perolat et al., 2022), resource allocation (Parise et al., 2020; Amelina et al., 2015) and robotics (Hamann, 2018; Hernandez et al. ´ , 2013).",No,,Yes,Q-Learning dynamics,,background,background
99,LDA,Latent Dirichlet Allocation,https://www.medrxiv.org/content/medrxiv/early/2023/11/17/2023.11.16.23298640.full.pdf,Uses,,"LDA is a generative probabilistic model which applies a distribution of topics over each document, assuming topics are drawn from a Dirichlet distribution.27",Yes,EHR-BERT,Yes,LDA,,background,background
103,PNAS-net,Progressive Neural Architecture Search,https://www.mdpi.com/2073-431X/12/9/174/pdf?version=1693565686,Background,,"Similarly, the majority of recent literature on AutoML for DL models concentrates on automating the design of DL models through the neural architecture search (NAS) process [24–28].",No,,No,,,background,background
104,GPT-4,GPT-4 Technical Report,https://arxiv.org/pdf/2310.08889,Background,,"Further, as large language models (LLMs) are drawing much attention in the NLP community, how strong LLMs behave in connecting discrete and continuous space perturbations remains unexplored, especially when GPT-4 (OpenAI, 2023) is known to support images and texts. As these models are not open-source to the public, we leave exploring the perturbation in LLMs in future works.",No,,No,,,future_work,future_work
106,Ankh_base,Ankh ☥: Optimized Protein Language Model Unlocks General-Purpose Modelling,https://www.biorxiv.org/content/biorxiv/early/2024/02/01/2024.01.29.577750.full.pdf,Uses,,"Using these mined sequences, we finetuned the complete encoder-decoder Ankh base model27
.
As a masking strategy, we employ unigram T5 span masking (Experiment 4 in the Ankh paper27)
and dynamically sample new masking tokens every epoch. We set the maximum sequence
length to 512 and randomly select 20% of tokens for masking, following the approach described
in the Ankh paper",No,,Yes, fine tuned,,uses,uses
107,Contriever,Unsupervised Dense Information Retrieval with Contrastive Learning,http://arxiv.org/pdf/2302.01626,Background,,"mContriever (Izacard et al., 2021b) and CCP (Wu et al., 2022a) similarly mine positive pairs by cropping two spans in a document. T",No,,No,,,background,background
108,Two-stream ConvNets for action recognition,Two-Stream Convolutional Networks for Action Recognition in Videos,http://arxiv.org/pdf/2305.01111,Background,,Mentioned in a table,No,,No,,,extends,uses
109,AlphaX-1,AlphaX: eXploring Neural Architectures with Deep Neural Networks and Monte Carlo Tree Search,https://ojs.aaai.org/index.php/AAAI/article/download/17233/17040,Background,,"We compare BANANAS to a host of popular NAS algorithms including random search (Li and Talwalkar 2019), DARTS (Liu, Simonyan, and Yang 2018), regularized evolution (Real et al. 2019), BOHB (Falkner, Klein, and Hutter 2018), NASBOT (Kandasamy et al. 2018b), local search (White, Nolen, and Savani 2020), TPE (Bergstra et al. 2011), BONAS (Shi et al. 2019), BOHAMIANN (Springenberg et al. 2016), REINFORCE (Williams 1992), GP-based BO (Snoek, Larochelle, and Adams 2012), AlphaX",No,,No,,,uses,uses
110,ALBERT-xxlarge,ALBERT: A Lite BERT for Self-supervised Learning of Language Representations,https://dl.acm.org/doi/pdf/10.1145/3583781.3590259,Background,,"Since the
introduction of the first transformer in 2017 [2], powerful
transformer-based pre-trained natural language processing (NLP)
models, such as BERT [3] and Albert [4], and computer vision
models, such as the Vision Transformer [5] have emerged.",no,,Yes,Albert ,,background,background
112,PreTrans-3L-250H,Speech recognition with deep recurrent neural networks,https://www.mdpi.com/2073-4433/14/3/542/pdf?version=1678952808,Background,,"They
incorporate a feedback loop in which the output of the RNN layer is taken as an input into
the next layer. Hence, RNNs are especially viable for analyzing time series in problems
related to text generation [69], speech recognition [70], or forecasting tasks [71].",no,,no,,,background,background
113,ObjectNet,ObjectNet: A large-scale bias-controlled dataset for pushing the limits of object recognition models,https://arxiv.org/pdf/2212.04825,Background,,"We also show the results of LLE on other OOD variants of ImageNet, including ImageNet-A [37] (IN-A), ImageNetV2 [69] (IN-V2), ObjectNet [9], and ImageNet-D [71,72] (IN-D). IN-D has rendition images similar to IN-R except for having additional domain annotations, e.g., clipart, infograph, etc.",yes,ImageNet-W,no,,,uses,uses
114,DLRM-2020,Deep Learning Recommendation Model for Personalization and Recommendation Systems,http://arxiv.org/pdf/2206.02626,Background,,"On the contrary, for recommendation tasks, there always has been a debate of linear vs. non-linear
networks [29, 65], along with the importance of increasing the width vs. depth of the network
[11, 39].",yes,DISTILL-CF,no,,,background,background
115,Once for All,Once for All: Train One Network and Specialize it for Efficient Deployment,https://arxiv.org/pdf/2102.05610,Background,,"When
designing fast models for inference with NAS, previous
work employed multi-objective search [53, 17, 12, 27, 61,
25, 11, 20, 37, 15] to consider accuracy together with performance/efficiency.",yes,EfficientNet-X,no,,,background,background
116,T5-3B,Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer,https://www.nature.com/articles/s41598-023-48594-4.pdf,Uses,,"a. We use a pretrained Opus-MT-based53 sequence-to-sequence model pretrained on the English-French language for back translation. T5 abstractive summarization: To address the issue of data scarcity, text summarization is conducted on input texts, generating concise summaries by employing the T5-large model5",no,,yes,t5-large,,uses,uses
117,BIDAF,Bidirectional Attention Flow for Machine Comprehension,https://arxiv.org/pdf/2010.10019,Uses,,"Even though our results are behind [2], we wish to point out that their context matching model with the bi-directional attention flow (BiDAF) [55] significantly contributes to the performance.",no,,yes,biDAF,,similarities,similarities
118,VD-RHN,Recurrent Highway Networks,https://ieeexplore.ieee.org/ielx7/6287639/9668973/09762315.pdf,Background,,"For example, the quality of neural language modeling [11] was significantly improved by using Highway layers [12], [13] or tying input and output embeddings [14].",no,,no,,,background,background
119,EfficientNet-L2,EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks,https://www.mdpi.com/2072-6694/16/2/430/pdf?version=1705650909,Uses,,"The ResNet 50 [38], EfficeientNet B3 [39], and ConViT (Small) [40] models were fine-tuned on the LVI datasets.",yes,ensemble,yes,finetuned,,uses,uses
120,Hybrid H3-2.7B,Hungry Hungry Hippos: Towards Language Modeling with State Space Models,http://arxiv.org/pdf/2305.13504,Background,,"Moreover, state space models [64, 66, 65, 39] are getting popular at handling long-range dependencies better than transformer architecture and exploring this direction for code generation is an interesting and exciting research direction.",no,,no,,,background,background
122,Pointer Sentinel-LSTM (medium),Pointer Sentinel Mixture Models,https://arxiv.org/pdf/2012.04632,Background,,"Other well-known approaches to address this challenge are [ 9 ,14 , 6 ,16 ,17 , 4]. In this paper, we argue that a key step in designing recurrent neural architectures is to understand the decay of dependence in sequential data and to use this understanding to inform the setting of the relevant hyper-parameters of the architecture.",yes,DilatedRNNs,no,,,background,background
123,FAST,Machine Learning for High-Speed Corner Detection,https://arxiv.org/pdf/2109.00210,Background,,"The image-based local feature extraction and description can be grouped into hand-crafted [22, 6, 32] and deep-learned [9, 40, 13, 35, 31] methods.",no,,no,,,background,background
124,PyramidNet,Deep Pyramidal Residual Networks,http://arxiv.org/pdf/2209.08473,Uses,,"Finally, according to the theory of [26] and [17], wider models are more easily interpreted as convex minimization problems.",yes,Wide PyramidNet272,yes,Wide PyramidNet272,,background,background
125,Transformer local-attention (NesT-B),"Nested Hierarchical Transformer: Towards Accurate, Data-Efficient and Interpretable Visual Understanding",https://arxiv.org/pdf/2308.05128,Background,,"This field is evolving rapidly, so methods such as transformers [53], large language models [5], knowledge distillation [8], wild and large datasets [31], unsupervised learning [9], and matching loss functions [44], etc. are constantly advancing the state-of-the-art. L",yes,N3HL153gpt,no,,,background,background
126,FTW,Human-level performance in 3D multiplayer games with population-based reinforcement learning,https://arxiv.org/pdf/2109.10665,Background,,"It has powerful representation learning and function approximation properties to be applied across various fields [17], [18], e.g., games [19] and robotics [20].",No,,No,,,background,background
127,Transformer ELMo,Dissecting Contextual Word Embeddings: Architecture and Representation,https://www.aclweb.org/anthology/2020.emnlp-main.397.pdf,Background,,"found the reference, couldnt find it in the text",,,,,,background,background
128,StarGAN v2,StarGAN v2: Diverse Image Synthesis for Multiple Domains,https://dl.acm.org/doi/pdf/10.1145/3588432.3591500,Background,,"found the reference, couldnt find it in the text",,,,,,background,background
129,Agent57,Agent57: Outperforming the Atari Human Benchmark,https://www.mdpi.com/2079-9292/12/16/3508/pdf?version=1692357476,Background,,". For instance, though Agent57 [8] stands as the premier deep reinforcement learning algorithm capable of surpassing the average human player across all 57 Atari games, it generally mandates orders of magnitude more interactions than its human counterpart.",yes,E2S2RND,no,,,background,background
130,LaMDA,LaMDA: Language Models for Dialog Applications,https://arxiv.org/pdf/2308.09490,Background,,"While some large-scale models are completely closedsource, such as OpenAI’s GPT-3 [3] or Google’s Bard [49], and are only accessible through an API, many other models are available as open-source models, usually including the code to train",no,,no,,,background,background
132,ProxylessNAS,ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware,https://dl.acm.org/doi/pdf/10.1145/3584945,Background,,"Differentiable methods [5, 22, 38, 65, 73] have been widely used in the image classification task.",yes,fine grained PAS-NE,no,,,background,background
133,Wide & Deep,"STRING v11: protein–protein association networks with increased coverage, supporting functional discovery in genome-wide experimental datasets",https://www.biorxiv.org/content/biorxiv/early/2023/10/12/2023.09.19.558413.full.pdf,Uses,,"The positive interactions were extracted from STRING (version 11) [56], a database encompassing diverse PPI networks and consolidating comprehensive information from various primary sources.",yes,SENSE-PPI,yes,version 11,,uses,uses
134,Thumbs Up?,Thumbs up? Sentiment Classification using Machine Learning Techniques,https://www.mdpi.com/1424-8220/21/4/1330/pdf?version=1613983067,Background,,"The most common way to do that is by analyzing certain traits of words (commonly their frequency within the text) [32,34]",no,,no,,,background,background
136,DITTO,Learning to Break the Loop: Analyzing and Mitigating Repetitions for Neural Text Generation,https://arxiv.org/pdf/2310.01041,Background,,Xu et al. (2022) proposed the DITTO objective that penalizes sentence-level repetition loop.,yes,DAEMON,no,,,background,background
137,Convolutional Pose Machines,Convolutional Pose Machines,http://nrl.northumbria.ac.uk/id/eprint/43318/1/Paper.pdf,Background,,could not find citation in text,,,,,,background,background
138,Enhanced Neighborhood-Based Filtering,Scalable Collaborative Filtering with Jointly Derived Neighborhood Interpolation Weights,https://www.atlantis-press.com/article/125950416.pdf,Background,,An incremental algorithm to update user factors is presented [25] by utilizing a simple method of the batch process.,no,,no,,,background,background
139,Prototypical networks,Prototypical Networks for Few-shot Learning,https://arxiv.org/pdf/2307.07286,Uses,,"For example, Snell et al. [32] presented the Prototypical Networks that compute distances between a datapoint and class-wise prototypes",yes,no name,yes,ProtoNet,,background,background
140,Pandemonium (morse),Pandemonium: a paradigm for learning,https://karger.com/ofa/article-pdf/2/6/374/3300852/000260906.pdf,Background,,"To a point, the mission of such constellations of molecules might be compared with the recognition of real-life patterns, such as handwritten characters formulated by Oliver Selfridge 50 years ago in a whimsically named feature-analysis approach, the ‘Pandemonium model’ [34, 35]",no,,no,,,background,background
141,ReLU (LFW),Rectified Linear Units Improve Restricted Boltzmann Machines,https://link.springer.com/content/pdf/10.1007/s44196-023-00366-8.pdf,Uses,,"In Eq. (5), a two-layer fully connected feed forward network with Rectifed Linear Units (ReLU) activation [34].",yes, (LN‑GTM),yes,ReLu,,uses,uses
142,Make-A-Video,Make-A-Video: Text-to-Video Generation without Text-Video Data,http://arxiv.org/pdf/2303.17599,Uses,,"Leveraging a pre-trained text-to-image diffusion model, MakeA-Video [34] performs video generation through a spatialtemporal decoder trained only on unlabeled video data.",yes,vid2vid-zero,yes,Make-A-Video,,background,background
143,Transformer local-attention (NesT-B),"Nested Hierarchical Transformer: Towards Accurate, Data-Efficient and Interpretable Visual Understanding",https://arxiv.org/pdf/2301.10750,Background,,ResNeSt is a modularized architecture that uses channel-wise attention to focus on various network branches to take advantage of their success in capturing cross-feature interactions and learning various representations [78].,yes,ConvNext,yes,ResNet,,background,background
144,Switch,Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity,https://arxiv.org/pdf/2211.08842,Background,,"Meanwhile, PTMs are also getting bigger and bigger. In the past two years, large models with trillions of parameters are popping up around the world, including GPT-3 [15], Switch Transformer [16], and M6 [17].",yes,ELBERT model and the acceleration method,no,,,background,background
145,EfficientDet,EfficientDet: Scalable and Efficient Object Detection,http://arxiv.org/pdf/2303.04884,Uses,,". EfficientDet (Tan et al., 2020), an augmented variant of YOLOv3, exploits a pyramid network to enable the detection of scaling targets",yes,O2RNet-ResNet101,yes,"EfficientDet-b0 (Oerke, 2006) 0.45 0.89 0.85 0.30 0.82 0.71 0.77 EfficientDet-b1 (Oerke, 2006) 0.45 0.89 0.86 0.30 0.82 0.72 0.77 EfficientDet-b2 (Oerke, 2006) 0.46 0.89 0.87 0.30 0.82 0.73 0.78 EfficientDet-b3 (Oerke, 2006) 0.49 0.93 0.91 0.32 0.84 0.75 0.81 EfficientDet-b4 (Oerke, 2006) 0.50 0.94 0.92 0.34 0.88 0.78 0.82 EfficientDet-b5 (Oerke, 2006)",,background,background
146,VGG16,Very Deep Convolutional Networks for Large-Scale Image Recognition,https://www.mdpi.com/2306-5354/11/1/19/pdf?version=1703413051,Background,,"Research has constantly improved network architecture around this fundamental principle, including architectural milestones like VGG [87], ResNet [88], Xception [89], or EfficientNet [90].",no,,no,,,background,background
147,PolyCoder,A systematic evaluation of large language models of code,http://arxiv.org/pdf/2302.05226,Background,,couldnt find citation in text,,,,,,background,background
148,DrLIM,Dimensionality Reduction by Learning an Invariant Mapping,https://link.springer.com/content/pdf/10.1007/s11042-023-14876-2.pdf,Background,,"For example, the contrastive loss [7] needs to construct sample pairs to train the model.",yes,ResNet-MLB,no,,,background,background
149,DiT-XL/2,Scalable Diffusion Models with Transformers,https://arxiv.org/pdf/2307.02270,Background,,"Recently, denoising diffusion models demonstrating great potential in various computer vision fields including super-resolution [52], [53], image generation [54]–[61], object detection and segmentation [62]–[65], etc.",yes,SVDM,no,,,background,background
150,Naive Bayes,Pattern classification and scene analysis,https://sol.sbc.org.br/index.php/ercemapi/article/download/21955/21778,Uses,,"Finally, the resulting image is normalized between 0 and 1. To evaluate the efficiency of the method used, the following validation metrics: accuracy (Acc), sensitivity (Sens), specificity (Spec), and area under roc curve (AUC) [Duda 1973].",yes,no name,yes,?,,uses,uses
151,ConvNet similarity metric,"Learning a similarity metric discriminatively, with application to face verification",http://arxiv.org/pdf/2303.05161,Background,,"Segregation of class manifolds is a powerful conceptualisation that informs the design of distancebased losses in metric learning and contrastive learning [13–17] and underlies several approaches aimed at quantifying expressivity and generalisation, in artificial neural networks as well as in neuroscience [18– 23].",no,no name,no,,,background,background
152,YOLOv3,YOLOv3: An Incremental Improvement,https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0296992&type=printable,Extends,,Examples of one-stage algorithms include the Single-Shot Multibox Detector (SSD) series [10] and the You Only Look Once (YOLO) series [11–17].,yes,YOLOv7-LDS. YOLOv7-LDS,yes,YOLOv7-LDS. YOLOv7-LDS,,background,background
153,AbLang,AbLang: an antibody language model for completing antibody sequences,https://www.nature.com/articles/s42004-023-01037-7.pdf,Uses,,"Finally, since LLMs have shown promising results on similar tasks, we also used an antibodyspecific pretrained LLM (AbLang22)",yes,,yes,AbLang,,uses,uses
154,HMM Word Alignment,HMM-Based Word Alignment in Statistical Translation,https://www.mdpi.com/2297-8747/24/1/14/pdf?version=1551266155,Background,Uses,Word alignment was also studied in connection with statistical translation by using a HMM by Vogel et al.,No,,Yes,Hidden Markov Models (HMMs) ,"Interesting application of HMM to the field of linguistics. The Voynich manuscript is an undeciphered script that we are still trying to decipher today. This paper aims to use HMM to prove that this manuscript is neither a hoax nor intentional cipher, but an actual language, through having the model identify evidence of the existence of two states associated with the symbols in the manuscript (like the consonants and vowels in English). ",background,background
155,Gated HORNN (3rd order),Higher Order Recurrent Neural Networks,https://arxiv.org/pdf/2206.01261,Motivation,,"In the context of recurrent models, (Soltani and Jiang, 2016) introduced weighted skip connections between subsequent states of an unfolded RNN learn long-term dependencies.",No,,Yes,"CNN, RNN",Introducing entangled residual mappings as a method of understanding the role of residual mappings across different learning models while preserving the iterative feature refinement. ,background,background
156,FAIRSEQ Adaptive Inputs,"fairseq: A Fast, Extensible Toolkit for Sequence Modeling",https://arxiv.org/pdf/2201.05742,Uses,,We use RoBERTa as the backbone of Kformer and implement our method using Facebook’s tool fairseq [13],Yes,Kformer,Yes,Kformer,,uses,uses
158,ESM1-670M (UR50/D),Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/jcb.30490,Uses,,"We reviewed and compared the most recent and frequently used DL‐based protein embeddings (namely: UniRep,20 SeqVec,21 ProteinBERT,25 and ESM‐1b23) in predicting transporter proteins and their relative substrates, in combination with several machine learning approaches.",Yes,PortPred,Yes,PortPred,,uses,uses
159,Spatially-Sparse CNN,Spatially-sparse convolutional neural networks,https://arxiv.org/pdf/1703.09438,Motivation,,"Our approach is largely inspired by Graham’s sparse convolutional networks [16, 17], which enable efficient shape analysis by storing a sparse set of non-trivial features instead of dense feature maps.",Yes,Octree Generating Networks (OGN),Yes,Octree Generating Networks (OGN),"Interesting application of OGNs to create high resolution 3D outputs, such that the higher the octree level, the more efficient the representation is.",uses,uses
160,XGLM,Few-shot Learning with Multilingual Language Models,http://arxiv.org/pdf/2208.01448,Background,Differences,"We show that AlexaTM 20B provides SOTA performance in zero-shot setting for all of these tasks, across all supported languages, improving on previous SOTA achieved by the XGLM 7.5B model (Lin et al., 2021).",Yes,AlexaTM 20B,Yes,AlexaTM 20B,Evaluates how AlexaTM 20B has overall better performance than other models (which includes the XGLM 7.5B model referenced).,differences,differences
161,,,,Similarities,,"The CLM mode is similar to the way previous large-scale decoder-only models have been using these models for generation and scoring for in-context learning (Brown et al., 2020b; Chowdhery et al., 2022; Lin et al., 2021).",,,,,,similarities,similarities
162,,,,Differences,,"Additionally, we evaluate AlexaTM 20B on a few multilingual datasets including XNLI, XCOPA, Paws-X, and XWinograd and show that AlexaTM 20B achieves SOTA numbers in zero-shot on all these tasks across all languages better than XGLM 7.5B model (Lin et al., 2021).",,,,,,uses,uses
163,,,,Differences,,"As can be seen, AlexaTM 20B outperforms the supervised M2M-124 615M model from Goyal et al. (2022) and XGLM 7.5B, which is a multilingual decoder-only model (Lin et al., 2021), across almost all pairs.",,,,,,differences,differences
164,,,,Background,,We follow Lin et al. (2021) and evaluate AlexaTM 20B on four multilingual data sets to evaluate its performance on non-English tasks.,,,,,,uses,uses
165,,,,Differences,,"As can be seen in Table 10, AlexaTM 20B performs better or on par to XGLM 7.5B (Lin et al., 2021) across all tasks and languages (supported by both models).",,,,,,similarities,similarities
166,,,,Background,,XGLM 7.5B numbers for XNLI and XCOPA are as reported by Lin et al. (2021).,,,,,,uses,uses
167,,,,Differences,,"Among public multilingual encoders, the most successful efforts include mBERT (a version of BERT pre-trained on Wikipedia in 104 languages), mBART (Liu et al., 2020b), XLM-R (Conneau et al., 2020), and XGLM (Lin et al., 2021).",,,,,,background,background
168,T5-3B,Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer,https://arxiv.org/pdf/2312.05092,Uses,,"CodeT5 [62] uses the T5 architecture [63], which unifies all tasks as text generation tasks",No,,Yes,"CodeBERT, CodeBERTa, GraphCodeBERT, JavaBERT, PLBART, CodeT5, UniXCoder, CodeReviewer","Doesn't further train the pre-trained models, just want to analyze the extent that these pre-trained models learn about the specific aspects of source code through probing. ",background,background
170,ViT-Base/32,An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale,https://bmcmedimaging.biomedcentral.com/counter/pdf/10.1186/s12880-023-01177-1,Background,,"In order to further highlight the efect of our model,we compare the proposed method with four methods: Efcient-b2 [14], Resnet34 [8], Swin transformer [15], and Vision transformer [16], as show in Fig. 9",No,,Yes,ResNet,Impactful extension of attention-enhanced architecture in the medical field to better identify pneumonia in chest X-ray images,uses,uses
171,BiLSTM for Speech,Framewise phoneme classification with bidirectional LSTM and other neural network architectures,https://www.mdpi.com/2220-9964/12/3/98/pdf?version=1677404230,Motivation,,"With the same or similar setup parameters, a bidirectional network achieved more desired results than a unidirectional network in many fields [58].",Yes,Att-DBGRU,Yes,Att-DBGRU,Interesting use of AI models to deciding how to manage tourist attractions by forecasting tourism volume. ,background,background
172,Learning deep architectures,Learning Deep Architectures for AI,https://www.nature.com/articles/s41598-023-35190-9.pdf,Uses,,Deep learning utilizes layers of non-linear processing elements for feature extraction and conversion.,No,,Yes,"You Only Look Once (YOLO), Single Shot Detector (SSD)",Good example of how AI models can be used in the real world for security - in this case an early weaopn detection framwork by using CNN-based models like YOLO and SSD. ,background,background
173,Zoneout + Variational LSTM (WT2),Pointer Sentinel Mixture Models,http://arxiv.org/pdf/2207.09519,Similarities,,"The cache model has been equipped on various models to boost the performance for vision or language models, including kNNLMs [30], Unbounded Cache [18], Matching Network [60] and others [43,53].",Yes,Tip-Adapter,Yes,"Tip-Adapter, Contrastive Vision-Language Pre-training (CLIP)",Purpose of citation: to say that these others models also equipped the cache models in their models to boost performance for vision and language models. ,background,background
174,LeNet-5,Gradient-based learning applied to document recognition,https://www.nature.com/articles/s41598-023-49334-4.pdf,Background,,"Due to the increase of convolution layer, successive multi-layer gradient multiplication may cause minimum amount of information that is captured according to the chain rule in back-propagation, resulting in the problems of Gradient Vanishing and Gradient Exploding and the decline of the accuracy of the training set.",No,,Yes,"ResNet50, SVR",Impactful example of how using the ResNet50 + SVR model combination can help rapidly conduct an excellent evaluation of pulmonary function parameters when patients cough. This is helpful especially since traditional clinical evaluations of respiratory diseases involve a complex process that the pateitns can't monitor daily.,motivation,motivation
175,Context-dependent RNN,Context dependent recurrent neural network language model,https://www.aclweb.org/anthology/N15-1186.pdf,Motivation,,"Many recent proposals in the literature use wordrepresentations as the basic units for tackling sentence-level tasks such as language modeling (Mnih and Hinton, 2007; Mikolov and Zweig, 2012), paraphrase detection (Socher et al., 2011a), sentiment analysis (Socher et al., 2011b), discriminative parsing (Collobert, 2011), as well as similar tasks involving larger units such as documents (Glorot et al., 2011; Huang et al., 2012; Le and Mikolov, 2014).",Yes,"SG, SG+Morph",Yes,"SG and SG+Morph models trained from scratch, for all languages that they considered","Cool example of a method for training models to discover morphological rules in languages. The citation mentions previous works that have developed language models for generation of words, but also mentions that these models treated words as units and neglected the relationship between the words, thereby affecting the word semantics. This paper presents a method for analyzing these relationships between the words, so that models are able to account for word semantics. ",background,background
176,PLATO-XL,PLATO-XL: Exploring the Large-scale Pre-training of Dialogue Generation,http://arxiv.org/pdf/2206.14000,Extends,,"We experiment on multiple Chinese pretrained language models, including T5 (Xue et al., 2021), BART (Liu et al., 2020), EVA2.0 (Gu et al., 2022), and PLATO (Bao et al., 2021b).",No,,Yes,"PLATO-SINC, PLATO, PLATO-FT, PLATO-FID, BART, T5, EVA2.0",,uses,uses
177,Elastic weight consolidation,Overcoming catastrophic forgetting in neural networks,http://arxiv.org/pdf/2306.08200,Background,,"One approach is to constrain the parameters of the model learned on a new task to deviate little from their values before this learning, e.g. by using distillation [1–4] or parameter regularization [5, 6] methods.",Yes,Prompt Of Prompts (POP),Yes,Prompt Of Prompts (POP),,background,background
178,,,,Background,,"EWC [5], GEM [21] and NSCL [6], on the other hand, suggested to constrain the gradient and parameters of the model, so as to remain close to those of the old model.",,,,,,background,background
179,RBM Image Classifier,Learning Multiple Layers of Features from Tiny Images,https://arxiv.org/pdf/2312.04918,Uses,,We started by training a standard VGG-16 [11] on the CIFAR-10 dataset [42],No,,Yes,"ResNet50, MobileNetV2",,uses,uses
180,Support Vector Machines,Support-Vector Networks,https://www.ias-iss.org/ojs/IAS/article/download/2928/1181,Uses,,"SVMs (Cortes and Vapnik 1995) are supervised learning method for classification, regression, and outlier’s detection",Yes,HSI classification (modification of Minimum Noise Fraction (MNF) + Edge Preserving Features (EPFs)),Yes,Support-vector networks,,background,background
181,VGG16,Very Deep Convolutional Networks for Large-Scale Image Recognition,https://www.nature.com/articles/s41598-023-49739-1.pdf,Background,,The most famous algorithm utilized for speeding up the evaluation of the gradient and for providing training to the neural networks is backpropagations. ,Yes,CNN-based model that isn't specifically named,Yes,"CNN-based model that has convolutional layers, fully-connected layers, and the output",Using CNNs to classify human activity recognition (HAR) tasks ,background,background
182,UL2,UL2: Unifying Language Learning Paradigms,https://arxiv.org/pdf/2307.12856,Uses,,"It is pre-trained using a mixture of long-span denoising objective (Tay et al., 2022) on a large-scale HTML corpus extracted from CommonCrawl.",Yes,HTML-T5,Yes,HTML-T5,,uses,uses
187,BatchNorm,Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift,https://researchopenworld.com/wp-content/uploads/2023/10/CST-8-833.pdf,Background,,"Importantly, these studies identified instances of cancer even in men in their twenties, with a prevalence ranging from 8% to 11%, highlighting the long period of latency between the development of prostate cancer and the appearance of symptoms in some individuals [19,20].",Yes,modified CNN system,Yes,modified CNN system - hybrid CNN-Deep Learning technique (CNN-RNN),,background,background
188,,,,Motivation,,Deep Learning [19] systems are built just for that purpose (Figure 4).,,,,,,background,background
216,Xception,Xception: Deep Learning with Depthwise Separable Convolutions,https://arxiv.org/pdf/2308.12494,Differences,Future Work,"To improve this, Xception [7] proposes to use separable convolution, a depthwise convolution followed by a pointwise convolution, which requires visiting each pixel only once by depthwise convolution.",no,,no,,"Not a model, but a roadmap to improve image recognition models. Quote: ""Extensive experiments demonstrate that our approach decreases runtime by up to 13% and reduces the number of parameters by up to 23%, while increasing PSNR and SSIM on several image restoration datasets.""",background,background
217,KEPLER,KEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language Representation,https://aclanthology.org/2021.findings-emnlp.292.pdf,Extends,,"KEPLER(Wanget al., 2019) uses Knowledge Embedding objective, i.e., TransE, to guide embedding encoded over entity description.",yes,Relation-Guided Pre-Training (RGPT-QA),no,,It proposes a framewrok model that can more accurate answer QA than privious models.,background,background
218,,,,Differences,,"From the table,KEPLER trained via TransE performs slightly better than KnowBERT trained via entity linking, and RGPT-QA out performs KEPLER by 2.8%, 2.1%, 5.7% on the three datasets.",yes,Relation-Guided Pre-Training (RGPT-QA),no,,It proposes a framewrok model that can more accurate answer QA than privious models.,differences,differences
219,GShard (dense),GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding,http://arxiv.org/pdf/2303.10845,Extends,,"Comparing to the expensive computational cost for training dense Transformer model, sparse architectures such as Mixtureof-Experts (MoE) [13, 14, 15, 22] are considered to be an appealing choice to scale model size up without incuring linear increase in computational cost.",yes,PanGu-Σ,yes,Ascend 910 AI,"PanGu-Σ provides state-of-the-art performance in zero-shot learning of various Chinese NLP downstream tasks. Moreover, it demonstrates strong abilities when f ine-tuned in application data of open-domain dialogue, question answering, machine translation and code generation.",background,background
220,WGAN-GP,Improved Training of Wasserstein GANs,https://arxiv.org/pdf/2309.13508,Extends,,"Because the gradient penalty enforces the Lipschitz constraint on the critic, limiting its update, we had to increase the number of critic training iterations per actor iteration to 5, a recommended value in WGAN-GP [14].",yes,Guided Cooperation via Modelbased Rollout (GCMR),yes,hierarchical reinforcement learning (HRL),"Here, we present a goal-conditioned HRL framework with Guided Cooperation via Modelbased Rollout (GCMR) 1 , which estimates forward dynamics to promote inter-level cooperation. The GCMR alleviates the state-transition error within off-policy correction through a model-based rollout, further improving the sample efficiency.",uses,uses
221,Transformer local-attention (NesT-B),"Nested Hierarchical Transformer: Towards Accurate, Data-Efficient and Interpretable Visual Understanding",http://arxiv.org/pdf/2304.13991,Extends,,"In Zhang et al. [40], a convolution is used to aggregate hierarchical transformer blocks in their Nested Hierarchical Transformer (NesT).",no,no,yes,Vision Transformers (ViT),"In addition, to use the CNN, we proposed to reconstruct the image data after the self-attention in a reverse embedding layer. Through the evaluation, we demonstrate that the proposed convolutions help improve the classification ability of ViT.",background,background
222,,,,Extends,,"NesT incorporates a convolution into the aggregation function of hierarchical Transformer blocks. NesT-T is used for the evaluation which includes three hierarchical layers of 8, 4, and 1 Transformer blocks each.",no,no,yes,Convolutional Neural Networks (CNN),"In addition, to use the CNN, we proposed to reconstruct the image data after the self-attention in a reverse embedding layer. Through the evaluation, we demonstrate that the proposed convolutions help improve the classification ability of ViT.",uses,uses
223,Max-Margin Markov Networks,Max-Margin Markov Networks,https://dl.acm.org/doi/pdf/10.3115/1220575.1220588,Motivation,Background,"Additionally, we use several pre-existing classifiers as features. This are simple maximum entropy Markov models trained off of the MUC6data, the MUC7 data and our ACE data.",yes,new joint EDTmodel (no name),yes,Entity detection and tracking (EDT),"In contrast, by modeling both aspects of the EDT task simultaneously, we are able to learn using highly complex, non-local features. We develop a new joint EDTmodel and explore the utility of many features, demonstrating their effectiveness on this task.",uses,uses
224,,,,Extends,,"The boundary decision features include: the second and third order Markov features over entity type, entity subtype and mention type; features appearing at the previous (and next) words within a window of three; the words that appear and the previous and next mention boundaries, specified also by entity type, entity subtype and mention type.",yes,new joint EDTmodel (no name),yes,Entity detection and tracking (EDT),"In contrast, by modeling both aspects of the EDT task simultaneously, we are able to learn using highly complex, non-local features. We develop a new joint EDTmodel and explore the utility of many features, demonstrating their effectiveness on this task.",uses,uses
225,,,,Differences,,"This non-locality makes models like Markov networks intractable, and LaSO provides an excellent framework for tackling this problem.",yes,new joint EDTmodel (no name),yes,Entity detection and tracking (EDT),"In contrast, by modeling both aspects of the EDT task simultaneously, we are able to learn using highly complex, non-local features. We develop a new joint EDTmodel and explore the utility of many features, demonstrating their effectiveness on this task.",background,background
226,GPT-2 (1.5B),Language Models are Unsupervised Multitask Learners,https://www.emerald.com/insight/content/doi/10.1108/JEBDE-08-2023-0015/full/pdf?title=unraveling-the-landscape-of-large-language-models-a-systematic-review-and-future-perspectives,Motivation,,"These models, such as GPT-1, GPT-2, GPT-3, InstructGPT and GPT-4 (Brownetal.,2020;OpenAI,2023;Ouyangetal., 2022; Radford, Narasimhan,Salimans,&Sutskever,2018;Radfordetal.,2019), are based on the architecture of the transformer (Vaswani et al., 2017), which is one of the famous architectures for developing LLMs and is well-known for its attention mechanisms, resulting in a simpler architecture than the recurrent neural networks (RNNs) (Schuster & Paliwal, 1997).",no,,yes,Transformer Architecture,"This paper aims to present a comprehensive examination of the research landscape in LLMs, providing an overview of the prevailing themes and topics within this dynamic domain.",background,background
227,,,,Differences,,"The GPT-2 model (Radfordetal.,2019) was proposed to further reduce the need for labeled datasets. It is a 1.5 billion transformer and uses a zero-shot setting, demonstrating that LLMs can learn various natural language tasks without explicit supervision. Compared with GPT-1 and GPT-2 models, GPT-3 model (Brown et al., 2020)has 175 billion parameters, which is much larger and improves the performance of LLMs further.",no,,yes,Transformer Architecture,"This paper aims to present a comprehensive examination of the research landscape in LLMs, providing an overview of the prevailing themes and topics within this dynamic domain.",background,background
228,OverFeat,"OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks",http://arxiv.org/pdf/2207.11523,Differences,Similarities,OverFeat [44] - Chart,yes,new road detection method (no name),yes,VGG-16,We propose a method to detect and segment roads with a random forest classifier of local experts with superpixel based machine-learned features.,background,background
229,Adaptive Subgrad,Adaptive Subgradient Methods for Online Learning and Stochastic Optimization,https://www.mdpi.com/2076-3417/13/5/2782/pdf?version=1677048989,Extends,,ADAM combines the AdaGrad’s ability to deal with sparse gradients [28] and RMSProp’s ability to deal with non-stationary objectives [29].,yes,"CNN and LSTM (both, no name)",yes,Adaptive Moment Estimation (ADAM),"We have developed both a CNN and an LSTM architecture for frequency-domain feature detection and approximation. The CNN models, one for phase and one for amplitude data, take short-distance Fourier transforms (SDFTs) representing the change in the signal over multiple observation points as input. The LSTM model takes the change in phase or amplitude points at each lateral location as a comma-separated value (CSV) input.",background,background
230,Restricted Bolzmann machines,Restricted Boltzmann machines for collaborative filtering,https://jwcn-eurasipjournals.springeropen.com/track/pdf/10.1186/s13638-019-1525-y,Differences,Background,"In the field of recommended systems, the restricted Boltzmann machine was first proposed to simulate a user’s explicit rating of items [18], and autoencoders and denoising autoencoders were also used for recommendations [19–21].",yes,neighborhood-aware deep learning method,yes,multi-layer perceptron (MLP) and convolution neural networks (CNN),"In the field of recommended systems, the restricted Boltzmann machine was first proposed to simulate a user’s explicit rating of items [18], and autoencoders and denoising autoencoders were also used for recommendations [19–21]. However, research using deep learning in the field of services recommendation is seldom. Therefore, we propose the neighborhood-aware deep learning method to predict the service quality of web services.",background,background
231,Statement Curriculum Learning,Formal Mathematics Statement Curriculum Learning,https://arxiv.org/pdf/2308.15605,Similarities,,"To train AIs to complete hard tasks, it is common to use reinforcement learning using outcomes as rewards, such as wins in games [19, 26] and successful proofs in proof generation systems [23, 30].",no,,yes,LLMs,"In this work, we build four new text-based datasets to evaluate measurement tampering detection techniques on large language models.",background,background
232,FAIRSEQ Adaptive Inputs,"fairseq: A Fast, Extensible Toolkit for Sequence Modeling",https://arxiv.org/pdf/2204.08858,Uses,,Two different ASR frameworks are used: ESPnet [22] and an internal toolkit based on fair seqand PyTorch [23].,no,,yes,GTC-T,"In this work, we are investigating GTC-T with a CTC-like and a MonoRNN-T graph using a large-scale data set of 145K hours.",uses,uses
233,,,,Uses,,"For the results presented here, an Emformer-based streaming ASR model architecture is used that is implemented using an internal fairseq-based ASR framework [23,24].",no,,yes,MonoRNN-T,"In this work, we are investigating GTC-T with a CTC-like and a MonoRNN-T graph using a large-scale data set of 145K hours.",uses,uses
234,Walking Minotaur robot,Learning to Walk via Deep Reinforcement Learning,http://arxiv.org/pdf/2111.12557,Motivation,,"However, these approaches are far from providing any practical solutions to the problem at hand and they are shown to be only effective on simpler practical robots [26]–[33] and demonstrations in more complex problems such as those offered by legged robots are missing.",no,,yes,Explicit Reference Governors (ERG),"In this work, we will report our preliminary results in the modeling, control design, and development of a legged robot called NU’s Husky Carbon (shown in Fig. 1). Our objective is to integrate legged and aerial mobility into a single platform.",motivation,motivation
235,MnasNet-A3,MnasNet: Platform-Aware Neural Architecture Search for Mobile,https://www.frontiersin.org/articles/10.3389/fphy.2023.1159266/pdf,Extends,,"Traditional NAS work uses the reinforcement learning algorithm (RL) [7], evolutionary algorithm (EA) [8], and the gradient-based method to conduct architecture search.",yes,CK-βNAS-CLR,no,,This paper proposes a circular kernel convolution-β-decay regulation NAS-confident learning rate (CK-βNAS-CLR) framework to automatically design the neural network structure for HSI classification.,background,background
236,DeepStack,DeepStack: Expert-Level Artificial Intelligence in No-Limit Poker,https://figshare.com/articles/journal_contribution/Mathematical_consistency_and_long-term_behaviour_of_a_dynamical_system_with_a_self-organising_vector_field/11861349/1/files/21742305.pdf,Background,,"Artificial intelligence (AI) is nowadays widely spread [36], has demonstrated very impressive and sometimes superhuman levels of performance in a range of applications, such as face recognition [33], medical diagnostics from image analysis [15, 8], games of Go [31] and poker [25], and is often recognised as the most important technology of the future [24].",yes,n/a (brain model),no,na,"Here we analyse a mathematical construct, which was recently proposed in [19] with the goal to develop AI both explainable and inspired by the brain.",background,background
237,Neuro-Symbolic Concept Learner,"The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences From Natural Supervision",http://arxiv.org/pdf/2205.14268,Motivation,,"These approaches use neural models to build executable logical programs. Examples include Liang et al. (2017) and Mao et al. (2019). We highlight Logic Tensor Networks (LTNs) [Badreddine et al., 2022], as we include this approach in our empirical evaluation. LTNs connect neural predictions into functions representing symbolic relations with real-valued or fuzzy logic semantics. Neural networks as predicates: This line of work int",yes,Neural Probabilistic Soft Logic (NeuPSL),yes,probabilistic soft logic (PSL),"This paper introduces Neural Probabilistic Soft Logic (NeuPSL), a novel NeSy method that integrates deep neural networks with a symbolic method designed for fast joint learning and inference",background,background
238,AlexNet,ImageNet classification with deep convolutional neural networks,https://www.preprints.org/manuscript/202310.1446/v1/download,Background,,"In 2012, AlexNet, proposed by Alex Krizhevsky et al. [5] made a splash in the ImageNet image recognition competition, crushing the classification performance of the second place support vector machines (SVM)",yes,attention mechanism for multiscale receptive fields convolution block (AMMRF),yes,common objects in context (COCO),The new detection method is more lightweight and works well for multi-scale ship target detection in SAR images.Our contributions can be summarized as follows.,background,background
239,,,,Motivation,,Applying deep learning to image processing can significantly improve detection accuracy and speed for tasks such as target detection and instance segmentation [5].,yes,You Only Look Once SAR Ship Identification (YOLO-SARSI),yes,PASCAL visual object classes (PASCAL VOC),The new detection method is more lightweight and works well for multi-scale ship target detection in SAR images.Our contributions can be summarized as follows.,background,background
240,SimCLR,A Simple Framework for Contrastive Learning of Visual Representations,https://academic.oup.com/bioinformatics/advance-article-pdf/doi/10.1093/bioinformatics/btae020/56167979/btae020.pdf,Motivation,,The contrastive loss used in contrastive learning strengthens the similarity between positive sample pairs (i.e. a sample and its augmented sample) while increasing the distance between negative sample pairs (i.e. a sample and other samples) (Chen et al. 2020b).,yes,"autoencoder-based method, scMAE",no,,"The masked autoencoder introduces a masking predictor, which captures relationships among genes by predicting whether gene expression values are masked.",background,background
241,DnCNN,Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising,https://www.mdpi.com/1424-8220/23/3/1486/pdf?version=1674977686,Similarities,,"However, these methods all face two problems [7]: (1) the optimization problem in the test stage is very complex, making the denoising process time-consuming; (2) parameters need to be manually adjusted to obtain a better image-denoising effect.",yes,image recognition model,yes,AlexNet,"We propose a new image-denoising model that aims to extract the local features of the image through CNN and focus on the global information of the image through the attention similarity module (ASM), especially the global similarity details of the image",motivation,motivation
242,,,,Background,,"For example, residual learning and bath normalization were applied to a deep convolutional neural network for image denoising (DnCNN) [7] to enhance the learning ability of the model.",yes,image recognition model,yes,VGG,"We propose a new image-denoising model that aims to extract the local features of the image through CNN and focus on the global information of the image through the attention similarity module (ASM), especially the global similarity details of the image",background,background
243,,,,Background,,"Zhang et al. [7] first designed deep CNNs for image denoising (DnCNN), and they improved the performance of the model by stacking multiple convolutional layers, residual learning [10], and batch normalization [21].",yes,image recognition model,yes,ResNet,"We propose a new image-denoising model that aims to extract the local features of the image through CNN and focus on the global information of the image through the attention similarity module (ASM), especially the global similarity details of the image",background,background
244,,,,Uses,,The color image datasets included the Waterloo Exploration Database and BSD432 [7].,yes,image recognition model,yes,DnCNN (our searched model),"We propose a new image-denoising model that aims to extract the local features of the image through CNN and focus on the global information of the image through the attention similarity module (ASM), especially the global similarity details of the image",uses,uses
245,,,,Uses,,The gray image datasets consisted of Set12 and BSD68 [7].,yes,image recognition model,yes,BRDNet,"We propose a new image-denoising model that aims to extract the local features of the image through CNN and focus on the global information of the image through the attention similarity module (ASM), especially the global similarity details of the image",uses,uses
246,,,,Differences,,"For gray image denoising, we chose several state-of-art denoising methods with the same test datasets, including BM3D [5], DnCNN [7], FFDNet [11], BRDNet [14], ADNet [15], and RDN [13].",yes,image recognition model,yes,RDASM,"We propose a new image-denoising model that aims to extract the local features of the image through CNN and focus on the global information of the image through the attention similarity module (ASM), especially the global similarity details of the image",uses,uses
247,Tensorized Transformer (257M),A Tensorized Transformer for Language Modeling,https://aclanthology.org/2021.findings-emnlp.67.pdf,Background,,Ma et al. (2019) combine low rank approximate and parameter sharing to construct a tensorized Transformer.,no,improved transformer model,no,,"In this paper, we present an approach to learning a hard retrieval attention where an attention head only attends to one token in the sentence rather than all tokens.",background,background
248,Perceiver IO,Perceiver IO: A General Architecture for Structured Inputs & Outputs,http://arxiv.org/pdf/2204.05994,Extends,,"Our proposed architecture is based on the Perceiver/PerceiverIO [8, 9] architectures.",yes,Malceiver,yes,Perceiver/PerceiverIO,"We propose the Malceiver, a hierarchical Perceiver model for Android malware detection that makes use of multi-modal features.",uses,uses
249,,,,Background,,"A recent pair of promising approaches, the Perceiver [9] and PerceiverIO [8], change the attention mechanism to use cross-attention rather than self-attention.",yes,Malceiver,yes,Perceiver/PerceiverIO,"We propose the Malceiver, a hierarchical Perceiver model for Android malware detection that makes use of multi-modal features.",background,background
250,,,,Motivation,,The PerceiverIO has been shown to be effective even with input sequences with over 2 million raw elements [8].,yes,Malceiver,yes,Perceiver/PerceiverIO,"We propose the Malceiver, a hierarchical Perceiver model for Android malware detection that makes use of multi-modal features.",background,background
251,,,,Extends,,"We therefore build on the Perceiver/PerceiverIO network architecture [9, 8].",yes,Malceiver,yes,Perceiver/PerceiverIO,"We propose the Malceiver, a hierarchical Perceiver model for Android malware detection that makes use of multi-modal features.",uses,uses
252,GPT-NeoX-20B,GPT-NeoX-20B: An Open-Source Autoregressive Language Model,https://www.biorxiv.org/content/biorxiv/early/2023/07/08/2023.07.06.547963.full.pdf,Future Work,,"With the increasing availability of large-scale annotated MS/MS data, the use of large language models such as LLaMA (Touvron et al., 2023), GPT-NeoX (Black et al., 2022) or Chinchilla (Hoffmann et al., 2022) seems to be a highly promising methodological avenue to train a new generation of structure prediction models in the future.",yes,deep neural netwrok for molecular structure construction,yes,GNPS,Here we report a deep neural network method to predict chemical structures solely from high-resolution MS/MS spectra. This novel approach initially relies on the encoding of SMILES strings from chemical structures using a continuous chemical descriptor space that had been previously implemented for molecule design,background,background
253,AWD-LSTM,On the State of the Art of Evaluation in Neural Language Models,https://europepmc.org/articles/pmc6612801?pdf=render,Background,,"A fair and unbiased comparison can be very challenging especially when considering the sensitivity of deep learning methods to the step of model selection: deep neural networks have many hyper-parameters that require careful tuning, and differences in performance can be the result of the use of different model selection strategies (Lipton and Steinhardt, 2018; Melis et al., 2018).",no,,yes,CNNs + RNNs,"In this study we present a systematic exploration of deep learning architectures for predicting DNA- and RNA-binding specificity. For this purpose, we present deepRAM, an end-to-end deep learning tool that provides an implementation of a wide selection of architectures; its fully automatic model selection procedure allows us to perform a fair and unbiased comparison of deep learning architectures",motivation,motivation
254,Multi-scale Dilated CNN,Multi-Scale Context Aggregation by Dilated Convolutions,https://arxiv.org/pdf/2307.06005,Uses,,"In addition, to capture long-range dependency between words, we also incorporate the dilated convolutional layer [51] that introduces “holes” into each convolution filter.",yes,Discretized Differentiable Neural Architecture Search (DDNAS),yes,Neural Architecture Search (NAS),"This paper presents a novel NAS method, Discretized Differentiable Neural Architecture Search (DDNAS), for text representation learning and classification.",extends,uses
256,SVM for face detection,Training support vector machines: an application to face detection,https://www.mdpi.com/2073-8994/13/4/615/pdf?version=1618226433,Background,,Data classification problems arise and are solved in many areas of human activity [1–7].,yes,two-stage hybrid SVM-kNN classifiers,yes,SVM classifier,The paper considers a solution to the problem of developing two-stage hybrid SVM-kNN classifiers with the aim to increase the data classification quality by refining the classification decisions near the class boundary defined by the SVM classifier.,background,background
257,,,,Background,,"Such problems include the problems of credit risk analysis [1], medical diagnostics [2], text categorization [4], the identification of facial images [7], etc.",yes,two-stage hybrid SVM-kNN classifiers,yes,SVM classifier,The paper considers a solution to the problem of developing two-stage hybrid SVM-kNN classifiers with the aim to increase the data classification quality by refining the classification decisions near the class boundary defined by the SVM classifier.,background,background
258,,,,Motivation,,"Many classification problems are successfully solved using the SVM algorithm [1–7,17–20,24–29].",yes,two-stage hybrid SVM-kNN classifiers,yes,SVM classifier,The paper considers a solution to the problem of developing two-stage hybrid SVM-kNN classifiers with the aim to increase the data classification quality by refining the classification decisions near the class boundary defined by the SVM classifier.,background,background
259,MCDNN (MNIST),Multi-column deep neural networks for image classification,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/bme2.12004,Uses,,These preprocessing steps are applied consistently to all images to artificially increase the dataset size using label‐preserving transformations [46].,yes,"robust deep learning approach for glasses detection, DL architecture",yes,CNN,"In this paper, we present a robust deep learning approach for glasses detection from selfie photos full/ partial frontal body non‐standard images captured in real‐life uncontrolled environments that do not utilize any facial landmarks.",background,background
260,ReLU (LFW),Rectified Linear Units Improve Restricted Boltzmann Machines,https://www.biorxiv.org/content/biorxiv/early/2023/12/02/2023.12.01.569515.1.full.pdf,Uses,,"To learn non-linear patterns, each layer in MetageNN is followed by a ReLU activation function [40].",yes,MetageNN,yes,Rectified Linear Units Improve Restricted Boltzmann Machines,"We present MetageNN, a memory-efficient long-read taxonomic classifier that is robust to sequencing errors and missing genomes. MetageNN is a neural network model that uses short k-mer profiles of sequences to reduce the impact of distribution shifts on error-prone long reads.",background,background
261,Transformer local-attention (NesT-B),"Nested Hierarchical Transformer: Towards Accurate, Data-Efficient and Interpretable Visual Understanding",http://arxiv.org/pdf/2210.05958,Motivation,,"The insufficient training data makes ViT hard to derive the inductive bias of attending locality, thus many recent works strive to introduce local inductive bias by integrating convolution into ViTs [18, 15, 30, 31, 32] and modify it to hierarchical structure [33, 34, 16, 17, 35], making ViTs more like traditional CNNs.",no,,yes,Vision Transformers (ViTs) and Convolutional Neural Networks (CNNs),"In this paper, we further consider this problem and point out two weaknesses of ViTs in inductive biases, that is, the spatial relevance and diverse channel representation.",background,background
262,,,,Motivation,,"To make ViTs more similar to standard CNNs, [16, 54, 17, 34, 33, 35, 57, 32] re-design the spatial and channel dimension of vanilla ViT, producing a series of hierarchical style vision transformer.",no,,yes,Vision Transformers (ViTs) and Convolutional Neural Networks (CNNs),"In this paper, we further consider this problem and point out two weaknesses of ViTs in inductive biases, that is, the spatial relevance and diverse channel representation.",background,background
263,,,,Uses,,"The structure of vision transformer also guarantees this mechanism because the length of input tokens is variable, except for the hierarchical structure vision transformer with window attention such as[17, 35].",no,,yes,Vision Transformers (ViTs) and Convolutional Neural Networks (CNNs),"In this paper, we further consider this problem and point out two weaknesses of ViTs in inductive biases, that is, the spatial relevance and diverse channel representation.",background,background
264,VD-LSTM+REAL Large,Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling,http://arxiv.org/pdf/2203.12644,Uses,,"The word embedding and softmax matrices are tied (Press and Wolf, 2017; Inan et al., 2017)",yes,MemSizer,no,,"We propose MemSizer, an approach towards closing the performance gap while improving the efficiency even with short generation. It projects the source sequences into lower dimension representations like Linformer, while enjoying efficient recurrent-style incremental computation similar to kernel-based transformers.",uses,uses
265,,,,Motivation,,"CNN allowed to achieve impressive results in image recognition, with near human performance on MNIST dataset and outperformed humans on traffic sign recognition by a factor of two [19].",yes,HydraNet CNNs,yes,U-Net architecture,"Based on U-Net architecture we develop HydraNet CNNs which allow segmenting worms accurately into anterior, mid-body and posterior parts",background,background
266,MCDNN (MNIST),Multi-column deep neural networks for image classification,https://www.aging-us.com/article/203916/pdf,Motivation,,"CNN allowed to achieve impressive results in image recognition, with near human performance on MNIST dataset and outperformed humans on traffic sign recognition by a factor of two [19].",yes,WormNet,yes,CNN,"We designed WormNet - a convolutional neural network (CNN) to predict the worm lifespan class based on young adult images (day 1 – day 3 old adults) and showed that WormNet, as well as, InceptionV3 CNN can successfully classify lifespan.",background,background
267,CodeT5+,CodeT5+: Open Code Large Language Models for Code Understanding and Generation,https://arxiv.org/pdf/2308.02582,Differences,,"We have not used other open-source models pretrained on code, such as CodeT5+ (Wang et al., 2023) (768 token length) or Codegen (2048 token length) (Nijkamp et al., 2022) for our study as they do not offer the token length required for our prompt (4K).",yes,LTMP-DA-GP,yes,LLMs,"In contrast, we devise an algorithm which performs offline sampling of a minimal set-of few-shots from the training data, with complete coverage of SQL clauses, operators and functions, and maximal domain coverage within the allowed token length. This allows for synthesis of a fixed Generic Prompt (GP), with a diverse set-of exemplars common across NL test queries, avoiding expensive test time exemplar retrieval. We further auto-adapt the GP to the target database domain (DA-GP), to better handle cross-domain generalization; followed by a decomposed Least-To-Most-Prompting (LTMP-DA-GP)",differences,differences
268,DNABERT,DNABERT: pre-trained Bidirectional Encoder Representations from Transformers model for DNA-language in genome,https://bmcgenomics.biomedcentral.com/counter/pdf/10.1186/s12864-021-08246-1,Motivation,Differences,"The DNAbert model [22] is more related to the present work. It is a transformer neural network, which in the pre-training is trained to predict k-mers (k=3-6) from the surrounding sequence context.",yes,bidirectional Markov model,yes,nucleotide models,We develop a bidirectional Markov model that use an average of the probability from a Markov model applied to both strands of the sequence and thus depends on up to 14 bases to each side of the nucleotide.,background,background
269,Reading Twice for NLU,Dynamic Integration of Background Knowledge in Neural NLU Systems,https://ojs.aaai.org/index.php/AAAI/article/download/17490/17297,Motivation,,"These approaches usually leverage knowledge to enhance a specific CQA component: 1) enhancing representations (Weissenborn, Kocisk ˇ y, and Dyer 2017; Bauer, Wang, and Bansal 2018; ` Mihaylov and Frank 2018; Ma et al. 2019); 2) enhancing attention mechanism (Chen et al. 2018; Wang and Jiang 2019); and 3) enhancing reasoning mechanism (Lin et al. 2019; Lv et al. 2020).",no,,yes,Commonsense Question Answering (CQA) approaches,"? To answer these questions, we benchmark knowledge-enhanced CQA by conducting extensive experiments on multiple standard CQA datasets using a simple and effective knowledgeto-text transformation framework.",background,background
270,Hybrid H3-2.7B,Hungry Hungry Hippos: Towards Language Modeling with State Space Models,https://arxiv.org/pdf/2309.13600,Motivation,,"These approaches provide superior performance in several areas, such as NLP (Mehta et al. 2022; Wang et al. 2022; Dao et al. 2022), speech (Saon, Gupta, and Cui 2023), RL (Lu et al. 2023; David et al. 2022), time series analysis, and more, especially in tasks that require capturing long-range dependencies.",no,,yes,Hyena N-D,"Our empirical findings indicate that the proposed Hyena N-D layer boosts the performance of various Vision Transformer architectures, such as ViT, Swin, and DeiT across multiple datasets",background,background
271,,,,Motivation,,"Recently, several novel sequence layers showed impressive results in 1-D sequence modeling, specifically in improving complexity (Peng et al. 2023; Poli et al. 2023; Dao et al. 2022).",no,,yes,Hyena N-D,"Our empirical findings indicate that the proposed Hyena N-D layer boosts the performance of various Vision Transformer architectures, such as ViT, Swin, and DeiT across multiple datasets",background,background
272,Transformer + Simple Recurrent Unit,Simple Recurrent Units for Highly Parallelizable Recurrence,http://arxiv.org/pdf/2305.13048,Uses,,"The element-wise WKV computation is time-dependent but can be readily parallelized along the other two dimensions (Lei et al., 2018) 3 .",yes,Receptance Weighted Key Value (RWKV),yes,RNNs,"We propose a novel model architecture, Receptance Weighted Key Value (RWKV), that combines the efficient parallelizable training of transformers with the efficient inference of RNNs.",background,background
273,fastText,Bag of Tricks for Efficient Text Classification,http://arxiv.org/pdf/2301.08006,Background,,"In [12], authors employed FastText word representation in conjunction with strategies such as bag of n-gram characteristics and demonstrated that FastText outperformed deep learning approaches while being faster.",yes,Word2Vec remodel,yes,Word2Vec,This paper proposes two novel models for the keyword suggestion task trained on scientific literature. Our techniques adapt the architecture of Word2Vec and FastText to generate keyword embeddings by leveraging documents’ keyword co-occurrence.,background,background
274,,,,Background,,"In [12], authors employed FastText word representation in conjunction with strategies such as bag of n-gram characteristics and demonstrated that FastText outperformed deep learning approaches while being faster.",yes,FastText remodel,yes,FastText,This paper proposes two novel models for the keyword suggestion task trained on scientific literature. Our techniques adapt the architecture of Word2Vec and FastText to generate keyword embeddings by leveraging documents’ keyword co-occurrence.,background,background
275,AmoebaNet-A (F=190),Regularized Evolution for Image Classifier Architecture Search,https://arxiv.org/pdf/2303.08308,Uses,,"Specifically, we design a stage-wise hyperspace to include many candidate search spaces and leverage aging evolution [30] to perform random mutations of elastic stages for search space evolution.",yes,SpaceEvo,yes,Regularized Evolution for Image Classifier Architecture Search,"To address this challenge, we propose SpaceEvo, an automatic method for designing a dedicated, quantizationfriendly search space for each target hardware.",uses,uses
276,,,,Extends,,"By factorizing the search space into a sequence of elastic stages ((Sec. 4.3), we enable traditional aging evolution methods, such as the aging evolution [30], to be directly applied to search the space (Sec. 4.4).",yes,SpaceEvo,yes,Regularized Evolution for Image Classifier Architecture Search,"To address this challenge, we propose SpaceEvo, an automatic method for designing a dedicated, quantizationfriendly search space for each target hardware.",uses,uses
277,,,,Uses,,"Taking this advantage, we leverage aging evolution [30] to search the large hyperspace.",yes,SpaceEvo,yes,Neural Architecture Search (NAS),"To address this challenge, we propose SpaceEvo, an automatic method for designing a dedicated, quantizationfriendly search space for each target hardware.",uses,uses
278,DNABERT,DNABERT: pre-trained Bidirectional Encoder Representations from Transformers model for DNA-language in genome,https://www.biorxiv.org/content/biorxiv/early/2023/08/17/2023.08.15.553415.full.pdf,Background,,"Different approaches to tackle these issues have emerged, including: (1) Developing specific architectures for long sequences (Lin et al. 2021; Rao et al. 2021); (2) Splitting the data into smaller segments (Dotan et al. 2023); (3) K-mer representation of all possible nucleotides (Ji et al. 2021).",no,,yes,"BPE, Unigram, WordPiece, “words”, and “pairs”.","In this work, we study the effect of alternative tokenization algorithms on eight different tasks in biology, from predicting the function of proteins and their stability, through nucleotide sequence alignment, to classifying proteins to specific families.",background,background
279,data2vec (vision),"data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language",https://arxiv.org/pdf/2308.14553,Motivation,,"In the field of automatic speech recognition (ASR), the self-supervised pre-trained models Wav2vec2.0 [13], HuBERT [14], Data2vec [15] and WavLM [16] were proposed recently, and in [17] using the pretrained models to learn different levels of information at different layers was analyzed.",no,,yes,TTS models,"In this work, we therefore explore pre-trained models to improve the noise robustness of TTS models.",background,background
280,BatchNorm,Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift,https://www.mdpi.com/1422-0067/24/21/15681/pdf?version=1698416591,Uses,,The output from the last hidden state is subjected to batch normalization to reduce the covariate shift and provide additional regularization [25].,yes,LSTM4piRNA,yes,LSTM network,"To address these issues, we propose LSTM4piRNA, a highly efficient deep learning-based method for predicting piRNAs in large-scale genome databases.",uses,uses
281,Inception-ResNet-V2,"Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning",https://arxiv.org/pdf/2308.07470,Uses,,"To understand the batching quality of DNN model serving systems, we ran a single copy of ResNet50 [11] (SLO 25 ms) and InceptionResNetV2 [37] (SLO 70 ms) separately on 8 GPUs using Clockwork, Nexus, Shepherd, and Symphony.",yes,Symphony,yes,InceptionResNetV2,"We propose Symphony, a DNN serving system that explores deferred batch scheduling to optimize system efficiency and throughput.",uses,uses
282,,,,Uses,,"We collected a mixed model zoo consisting of 37 widelyused DNN models, including variants of DenseNet [17], EfficientNet [39, 40], Inception [37, 38], MobileNet [13, 14, 32], NASNet [49], ResNet [11, 12], VGG [35], Xception [3], SSDMobileNet [23], and Bert [8].",yes,Symphony,yes,DenseNet,"We propose Symphony, a DNN serving system that explores deferred batch scheduling to optimize system efficiency and throughput.",uses,uses
283,,,,Uses,,"To understand how batch size affects goodput and to study how close is the batching behavior to the ideal staggered execution, we run a single copy of ResNet50 [11] and InceptionResNetV2 [37] separately with 8 GPUs on Symphony, Clockwork, and Nexus. Requests arrive in a Poisson distribution.",yes,Symphony,yes,ResNet50,"We propose Symphony, a DNN serving system that explores deferred batch scheduling to optimize system efficiency and throughput.",uses,uses
284,BERT-Large-CAS (PTB+WT2+WT103),Language Models with Transformers,https://journals.nauss.edu.sa/index.php/JISCR/article/download/1488/1011,Uses,,"The transformer model [85, 133] uses the attention to boost the training speed.",no,,yes,too many,"In this study, research directions and the theoretical foundation in this area are investigated.",background,background
285,Make-A-Video,Make-A-Video: Text-to-Video Generation without Text-Video Data,http://arxiv.org/pdf/2305.08850,Background,Differences,"Diffusion-based generative models have demonstrated remarkable success in generating photorealistic and diverse images [27, 28, 31] and videos [34, 38, 41] conditioned on text.",yes,Make-AProtagonist,yes,Stable UnCLIP,"In this regard, we propose a generic video editing framework called Make-AProtagonist, which utilizes textual and visual clues to edit videos with the goal of empowering individuals to become the protagonists.",background,background
286,,,,Motivation,,"In view of the impressive performance in T2I, text-to-video generation (T2V) [11, 12, 20, 34, 41] has attracted much attention.",yes,Make-AProtagonist,yes,Stable UnCLIP,"In this regard, we propose a generic video editing framework called Make-AProtagonist, which utilizes textual and visual clues to edit videos with the goal of empowering individuals to become the protagonists.",background,background
287,LDM-1.45B,High-Resolution Image Synthesis with Latent Diffusion Models,https://arxiv.org/pdf/2312.08494,Motivation,Uses,"Diffusion models [4, 5, 6] have shown unprecedented success in multiple modalities, such as text-conditional image and audio generation [7, 8], de novo protein design [9], natural language processing [10], and medical imaging [11, 12]. For an extensive survey on the current state of diffusion models and their applications, see [13].",yes,PerMod,yes,Difussion Models,"Towards allowing greater perceptual control over voice, we introduce PerMod, a conditional latent diffusion model that takes in an input voice and a perceptual qualities vector, and produces a voice with the matching perceptual qualities.",background,background
288,Maxout Networks,Maxout Networks,https://www.frontiersin.org/articles/10.3389/fpls.2020.611622/pdf,Uses,,"Multilayer perceptron is a powerful machine learning technique that can characterize the features of the samples and learn the appropriate classification features from the samples (Goodfellow et al., 2016).",no,,yes,Multilayer perceptrons and Vector Machine,"We used hyperspectral imaging data and machine learning to explore the possibility of fast, accurate and automated discrimination of weeds in pastures where ryegrass and clovers are the sown species.",background,background
289,A3C FF hs,Asynchronous Methods for Deep Reinforcement Learning,http://arxiv.org/pdf/2302.02298,Uses,,"This means that one can select other feature extraction models to replace VGG-16 in the first block and can also consider other state-of-the-art algorithms [13]–[15] instead of A3C [31] that is implemented in [21], as long as it can approximate a value function [4].",no,,yes,Deep Reinforced Learning,"In this paper, we review two publications that investigate the mentioned issues of DRL and propose effective solutions.",background,background
291,YOLOv3,YOLOv3: An Incremental Improvement,https://dl.acm.org/doi/pdf/10.1145/3581783.3612412,Background,,"While many architectures have attempted to train on different scales [11, 31], they are all data-driven and fail to provide the necessary guarantees.",yes,ScaleFlow,yes,Neural Networks,"To overcome these limitations, in this work, we propose ScaleFlow, a closed-loop scale-adaptive inference that can reduce model inference time by progressively processing vision data with increasing resolution but decreasing spatial size, achieving speedup without compromising accuracy",motivation,motivation
292,,,,Background,,"However, they only provide a way of quantifying class uncertainty, not location uncertainty [11, 29– 31, 42, 44].",yes,ScaleFlow,yes,Neural Networks,"To overcome these limitations, in this work, we propose ScaleFlow, a closed-loop scale-adaptive inference that can reduce model inference time by progressively processing vision data with increasing resolution but decreasing spatial size, achieving speedup without compromising accuracy",background,background
293,,,,Differences,,"We select several representative object detection neural network models, YOLOv3 [31], CenterNet [44], RetinaNet [23], and FCOS [37] to evaluate our ScaleFlow as an object-detection service with both live streaming from a webcam and pseudo streaming from the COCO dataset [24].",yes,ScaleFlow,yes,Neural Networks,"To overcome these limitations, in this work, we propose ScaleFlow, a closed-loop scale-adaptive inference that can reduce model inference time by progressively processing vision data with increasing resolution but decreasing spatial size, achieving speedup without compromising accuracy",uses,uses
294,,,,Uses,,"In this section, we explore opportunities for improving neural network speed through scale-adaptive designs, using a motivational study with YOLOv3 [31] object detection on COCO dataset [24].",yes,ScaleFlow,yes,Neural Networks,"To overcome these limitations, in this work, we propose ScaleFlow, a closed-loop scale-adaptive inference that can reduce model inference time by progressively processing vision data with increasing resolution but decreasing spatial size, achieving speedup without compromising accuracy",uses,uses
295,,,,Differences,,"We choose five neural network architectures designed for object detection, YOLOv3 [31], CenterNet [44], RetinaNet [23], and FCOS [37], EfficientDet [36]. Due to space constraints, some experiments only use YOLOv3 and CenterNet as representative anchorbased and anchor-free model",yes,ScaleFlow,yes,Neural Networks,"To overcome these limitations, in this work, we propose ScaleFlow, a closed-loop scale-adaptive inference that can reduce model inference time by progressively processing vision data with increasing resolution but decreasing spatial size, achieving speedup without compromising accuracy",uses,uses
296,WizardCoder-15.5B,WizardCoder: Empowering Code Large Language Models with Evol-Instruct,https://arxiv.org/pdf/2310.05103,Motivation,,"Recently, WizardCoder (Luo et al., 2023) significantly outperforms other open-source Code LLMs by employing the Evol-Instruct method for complex instruction fine-tuning.",no,,yes,DetectGPT,"This work proposes a training-free approach for the detection of LLMs-generated codes, mitigating the risks associated with their indiscriminate usage.",background,background
297,ShuffleNet v1,ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices,https://arxiv.org/pdf/2308.13343,Motivation,,"There are architectures like Structured transform networks [11], Deep fried convnets [15], Shufflenet [19] which have considered computational aspects as well",yes,SaEnet,yes,CNN,"We propose SaEnet, Squeeze aggregated excitation network, for learning global channelwise representation in between layers.",background,background
298,VQGAN + CLIP,Taming Transformers for High-Resolution Image Synthesis,https://arxiv.org/pdf/2304.08945,Background,,"From then on, transformer-based models have been exploited for different tasks, including object detection [29], image generation [30]), video understanding [31], etc.",yes,DIRFA,yes,transformer architecture,"This paper presents DIRFA, a novel method that can generate talking faces with diverse yet realistic facial animations from the same driving audio.",background,background
299,BellKor 2007,The BellKor solution to the Netflix Prize,https://ojs.aaai.org/index.php/ICWSM/article/download/15013/14863,Background,,Such applications have made extensive use of Matrix Factorization methods that have been popularized during the Netflix Prize (Bell and Koren 2007).,yes,,no,,"However, collaboration patterns are difficult to capture when the relationships between users are not directly observable, since they need to be inferred from the user actions. In this work, we propose a solution to this problem by adopting a systemic view of collaboration.",background,background
300,Transformer + Simple Recurrent Unit,Simple Recurrent Units for Highly Parallelizable Recurrence,https://ieeexplore.ieee.org/ielx7/6287639/8600701/08786773.pdf,Motivation,,"The first architecture of RNNs is based on the simple recurrent units (SRUs), which is simple and fast. However, it suffers from the vanishing gradient problem [29].",yes,,yes,SRUs and GRUs in neural networks,"In this paper, we propose an effective multi-sensors-based framework for human activity recognition using a hybrid deep learning model, which combines the simple recurrent units (SRUs) with the gated recurrent units (GRUs) of neural networks.",motivation,motivation
301,Conformer + Wav2vec 2.0 + Noisy Student,Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition,http://arxiv.org/pdf/2210.07677,Differences,,"Namely, we compare against the high-performing self-supervised speech representations models wav2vec 2.0 [2], Conformer [23], and w2v-BERT models [4].",yes,TransFusion,yes,LibriSpeech,"Specifically, we propose TransFusion: a transcribing diffusion model which iteratively denoises a random character sequence into coherent text corresponding to the transcript of a conditioning utterance",uses,uses
302,,,,Differences,,"We compare against three state-of-the-art models for ASR: wav2vec 2.0 [2], Conformer [23], and w2v-BERT [4].",yes,TransFusion,yes,LibriSpeech,"Specifically, we propose TransFusion: a transcribing diffusion model which iteratively denoises a random character sequence into coherent text corresponding to the transcript of a conditioning utterance",uses,uses
303,,,,Differences,,"This differs from the baselines, all of which have been trained with substantial data augmentation to further improve performance [2, 23, 4].",yes,TransFusion,yes,LibriSpeech,"Specifically, we propose TransFusion: a transcribing diffusion model which iteratively denoises a random character sequence into coherent text corresponding to the transcript of a conditioning utterance",differences,differences
304,LSTM with forget gates,Learning to Forget: Continual Prediction with LSTM,https://www.mdpi.com/2075-1680/12/3/266/pdf?version=1679978199,Background,,"Different types of ANNs include shallow networks, deep networks, convolutional neural networks (CNNs), and recurrent neural networks (RNNs) [29,30].",no,,yes,long short-term memory (LSTM),"In the current study, the use of an LSTM and a bidirectional LSTM (BiLSTM) is proposed for dealing with a data collection that, besides the time series values denoting the solar energy generation, also comprises corresponding information about the weather.",background,background
305,Part-of-sentence tagging model,End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF,https://www.aclweb.org/anthology/2020.coling-main.245.pdf,Uses,,"Secondly, we propose to use a BiLSTM-CNN architecture (Ma, 2016) that integrates character embeddings as additional features, using a convolution layer.",no,,yes,Neural Networks,"Since the MEDIA task seems to be one of the most difficult, according to several previous studies, we propose to explore Neural Networks approaches focusing of three aspects: firstly, the Neural Network inputs and more specifically the word embeddings; secondly, we compared French version of BERT against the best setup through different ways; Finally, the comparison against State-of-the-Art approaches.",uses,uses
306,,,,Extends,,"To further improve the performance of our SLU model, we propose to use a BiLSTM-CNN (convolutional neural network) architecture (Ma, 2016) that integrates character embeddings using a convolution layer, in addition to the word embeddings.",no,,yes,Neural Networks,"Since the MEDIA task seems to be one of the most difficult, according to several previous studies, we propose to explore Neural Networks approaches focusing of three aspects: firstly, the Neural Network inputs and more specifically the word embeddings; secondly, we compared French version of BERT against the best setup through different ways; Finally, the comparison against State-of-the-Art approaches.",uses,uses
307,,,,Extends,,"In this section, we propose to use a BiLSTM-CNN architecture (Ma, 2016) that integrates character embeddings as additional features, using a convolution layer.",no,,yes,Neural Networks,"Since the MEDIA task seems to be one of the most difficult, according to several previous studies, we propose to explore Neural Networks approaches focusing of three aspects: firstly, the Neural Network inputs and more specifically the word embeddings; secondly, we compared French version of BERT against the best setup through different ways; Finally, the comparison against State-of-the-Art approaches.",uses,uses
308,Unsupervised Scale-Invariant Learning,Object class recognition by unsupervised scale-invariant learning,https://isprs-archives.copernicus.org/articles/XL-1-W1/333/2013/isprsarchives-XL-1-W1-333-2013.pdf,Background,,"Later, Webber et. al (2000) represent objects as constellations of rigid parts, and recognized objects with a join probability density function on the shape of rigid parts by similarity matching. Fergus et. al (2003) and Opelt et. al (2004) proposed category models composed of some more flexible parts, and estimated the parameters of the parts using expectation-maximization algorithm.",yes,hierarchical semantic graph model,no,,"In this paper, we propose a hierarchical semantic graph model to detect and recognize man-made objects in high resolution remote sensing images automatically.",background,background
309,ProGen2-xlarge,ProGen2: Exploring the Boundaries of Protein Language Models,https://journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.1011162&type=printable,Background,,"Recently, self-supervised masked language models of biological sequences have been used to study proteins [14–21], DNA [22], RNA [23, 24], and glycans [25, 26].",yes,,yes,BERT,"Here, we introduce a selfsupervised learning approach designed to identify and characterize BGCs from such data.",background,background
311,GSM,Gated Self-Matching Networks for Reading Comprehension and Question Answering,https://ojs.aaai.org/index.php/AAAI/article/download/4591/4469,Background,,"It means that hp, the state at the position that we attend to, is used for comparing with the sentence representations to encode position information, and ht is used for matching the sentence representations against itself (self-matching) to collect information from the context (Wang et al. 2017).",yes,,yes,NLP,"To this end, we first design a tagging scheme to generate n tag sequences for an n-word sentence. Then a position-attention mechanism is introduced to produce different sentence representations for every query position to model these n tag sequences. In this way, our method can simultaneously extract all entities and their type, as well as all overlapping relations",background,background
312,,,,Motivation,,"Attention mechanisms are used to model dependencies of input and output sequences, and are successfully applied in various NLP tasks (Bahdanau, Cho, and Bengio 2014; Vaswani et al. 2017; Cheng, Dong, and Lapata 2016; Wang et al. 2017",yes,,yes,NLP,"To this end, we first design a tagging scheme to generate n tag sequences for an n-word sentence. Then a position-attention mechanism is introduced to produce different sentence representations for every query position to model these n tag sequences. In this way, our method can simultaneously extract all entities and their type, as well as all overlapping relations",background,background
313,Part-of-sentence tagging model,End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF,https://arxiv.org/pdf/2008.12014,Extends,,"For both PoS tagging and NER, we experiment with an established neural sequence tagging model, dubbed BILSTM-CNN-CRF, introduced by Ma and Hovy [22].",yes,GREEK-BERT,yes,NLP,"In this paper, we present GREEK-BERT, a monolingual BERT-based language model for modern Greek.",uses,uses
314,ALIGN,Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision,http://arxiv.org/pdf/2304.09172,Uses,,"Approaches such as CLIP (Radford et al., 2021) and ALIGN (Jia et al., 2021) have catalyzed a lot of recent progress in computer vision by showing that Transformer-based (Vaswani et al., 2017) models trained using large amounts of image-text data from the internet can yield transferable representations, and such models can perform zero-shot recognition and retrieval using natural language queries.",yes,MERU,yes,CLIP,"We propose MERU, a contrastive model that yields hyperbolic representations of images and text.",background,background
315,,,,Uses,,"Our method conceptually resembles current state-of-the-art contrastive methods (Jia et al., 2021; Radford et al., 2021).",yes,MERU,yes,CLIP,"We propose MERU, a contrastive model that yields hyperbolic representations of images and text.",similarities,similarities
316,,,,Uses,,"More recent approaches like CLIP (Radford et al., 2021) and ALIGN (Jia et al., 2021) use contrastive metric learning to pre-train Vision Transformers (Dosovitskiy et al., 2021) and have helped to better realize the motivations of the earlier works in practice.",yes,MERU,yes,CLIP,"We propose MERU, a contrastive model that yields hyperbolic representations of images and text.",background,background
318,EDSR,Enhanced Deep Residual Networks for Single Image Super-Resolution,https://www.mdpi.com/1424-8220/23/21/8717/pdf?version=1698285540,Background,,"For example, EDSR [26] has more than 40M parameters, and the huge computing power requirement makes it almost impossible to deploy in embedded devices, which limits its practical application",yes,dynamic attention mechanism-based thermal image super-resolution network (LDASRNet),yes,"shallow feature extraction (SFE) module, a deep feature extraction (DFE) module and a feature reconstruction (FRec) module.","In this paper, we propose a dynamic attention mechanism-based thermal image super-resolution network for infrared sensors. Specifically, the dynamic attention modules adaptively reweight the outputs of the attention and non-attention branches according to features at different depths of the network",motivation,motivation
319,,,,Differences,,"Unlike SRResNet [33], EDSR [26] consists of 32 residual blocks that remove batch normalization, reducing memory consumption and artifacts",yes,dynamic attention mechanism-based thermal image super-resolution network (LDASRNet),yes,"shallow feature extraction (SFE) module, a deep feature extraction (DFE) module and a feature reconstruction (FRec) module.","In this paper, we propose a dynamic attention mechanism-based thermal image super-resolution network for infrared sensors. Specifically, the dynamic attention modules adaptively reweight the outputs of the attention and non-attention branches according to features at different depths of the network",background,background
320,,,,Differences,,"To verify that LDASRNet has comparable or even better performance than larger networks, we select models AWSRN [65], SRMDNF [67], CARN [68], ChaSNet [44], MPRANet [1] and MDSR [26] with parameters ranging from 1.4M to 6.5M for comparison.",yes,dynamic attention mechanism-based thermal image super-resolution network (LDASRNet),yes,"shallow feature extraction (SFE) module, a deep feature extraction (DFE) module and a feature reconstruction (FRec) module.","In this paper, we propose a dynamic attention mechanism-based thermal image super-resolution network for infrared sensors. Specifically, the dynamic attention modules adaptively reweight the outputs of the attention and non-attention branches according to features at different depths of the network",uses,uses
321,,,,Differences,,"In addition, we select RCAN [24] and EDSR [26], two networks with parameters exceeding 10M (EDSR has more than 40M parameters) as reference.",yes,dynamic attention mechanism-based thermal image super-resolution network (LDASRNet),yes,"shallow feature extraction (SFE) module, a deep feature extraction (DFE) module and a feature reconstruction (FRec) module.","In this paper, we propose a dynamic attention mechanism-based thermal image super-resolution network for infrared sensors. Specifically, the dynamic attention modules adaptively reweight the outputs of the attention and non-attention branches according to features at different depths of the network",uses,uses
322,Megatron-BERT,Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism,https://www.nature.com/articles/s41746-022-00742-2.pdf,Uses,,We used a total number of 992 NVIDIA DGX A100 GPUs from 124 superPOD nodes at UF’s HiPerGator-AI cluster to train GatorTron models by leveraging both data-level and model-level parallelisms implemented by the Megatron-LM package [43].,no,,yes,GatorTron,We examine how (1) scaling up the number of parameters and (2) scaling up the size of the training data could benefit these NLP tasks.,uses,uses
323,LSTM,Long Short-Term Memory,https://journal.uob.edu.bh:443/bitstream/123456789/5190/3/IJCDS150130_1570911792.pdf,Uses,,We employed VGG16 [20] and LSTM [21] networks for image captioning. Figure 3 block diagram for image captioning.,yes,CNBD-Combinational Network for Bullying Detection,yes,Binary Encoder Image Transformer (BEiT) and Multi-Layer Perceptron (MLP) network,"We proposed a deep learning technique named as CNBD-Combinational Network for Bullying Detection (CNBD), which is a combination of two networks: Binary Encoder Image Transformer (BEiT) and Multi-Layer Perceptron (MLP) network.",uses,uses
324,Galactica,Galactica: A Large Language Model for Science,http://arxiv.org/pdf/2305.16636,Uses,,"When constructing our training set, we use incontext few-shot learning with the 6.7B parameter version of Galactica (Taylor et al., 2022).",yes,DataFinder Dataset,yes,GPT-3 and Galactica,"To facilitate this task, we build the DataFinder Dataset which consists of a larger automatically-constructed training set (17.5K queries) and a smaller expertannotated evaluation set (392 queries).",uses,uses
325,,,,Uses,,"We simulate query collection with the 6.7B parameter version of Galactica (Taylor et al., 2022), a large scientific language model that supports fewshot learning.",yes,DataFinder Dataset,yes,GPT-3 and Galactica,"To facilitate this task, we build the DataFinder Dataset which consists of a larger automatically-constructed training set (17.5K queries) and a smaller expertannotated evaluation set (392 queries).",uses,uses
326,,,,Uses,,"To encourage more efficient labeling (Wang et al., 2021), we provided autosuggestions for each field from GPT-3 (Brown et al., 2020) and Galactica 6.7B (Taylor et al., 2022) to help annotators.",yes,DataFinder Dataset,yes,GPT-3 and Galactica,"To facilitate this task, we build the DataFinder Dataset which consists of a larger automatically-constructed training set (17.5K queries) and a smaller expertannotated evaluation set (392 queries).",uses,uses
327,Meena,Towards a Human-like Open-Domain Chatbot,https://arxiv.org/pdf/2010.03450,Background,,"However, recent success on many language understanding problems (Wang et al., 2019), the impressive generation capabilities of modern dialog systems (Zhang et al., 2019; Adiwardana et al., 2020), as well as the huge interest in yes/no question-answering (Choi et al., 2018; Clark et al., 2019) have created a conducive environment for revisiting this hard task.",yes,Circa,no,,"We create and release1 the first large-scale English language corpus ‘Circa’ with 34,268 (polar question, indirect answer) pairs to enable progress on this task.",background,background
328,LDA,Latent Dirichlet Allocation,https://arxiv.org/pdf/2310.07739,Uses,,LDA works by selecting the number of clusters that yielded the largest coherence value [49].,no,,yes,LDA,"In this paper, we investigate the supply-demand dynamics of the four presidential candidates of Taiwan, using 911,510 Facebook posts from public figures, pages, and public groups, provided by CrowdTangle.",background,background
329,,,,Uses,,"After filtering the data sources by policy issues and candidates, we employed the two keyword extraction methods: frequency counts and Latent Dirichlet Allocation (LDA) for topic modeling.",no,,yes,LDA,"In this paper, we investigate the supply-demand dynamics of the four presidential candidates of Taiwan, using 911,510 Facebook posts from public figures, pages, and public groups, provided by CrowdTangle.",uses,uses
330,DINOv2,DINOv2: Learning Robust Visual Features without Supervision,http://arxiv.org/pdf/2305.19256,Uses,,"Specifically, we generate 10000 images from each model and we use DINO [9]-v2 [42] to compute top-1 similarity to the training images.",yes,first diffusion-based framework that can learn an unknown distribution,yes,DINOv2,We present the first diffusion-based framework that can learn an unknown distribution using only highly-corrupted samples.,uses,uses
331,Temporal Convolutional Attention-based Network(TCAN) (WT2),Temporal Convolutional Attention-based Network For Sequence Modeling,https://arxiv.org/pdf/2211.13114,Future Work,,Our future work will investigate modifying TCNs [27] and attentionbased TCNs [28] to handle variable-length sequences and applying them to signal-level SC.,no,,yes,LSTM,"To circumvent these requirements, we present a novel SC approach utilizing many-to-one attention-based LSTM. With the proposed LSTM network, SC is solved as a regression problem, taking the entire sensor signal as input and the step count as the output. The analysis shows that the attention-based LSTM automatically learned the pattern of steps even in the absence of groundtruth labels.",future_work,future_work
333,Enhanced Neighborhood-Based Filtering,Scalable Collaborative Filtering with Jointly Derived Neighborhood Interpolation Weights,https://arxiv.org/pdf/1509.09130,Motivation,,Taking into account the popularity of items in order to improve the recommendation has been considered before by [8] who design a greedy sequential preprocessing procedure aimed at subtracting different explanatory effects that may have an influence on the data,no,,no,,"In this contribution, we provide statistical evidence that existing movie recommendation datasets reveal a significant positive association between the rating of items and the propensity to select these items.",background,background
334,,,,Background,,These include standard user and item rating effects as well as popularity —referred to as “support” in [8]— and time-related effects,no,,no,,"In this contribution, we provide statistical evidence that existing movie recommendation datasets reveal a significant positive association between the rating of items and the propensity to select these items.",background,background
335,,,,Motivation,,"Interestingly, [8] uses successive Bayesian regressions for each effect to reduce the variability inherent in using a linear model with many missing observations.",no,,no,,"In this contribution, we provide statistical evidence that existing movie recommendation datasets reveal a significant positive association between the rating of items and the propensity to select these items.",background,background
336,,,,Future Work,,"An alternative would be to use a Bayesian mean estimate, as in [8], to shrink the estimates towards the global mean rating for scarcely observed items.",no,,no,,"In this contribution, we provide statistical evidence that existing movie recommendation datasets reveal a significant positive association between the rating of items and the propensity to select these items.",background,background
337,Llama 2-70B,Llama 2: Open Foundation and Fine-Tuned Chat Models,https://www.biorxiv.org/content/biorxiv/early/2023/11/29/2023.11.28.568945.full.pdf,Background,,"In recent years, generative models have emerged as powerful tools for generating creative and diverse content, ranging from text [15]–[17], images [18], [19] to speech [20] and more",no,,yes,LLM,"In particular, we introduce an optimization pipeline that utilizes Large Language Models (LLMs) to pinpoint the mutation hotspots in the sequence and then suggest replacements to improve the overall fitness.",background,background
338,Meta Pseudo Labels,Meta Pseudo Labels,https://arxiv.org/pdf/2208.12633,Differences,,"Other research fields include semi-supervised learning, where only parts of the data are annotated (Pham et al., 2021), and synthetic datasets, where more training data are generated (Xu et al., 2019).",no,,yes,Extreme Gradient Boosting (XGBoost),The limitations can be overcome by proposing a pipeline to process remote sensing images into feature-based representations that allow the employment of Extreme Gradient Boosting (XGBoost) for yield prediction.,background,background
339,Deep LSTM for video classification,Beyond short snippets: Deep networks for video classification,https://www.nature.com/articles/s41598-023-35938-3.pdf,Uses,,The target model consists of an LSTM-CNN encoder [101] and a classifcation head Ht.,yes,,yes,CT,"To address this problem, we develop a three-level optimization based method which leverages CT data from a source domain to mitigate the lack of labeled CT scans in a target domain. Our method automatically identifes and downweights low-quality source CT data examples which are noisy or have large domain discrepancy with target data, by minimizing the validation loss of a target model trained on reweighted source data.",uses,uses
340,RBM-tuning,A Practical Guide to Training Restricted Boltzmann Machines,https://arxiv.org/pdf/1812.05477,Motivation,,Replacing binary units with Gaussian units can be performed by modifying the energy function [12].,yes, GPDB,yes,ShapeOdd,In this paper we present a generative model of shapes which provides a low dimensional latent encoding which importantly resides on a smooth manifold with respect to the silhouette images.,background,background
341,VQGAN + CLIP,Taming Transformers for High-Resolution Image Synthesis,https://arxiv.org/pdf/2308.15300,Differences,,"Unlike the widely-used generative models including GANs [48], [49] and VAEs [39], [50], which learn the data distribution by a proxy adversarial task or maximizing the ELBO, the flow models explicitly estimate arbitrary data distribution through the bijective invertible normalizing flows",yes,MSFlow,yes,Real-NVP,"o generalize the anomaly size variation, we propose a novel Multi-Scale Flow-based framework dubbed MSFlow composed of asymmetrical parallel flows followed by a fusion flow to exchange multi-scale perceptions.",differences,differences
342,XLM,Cross-lingual Language Model Pretraining,https://jurnal.stmikroyal.ac.id/index.php/jurteksi/article/download/2492/1253,Uses,,Can predict the next token in sequence because it is trained with Casual Language Modeling (CLM) goals[17].,no,,yes,GPT-2,"This research proposes a Transformer model with an Attention mechanism that can fetch important information, solve parallelization problems, and summarize long texts. The Transformer model we propose is GPT-2.",background,background
346,OpenAI Five,Dota 2 with Large Scale Deep Reinforcement Learning,https://arxiv.org/pdf/2104.07294,Background,,"Several methods have been proposed to try to either reduce the space of actions by re-using model outputs for different action types [2], [3], provide side information to facilitate the exploration of large numbers of possible actions [4]–[6], or simplify the manipulation of the action spaces through action embeddings via mechanisms such as attention and graphs networks [7]–[9]. I",yes,Conditional Action Trees,no,,,background,background
347,"Variational (untied weights, MC) LSTM (Large)",A Theoretically Grounded Application of Dropout in Recurrent Neural Networks,https://aclanthology.org/2021.acl-long.101.pdf,Background,,"Moreover, we include variational dropout (Gal and Ghahramani, 2016) as a comparison since it was used in a previous work on zero-shot translation (Pham et al., 2019) instead of the standard element-wise dropout.",yes,"Transformer
(Vaswani et al., 2017) with 5 encoder and decoder
layers. For the Europarl datasets with more training data, we enlarge the model to 8 encoder and
decoder layers.",no,,"Found this very interesting, it involves translations",uses,uses
348,Fast R-CNN,Fast R-CNN,https://wepub.org/index.php/TCSISR/article/download/369/341,Uses,,"In the development process of target detection algorithm, there are two branches, one is RCNN, fast RCNN and fast CNN, i.e. fastrcnn series [13-16], in which RCNN generates 1k~2k candidate boxes from a graph, extracts features from candidate regions and sends them to SVM classifier, and uses regression to refine the position.",yes,e BSSD algorithm based on SSD algorithm,yes,Fast R-CNN,,background,background
349,"MSRA (C, PReLU)",Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification,http://www.cell.com/article/S2405844023052945/pdf,Background,,"It would be equally true that the DNN performance is heavily affected by the weight parameter initialization methods [55,56].",no,,no,,,background,background
350,GPipe (Transformer),GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism,https://dl.acm.org/doi/pdf/10.1145/3470496.3527405,Uses,,"To efficiently train these models, a variety of techniques have been used to exploit both pipelined (model) parallelism [30][19] and data (mini-batch) parallelism.",yes,software-scheduled routing algorithm allows the automatic parallelizing compiler to load balance the global links of the Dragonfly network,yes,pipeline parallelism,,background,background
351,SVD in recommender systems,Application of Dimensionality Reduction in Recommender System - A Case Study,http://www.aaai.org/Papers/Workshops/2006/WS-06-10/WS06-10-005.pdf,Background,,"Collaborative filtering algorithms range from the simple nearest-neighbor methods (Breese, Heckerman, & Kadie 1998; Resnick et al. 1994; Sarwar et al. 2001) to more complex machine learning based methods such as graph based methods (Aggarwal et al. 1999; Huang, Chen, & Zeng 2004), linear algebra based methods (Billsus & Pazzani 1998; Sarwar et al. 2000; Goldberg et al. 2001; Marlin & Zemel 2004; Rennie & Srebro 2005; DeCoste 2006), and probabilistic methods (Hofmann & Puzicha 1999; Pennock et al. 2000; Popescul et al. 2001; Karypis 2001; Deshpande & Karypis 2004).",yes,MAD 6.00,no,,,background,background
352,AlphaFold 2,Single-sequence protein structure prediction using a language model and deep learning,https://www.biorxiv.org/content/biorxiv/early/2023/01/20/2023.01.18.524637.full.pdf,Background,,"The a-helical CTD conformation was also missed by RoseTTAfold3 and RGN256, an MSA-independent deep learning method that outperforms AlphaFold2 on orphan protein sequences (Extended Data Figure 3).",no,,no,,,differences,differences
353,NASv3 (CIFAR-10),Neural Architecture Search with Reinforcement Learning,http://arxiv.org/pdf/2301.01299,Background,,"On the other hand, NAS techniques [181] have been widely used to search a crafted architecture based on the data in each device, thus leading to the model heterogeneity situation.",no,,no,,,background,background
354,Bayesian automated hyperparameter tuning,Practical Bayesian Optimization of Machine Learning Algorithms,https://www.mdpi.com/2075-163X/12/12/1621/pdf?version=1671195392,Background,,"Contemporary HPO algorithms can be mainly divided into grid-based search (grid), Bayesian optimization (Bayesian), gradient-based optimization (gradient-based), and population-based optimization (evolutionary algorithm, genetic algorithm, etc.), among which the grid search and Bayes-based optimization are the most Minerals 2022, 12, 1621 3 of 25 popular [104–110]",yes,random search-GBDT,no,,,background,background
355,W2v-BERT,w2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-Supervised Speech Pre-Training,https://arxiv.org/pdf/2303.01664,Uses,,"For the input feature, instead of a log-mel spectrogram used in conventional methods [1,4], we use a speech representation extracted from w2v-BERT [20], an SSL model trained on degraded speech samples.",yes,Miipher,yes,w2v-BERT,,differences,differences
356,DINOv2,DINOv2: Learning Robust Visual Features without Supervision,https://arxiv.org/pdf/2302.14051,Background,,"Concurrent work (Oquab et al., 2023) attempts to address this by adding a “onetime” automatic data curation step that keeps only the most relevant images from a static web crawl dataset",no,,no,,,background,background
357,NTM,Neural Turing Machines,https://arxiv.org/pdf/2211.06441,Background,,"Environment forcing also enables a neural network to access long-range, persistent memory in a
very different way than previous approaches, such as LSTM (Hochreiter & Schmidhuber, 1997),
Neural Turing Machines (Graves et al., 2014), or Memory Networks (Weston et al., 2014). These
methods can be thought of as improving long-range memory by alleviating difficulties associated
with back-propagating through many time-steps",no,,no,,,background,background
358,M6-T,M6-T: Exploring Sparse Expert Models and Beyond Anonymous ACL submission,https://aclanthology.org/2023.findings-eacl.180.pdf,Background,,"Following this, M6- T (Yang et al., 2021) splits experts into k prototypes (i.e., groups of experts).",no,,no,,,background,background
359,DeepNet,"DeepNet: Scaling Transformers to 1, 000 Layers",http://arxiv.org/pdf/2306.02701,Background,,"For example, ResNet101[8] has 101 layers, Swin-L[9] has 120 layers and DeepNet even has 1000 layers [10].",no,,no,,,background,background
360,Cross-Lingual POS Tagger,Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections,https://www.aclweb.org/anthology/E17-1084.pdf,Background,,"Crosslingual word embeddings can also be used in transfer learning, where the source model is trained on one language and applied directly to another language; this is suitable for the low-resource scenario (Yarowsky and Ngai, 2001; Duong et al., 2015b; Das and Petrov, 2011; Tackstr ¨ om et al., ¨ 2012).",yes,multilingual joint training model with explicit mapping,no,,,background,background
361,Universal approximation via Feedforward Networks,Multilayer feedforward networks are universal approximators,http://arxiv.org/pdf/2306.06913,Background,,"Relying on the degree characteristics and the universal approximation theorem of the MLP [51], The semantics of aggregation weights of both GCN and GraphSAGE can be approximated by GT, which
shows the aggregation of GCN and GraphSAGE are special
forms of the outer head of GT layer.",yes,NRL-GT,no,,,uses,uses
362,R-FCN,R-FCN: Object Detection via Region-based Fully Convolutional Networks,https://www.mdpi.com/2072-4292/14/4/950/pdf?version=1645156165,Background,,The convolutional neural network (CNN) model is the most widely used deep learning model [13–22]. CNN does not need to use artificially designed features and can learn and extract effective features of the image using massive images and annotations,yes,(CNN-AOOF),no,,,background,background
366,Chinchilla,Training Compute-Optimal Large Language Models,http://arxiv.org/pdf/2210.04909,Background,,"Anticipating this scaling trend to remain in vogue for the foreseeable future [6–8], it is imperative that we understand how to scale up models intelligently.",Yes,,Yes,,,motivation,motivation
368,Naive Bayes,Pattern classification and scene analysis,https://strathprints.strath.ac.uk/76660/1/Venerandi_Fusco_ICCSA_2020_Describing_the_residential_valorisation_of_urban_space_at_the_street_level.pdf,Background,Uses,"Such variable is linked to each individual variable through oriented arcs, in what is called a naive Bayes classifier [16].",Yes,,Yes,Bayesian clustering,,background,background
369,MetaLM,Language Models are General-Purpose Interfaces,http://arxiv.org/pdf/2302.07842,Background,,"As recently demonstrated by Hao et al. (2022) and Alayrac et al. (2022), LMs can also be used as a general-purpose interface with models pre-trained on different modalities.",Yes,Augmented Language Models,Yes,Augmented Language Models,,background,background
371,BART-large,"BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",https://arxiv.org/pdf/2310.01558,Background,,"A dominant approach for combating this issue has been Retrieval Augmented Language Models (RALMs), which incorporate a retrieval mechanism to reduce the need for storing information in the LLM parameters (Guu et al., 2020; Lewis et al., 2020b; Izacard et al., 2022; Rubin & Berant, 2023).",Yes,fine tuned,Yes,RALM,,background,background
373,Word Representations,Word Representations: A Simple and General Method for Semi-Supervised Learning,http://fulir.irb.hr/4124/7/Document-based%20topic%20coherence%20measures%20for%20news%20media%20text%20%5Bpostprint%20version%5D.pdf,Uses,,"This method of aggregation relies on pre-constructed word embeddings (Turian et al., 2010): low-dimensional, continuous-valued vectorial representations of words’ meanings derived from word co-occurrences in a large text corpus.",Yes,,Yes,Topic model,,background,background
374,InstructGPT,Training language models to follow instructions with human feedback,https://aclanthology.org/2023.findings-emnlp.983.pdf,Background,,"For nontoxic text generation, model retraining with auxiliary information is used, including control codes as in - CTRL (Keskar et al., 2019) or reinforcement learning from human feedback - InstructGPT (Ouyang et al., 2022).",Yes,Gated Toxicity Avoidance (GTA),Yes,Controllable Text Generation (CTG),,uses,uses
375,Base LM + kNN LM + Continuous Cache,Generalization through Memorization: Nearest Neighbor Language Models,https://arxiv.org/pdf/2308.04215,Background,,"Various methods have been proposed to integrate the retrieved data into the language model, including the use of prompts (Lewis et al., 2020; Guu et al., 2020; Shi et al., 2023), crossattention modules (Borgeaud et al., 2021), vector concatenation (Izacard and Grave, 2021; Fan et al., 2021), and output distribution adjustment at decoding (Khandelwal et al., 2020; Liu et al., 2022).",Yes,Hybrid RetrievalAugmented Generation (HybridRAG),Yes,Hybrid RetrievalAugmented Generation (HybridRAG),,background,background
376,EfficientZero,Mastering Atari Games with Limited Data,https://intellrobot.com/article/download/5115,Background,,"For sequential decision making problems, model-based planning is a powerful approach to improve sample efficiency and has achieved great success in applied domains such as game playing[79–81] and continuous control[82,83]",No,,No,,,background,background
377,Residual Dense Network,Residual Dense Network for Image Super-Resolution,https://www.mdpi.com/2079-9292/11/22/3809/pdf?version=1669116005,Background,Motivation,They are mainly PSNR-oriented and GAN-driven methods. PSNR-oriented methods [1–6] are trained with the MSE or L1 as loss functions and achieve excellent PSNR,Yes,epistemic-uncertainty-based divide-and-conquer network (EU-DC),Yes,epistemic-uncertainty-based divide-and-conquer network (EU-DC),,background,background
378,LRSO-GAN,Unlabeled Samples Generated by GAN Improve the Person Re-identification Baseline in Vitro,https://arxiv.org/pdf/2004.08787,Uses,,The experiments were conducted over two public datasets Market1501 [58] and DukeMTMC-ReID [36] [59] by using the evaluation metrics Cumulative Matching Characteristic (CMC) curve and mean average precision (mAP).,Yes,augmented discriminative clustering (AD-Cluster),Yes,"ResNet-50, ImageNet",,uses,uses
379,GoogLeNet / InceptionV1,Going deeper with convolutions,https://www.frontiersin.org/articles/10.3389/fpls.2023.1328952/pdf?isPublishedV2=False,Uses,Differences,"These experiments involved benchmarking the proposed approach against several state-of-the-art methods, namely AlexNet Krizhevsky et al. (2012), GoogleNet Szegedy et al. (2014), VGG Abas et al. (2018), ResNet101 Zhang (2021), EfficientNetB3 Singh et al. (2022), Inception V3 Jenipher and Radhika (2022), MobileNet V2140 Elfatimi et al. (2022), and vision transformer Dosovitskiy et al. (2020).",Yes,,Yes,GoogLeNet,An interesting paper that classifys leaf diseases in ligneous plants by proposing a new model & test against with the source paper,uses,uses
381,Diabetic Retinopathy Detection Net,Development and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs.,https://www.mdpi.com/2079-9721/11/3/97/pdf?version=1689308882,Background,,"In general, for the diagnosis and treatment of diabetes, the clinical application of AI can be divided into four main sectors: (i) retinal screening; (ii) support for clinical diagnosis; (iii) management tools; and (iv) risk evaluation [31].",No,,No,commentary that briefly describes the evolution of AI and its applications in healthcare (focus on diabetes - related to the source paper),,background,background
382,,,,Background,,"The second group includes systems that send data collected from continuous glucose monitoring to a cloud server and utilizes AI to remotely decide and suggest the appropriate adjustment for insulin dose; the physicians can then evaluate the suggestion and, if necessary, alert patients [31].",,,,,,background,background
383,,,,Background,,"For example, in the Guardian Connect System, AI predicts hypoglycemia 1 h in advance on the basis of data received from continuous glucose monitoring and warning the patient who can take, for example, glucose tablets in time [31].",,,,,,background,background
384,,,,Background,,"Finally, the last group involves ML technologies that are able to identify subjects at high risk of developing diabetes, even if ML does not currently outperform the conventional statistical models already employed to calculate the risk of diabetes onset, so that more studies are needed in this regard [31].",,,,,,background,background
385,Photo-Geometric Autoencoder,Unsupervised Learning of Probably Symmetric Deformable 3D Objects From Images in the Wild,https://www.mdpi.com/2079-9292/12/2/350/pdf?version=1673329193,Background,,"In recent years, the use of such architectures has demonstrated great success in both supervised and unsupervised learning for depth estimation problems [12,13].",Yes,HeightNet,Yes,"HeightNet, LapDepth",,background,background
423,Phenaki,Phenaki: Variable Length Video Generation From Open Domain Textual Description,https://arxiv.org/pdf/2212.08045,Background,,"These broadly use discriminative tasks to learn representations for various downstream modalities; generative approaches to multimodal modelling have been scaled to billions of parameters, generating text [2, 10, 74, 82], images [58, 62, 83], videos [27, 72] or audio [5] from various modalities.",yes,CLIPPO,no,,,background,background
424,LaMDA,LaMDA: Language Models for Dialog Applications,https://arxiv.org/pdf/2306.08107,Background,,"Large Language Models (LLMs) (Zhao et al., 2023a) are currently on everybody’s lips due to the recent series of rapid breakthroughs achieved, such as self-attention (Vaswani et al., 2017), BERT (Devlin et al., 2019), several versions of GPT (Radford et al., 2018; 2019; Brown et al., 2020; OpenAI, 2022; 2023), LaMDA (Thoppilan et al., 2022), LLaMA (Touvron et al., 2023), or OpenAssistant (Köpf et al., 2023).",no,,no,,,background,background
425,Inception v3,Rethinking the Inception Architecture for Computer Vision,https://www.frontiersin.org/articles/10.3389/fncom.2023.1268116/pdf?isPublishedV2=False,Background,,"Specifically, we used three vision networks with pre-trained weights that are available in the TensorFlow’s model zoo: InceptionV3 (Szegedy et al., 2016), ResNet50 (He et al., 2016), and EfficientNetB4 (Tan and Le, 2019).",yes,e classical autoencoder framework and create two networks: a “forward network” and an “inverse network”.,no,,,uses,uses
426,ATLAS,UnifiedQA: Crossing Format Boundaries With a Single QA System,https://www.igi-global.com/ViewTitle.aspx?TitleId=328681&isxn=9781668479155,Background,,"In the relation extraction task, the verbalizer mainly aims to map the generated sequences to specific relation classifications, and some scholars have conducted answer engineering studies in classification tasks (Yin et al., 2019), relation extraction (Chen et al., 2022), named entity recognition (Cui et al., 2021), generation tasks (Alec Radford et al., 2019), and multiple choices tasks (Khashabi et al., 2020).",no,,no,,,background,background
427,GPU DBNs,Large-scale deep unsupervised learning using graphics processors,https://www.spiedigitallibrary.org/journals/Journal-of-Applied-Remote-Sensing/volume-11/issue-4/042609/Comprehensive-survey-of-deep-learning-in-remote-sensing--theories/10.1117/1.JRS.11.042609.pdf,Background,,"For example, Raina et al.67 put forth central processing unit (CPU) and GPU ideas to accelerate DBNs and sparse coding",no,,no,,,background,background
428,Naive Bayes,Pattern classification and scene analysis,https://www.mdpi.com/1424-8220/23/24/9811/pdf?version=1702535879,Uses,,Fourteen classifiers were tested: • K nearest neighbor methods with the selected metrics; • Naive Bayes classifier (NB) [33–35];,yes,MCA-8 device in the Styrofoam,yes,NB classifier. ,,uses,uses
429,OpenAI Five,Dota 2 with Large Scale Deep Reinforcement Learning,http://arxiv.org/pdf/2306.00975,Background,,"Although Reinforcement Learning (RL) has demonstrated success across challenging tasks and games in both simulated and real environments [2, 9, 11, 89, 97], the observation spaces for visual RL tasks are typically predefined to offer the most advantageous views based on prior knowledge and can not be actively adjusted by the agent itself.",yes,SUGARL,no,,,background,background
430,NPLM,A Neural Probabilistic Language Model,https://arxiv.org/pdf/2306.01941,Background,,"An LLM, like any language model, predicts the conditional probability of a token—which might be a character, word, or other string—given its preceding context and, in the case of bidirectional models, its surrounding context [17, 156].",no,,no,,,background,background
431,LeNet-5,Gradient-based learning applied to document recognition,https://plantmethods.biomedcentral.com/counter/pdf/10.1186/s13007-023-01119-6,Background,,"A typical Transformer is comprised of Attention modules focusing on vital information from global to local, and it often showed signifcant performance improvement when trained on large datasets [25].",yes,ESMAraPPI,no,,,background,background
432,NMT Transformer 437M,Massively Multilingual Neural Machine Translation,https://aclanthology.org/2021.eacl-main.30.pdf,Background,,"This is analogous to the techniques used for silver data pre-training (Konstas et al., 2017; van Noord and Bos, 2017) in AMR parsing and multi-lingual pre-training (Aharoni et al., 2019) in machine translation.",yes,"transformer-based
multilingual word embeddings for annotation projection of AMR annotations.",no,,,similarities,similarities
433,LSTM + dynamic eval,Dynamic Evaluation of Neural Sequence Models,https://aclanthology.org/2021.codi-main.14.pdf,Background,,"Running oracle self-training makes it similar to the dynamic evaluation approach introduced in language modeling (Mikolov, 2012; Graves, 2013; Krause et al., 145 2018), where input text to the language model is the target used to train the neural language model during evaluation.",yes,foreign-text-to-English AMR alignment,no,,,similarities,similarities
434,LSTM,Long Short-Term Memory,https://ijere.iaescore.com/index.php/IJERE/article/download/26024/13749,Background,,Long short-term memory (LSTM) is one of the powerful classification methods in deep learning. LSTM architecture has been developed as a solution to the problem of vanishing and exploding gradients encountered in recurring neural networks (RNNs) [24].,yes,"We integrated the RF model to
predict the sentiment analysis, and the LSTM model to predict the epistemic",no,,,background,background
435,OpenAI Five Rerun,Dota 2 with Large Scale Deep Reinforcement Learning,http://arxiv.org/pdf/2301.04299,Background,,"Deep Reinforcement Learning (DRL) has made significant progress over the past decade, from its start playing Atari games [1], to beating humans in board [2] and video games [3, 4], to now addressing important complex safetycritical challenges such as defending computer systems [5], managing power networks [6] and driving vehicles [7].",no,,no,,,background,background
436,T5-11B,Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer,https://www.cambridge.org/core/services/aop-cambridge-core/content/view/5E5A7C1272C234F77ECB4A354E6FB253/S1351324923000487a.pdf/div-class-title-data-to-text-generation-using-conditional-generative-adversarial-with-enhanced-transformer-div.pdf,Background,,"One of the most common deep learning methods is to use the maximum likelihood estimation (MLE) loss function.
D2T models trained with this method, which are generally based on RNN networks (Wen et al.
2015a, b, c, 2016; Dusek and Jurcicek 2016; Mei, Bansal, and Walter 2016; Nayak et al. 2017; Riou
et al. 2017; Gehrmann, Dai, and Elder 2018; Juraska et al. 2018; Liu et al. 2018; Oraby et al. 2018;
Sha et al. 2018) or transformers (Gehrmann et al. 2018; Gong 2018; Radford et al. 2019; Kasner
and Dušek 2020a; Peng et al. 2020; Harkous, Groves, and Saffari 2020; Chen et al. 2020; Kale and
Rastogi 2020a; Raffel et al. 2020; Chang et al. 2021; Lee 2021), auto-regressively generate each output token based on the sequence of previously generated tokens.",yes,"enhanced version of the vanilla transformer encoder
and decoder",no,,,background,background
437,GloVe (6B),GloVe: Global Vectors for Word Representation,https://arxiv.org/pdf/2310.07290,Background,,"ations. These models, such as Word2Vec [32], FastText [8], GloVe [44], and BERT [16], capture the semantic and syntactic meaning of words, sentences, or entire documents by mapping them to dense vecto",yes,G-CatA,yes,GloVe,,background,background
438,,,,Uses,,"Out of the word embedding models utilized by the authors, we specifically chose GloVe [44], as they demonstrated that it yielded the most favorable outcomes",yes,G-CatA,yes,GloVe,,uses,uses
439,Sparse coding model for V1 receptive fields,Sparse coding with an overcomplete basis set: A strategy employed by V1?,https://www.intechopen.com/citation-pdf-url/69022,Background,,"A significantly different approach to the sparse modelling, originally introduced by Olshausen and Field [1], consists of learning a dictionary from some training data.",no,,no,,,background,background
440,,,,Background,,"Olshausen and Field [1] proposed a significantly different approach for designing the dictionary using the training data, benefiting from modelling the receptive fields of simple cells in the mammalian primary visual cortex",no,,no,,,background,background
441,Time-delay neural networks,Phoneme recognition using time-delay neural networks,http://arxiv.org/pdf/2108.05679,Background,,"An encoder (or a frame processor) implemented with multiple layers of time-delay neural network (TDNN) [19], [20]. In [21], it’s shown that a TDNN could be implemented as a 1D-CNN with dilation. In [4], [22], [23], 2D-convolution has shown to be effective as well",yes,xi-vector,no,,,background,background
442,Walking Minotaur robot,Learning to Walk via Deep Reinforcement Learning,http://arxiv.org/pdf/2209.08381,Background,,"RL algorithms have seen impressive successes recently in a number of application such as playing games [14], [15] and robotics [16]–[19].",yes,"an algorithm for autonomous ship landing for VTOL capable UAVs in the presence of adversarial environmental
conditions such as wind gusts",no,,,background,background
443,ESRGAN,ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks,http://arxiv.org/pdf/2304.09414,Background,,Given the success of residual neural networks in the area of image reconstruction [56]–[58] we use one of such architectures as the backbone for our method,yes,no name,no,,,uses,uses
444,YOLOv2,"YOLO9000: Better, Faster, Stronger",https://arxiv.org/pdf/2308.11894,Background,,"The former, such as YOLO [29, 45, 46], usually has higher detection speed, while the latter, such as Faster R-CNN [47], usually has higher detection accuracy.",yes,SysAdv,no,,,background,background
445,DLRM-2020,Deep Learning Recommendation Model for Personalization and Recommendation Systems,https://link.springer.com/content/pdf/10.1007/s44196-022-00179-1.pdf,Background,,These standard scores will further be put into the whole ranking deep neural network to get the overall score ranking. Maxim et al. [28] designed a new parallel scheme that enabled efcient computation of fully connected layers in learning-based recommendation model.,yes,DRR-Max,no,,,background,background
447,DeepLabV3+,Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation,https://www.mdpi.com/2313-7673/8/4/356/pdf?version=1691641647,Background,,"Serveral key techniques have emerged, such as enlarging the receptive field with dilated or atrous convolution [18–20], refining the contextual information by multi-scale feature fusion [21–24], etc",yes,SCGNet-L,no,,,background,background
448,Cross-lingual alignment,"Cross-Lingual Alignment of Contextual Word Embeddings, with Applications to Zero-shot Dependency Parsing",https://ojs.aaai.org/index.php/AAAI/article/download/17588/17395,Background,,"Recently, numerous cross-lingual adaptation methods have been applied to this data-scarcity scenario, where zero or very few target language training samples are utilized (Wisniewski et al. 2014; Schuster et al. 2019b; Artetxe and Schwenk 2019; Liu et al. 2019; Chen et al. 2019)",no,,no,,,background,background
449,"Mogrifier (d2, MoS2, MC) + dynamic eval",Remaining useful life prediction of lithium battery based on ACNN-Mogrifier LSTM-MMD,https://www.mdpi.com/1996-1944/16/22/7186/pdf?version=1700119067,Background,,"However, the type of life reported in these studies is the working life. Similar research on the fatigue life has rarely been reported [25,26].",no,,no,,,background,background
450,"MSRA (C, PReLU)",Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification,https://arxiv.org/pdf/2310.01942,Background,,"Modern deep learning architectures have demonstrated great generalization performance, surpassing human baselines on different tasks [6, 19, 57].",yes,a new OODaware training regime tailored for representations trained with SupCo,no,,,background,background
451,Image Classification with the Fisher Vector: Theory and Practice,"Author manuscript, published in ""International Journal of Computer Vision (2013)"" International Journal of Computer Vision manuscript No. (will be inserted by the editor) Image Classification with the Fisher Vector: Theory and Practice",https://www.ijcai.org/proceedings/2017/0256.pdf,Background,,"It cannot work for those situations where we have limited resources which cannot meet the requirement, such as doing image labeling [Sanchez ´ et al., 2013] on smart phones",no,,no,,,background,background
452,MegaSyn,Dual use of artificial-intelligence-powered drug discovery,http://www.sciencepolicyjournal.org/uploads/5/4/3/4/5434385/cherney_etal_jspg_22-3.pdf,Background,,"In fact, a pharmaceuticals company found that toggling their drug discovery AI program to predict the most toxic compounds to humans could be accomplished in just six short hours (Urbina 2022).",no,,no,,,background,background
453,AbLang,AbLang: an antibody language model for completing antibody sequences,https://www.biorxiv.org/content/biorxiv/early/2023/01/31/2023.01.29.525793.full.pdf,Uses,,"Encouraged by the success of PLMs in protein representation learning, series work seeks to learn antibody representations based on sequences of antibodies. (Leem et al., 2021; Ruffolo et al., 2021; Olsen et al., 2022b; Prihoda et al., 2022; Li et al., 2022). AntiBERTy (Ruffolo et al., 2021) proposed the first antibody-specific language model, exploring a Transformer trained on 558M natural antibody sequences in the OAS database.",no,,yes,AbLang H,,background,background
454,BellKor 2009,The BellKor Solution to the Netflix Grand Prize,https://dl.acm.org/doi/pdf/10.1145/3383313.3412216,Background,,"Since temporal information hold contextual information, they can be very crucial for recommendation performance. TimeSVD++ and BPTF [12, 27] adopted time factor into the matrix factorization
method, and TimeSVD++ was one of the main contributions for
the winning of Netflix Grand Prize [11]",yes,MEANTIME,no,,,background,background
455,NLLB,No Language Left Behind: Scaling Human-Centered Machine Translation,https://arxiv.org/pdf/2307.15286,Uses,,"Inspired by one work [34], we use a paraphraser via multilingual Neural Machine Translation (NMT) system (NLLB) based on encoder-decoder framework[4], enabling high-quality zero-shot translations in 200 languages.",yes," new decoding
method that focuses on the lexical variations of the complex word.",yes,NLLB,,uses,uses
